{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Problem at Hand Writing highly optimized compute-intensive code in a traditional programming language is strenuous and time-consuming. Not only does it require advanced engineering skills such as fluency in Assembly language, but a deep understanding of computer architecture is also indispensable. Manual optimization of even the simplest numerical algorithms demands a significant engineering effort. Needless to say, a highly optimized numerical code is often prone to bugs, lacks readability, and offers little to no usability. Code maintenance becomes a nightmare resulting in the reimplementation of the same logic every time an architecture level change is introduced. Accera: An Optimized Solution Accera is a compiler that enables you to experiment with loop optimizations without hand-writing Assembly code. With Accera, these problems and impediments can be addressed in an optimized way. It is available as a Python library and supports cross-compiling to a wide range of processor targets . Accera has THREE primary goals: Performance: To guarantee the fastest implementation for any compute-intensive algorithm. Readability: To ensure effective implementation of algorithms without sacrificing the readability of code. Writability: To provide a user-friendly programming model, designed for agility and maintainability. Install To install for Linux, macOS, or Windows (requires Python 3.7-3.10): pip install accera See the Install Instructions for more details on installing pre-built Python 3 packages and how to build Accera from the source. Quickstart In this example, we will: Implement matrix multiplication with a ReLU activation (matmul + ReLU), commonly used in machine learning algorithms. Generate two implementations: a naive algorithm and loop-based transformations. Compare the execution time of both implementations. Run in your browser No installation is required. This will launch a Jupyter notebook with the quickstart example running in the cloud. Run on your machine Create a Python 3 script called quickstart.py : import accera as acc # define placeholder inputs/output A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 512 , 512 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 512 , 512 )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( 512 , 512 )) # implement the logic for matmul and relu matmul = acc . Nest ( shape = ( 512 , 512 , 512 )) i1 , j1 , k1 = matmul . get_indices () @matmul . iteration_logic def _ (): C [ i1 , j1 ] += A [ i1 , k1 ] * B [ k1 , j1 ] relu = acc . Nest ( shape = ( 512 , 512 )) i2 , j2 = relu . get_indices () @relu . iteration_logic def _ (): C [ i2 , j2 ] = acc . max ( C [ i2 , j2 ], 0.0 ) package = acc . Package () # fuse the i and j indices of matmul and relu, add to the package schedule = acc . fuse ( matmul . create_schedule (), relu . create_schedule (), partial = 2 ) package . add ( schedule , args = ( A , B , C ), base_name = \"matmul_relu_fusion_naive\" ) # transform the schedule, add to the package f , i , j , k = schedule . get_indices () ii , jj = schedule . tile ({ i : 16 , j : 16 }) # loop tiling schedule . reorder ( j , i , f , k , jj , ii ) # loop reordering plan = schedule . create_plan () plan . unroll ( ii ) # loop unrolling package . add ( plan , args = ( A , B , C ), base_name = \"matmul_relu_fusion_transformed\" ) # build a dynamically-linked package (a .dll or .so) that exports both functions print ( package . build ( name = \"hello_accera\" , format = acc . Package . Format . HAT_DYNAMIC )) Ensure that you have a compiler in your PATH: Windows: Install Microsoft Visual Studio and run vcvars64.bat to setup the command prompt. Linux/macOS: Install gcc Don't have a compiler handy? We recommend trying Accera in your browser instead Install Accera: pip install accera Generate the library that implements two versions of matmul + ReLU: python quickstart.py To consume and compare the library functions, create a file called benchmark.py in the same location: import hatlib as hat import numpy as np # load the package _ , functions = hat . load ( \"hello_accera.hat\" ) # call one of the functions with test inputs A_test = np . random . rand ( 512 , 512 ) . astype ( np . float32 ) B_test = np . random . rand ( 512 , 512 ) . astype ( np . float32 ) C_test = np . zeros (( 512 , 512 )) . astype ( np . float32 ) C_numpy = np . maximum ( C_test + A_test @ B_test , 0.0 ) matmul_relu = functions [ \"matmul_relu_fusion_transformed\" ] matmul_relu ( A_test , B_test , C_test ) # check correctness np . testing . assert_allclose ( C_test , C_numpy , atol = 1e-3 ) # benchmark all functions hat . run_benchmark ( \"hello_accera.hat\" , batch_size = 5 , min_time_in_sec = 5 ) Run the benchmark to get the execution time results: python benchmark.py Next Steps The Manual is the best introductory resource for the Accera Python programming model. In particular, the schedule transformations describe how you can experiment with different loop transformations with just a few lines of Python code. Finally, the .hat format is just a C header file containing the metadata. Learn more about the HAT format and benchmarking . How it works In a nutshell, Accera takes the Python code that defines the loop schedule and algorithm while converting it into MLIR intermediate representation (IR). Accera's compiler then takes this IR through a series of MLIR pipelines to perform transformations. The result is a binary library with a C header file. The library implements the algorithms that are defined in Python and it is compatible with the target. To peek into the stages of IR transformation that Accera does, try replacing format=acc.Package.Format.HAT_DYNAMIC with format=acc.Package.Format.MLIR_DYNAMIC in quickstart.py , re-run the script, and search the _tmp subfolder for the intermediate *.mlir files. We plan to document these IR constructs in the future. Documentation Get familiar with Accera's concepts and Python constructs in the Documentation page. Tutorials Step-by-step examples are available on the Tutorials page. We're working on adding more complementary examples and tutorials. Contributions Accera is a research platform-in-progress that can certainly benefit from your contributions. We would love your feedback, recommendations, and feature requests. Not to mention that we are excited to answer your questions. Let\u2019s collaborate! Please file a Github issue or send us a pull request. Please review the Microsoft Code of Conduct to learn more. Credits Accera is built using several open source libraries, including: LLVM , pybind11 , toml++ , tomlkit , vcpkg , pyyaml , and HAT . For testing, we used numpy and catch2 . License This project is released under the MIT License .","title":"Home"},{"location":"#problem-at-hand","text":"Writing highly optimized compute-intensive code in a traditional programming language is strenuous and time-consuming. Not only does it require advanced engineering skills such as fluency in Assembly language, but a deep understanding of computer architecture is also indispensable. Manual optimization of even the simplest numerical algorithms demands a significant engineering effort. Needless to say, a highly optimized numerical code is often prone to bugs, lacks readability, and offers little to no usability. Code maintenance becomes a nightmare resulting in the reimplementation of the same logic every time an architecture level change is introduced.","title":"Problem at Hand"},{"location":"#accera-an-optimized-solution","text":"Accera is a compiler that enables you to experiment with loop optimizations without hand-writing Assembly code. With Accera, these problems and impediments can be addressed in an optimized way. It is available as a Python library and supports cross-compiling to a wide range of processor targets . Accera has THREE primary goals: Performance: To guarantee the fastest implementation for any compute-intensive algorithm. Readability: To ensure effective implementation of algorithms without sacrificing the readability of code. Writability: To provide a user-friendly programming model, designed for agility and maintainability.","title":"Accera: An Optimized Solution"},{"location":"#install","text":"To install for Linux, macOS, or Windows (requires Python 3.7-3.10): pip install accera See the Install Instructions for more details on installing pre-built Python 3 packages and how to build Accera from the source.","title":"Install"},{"location":"#quickstart","text":"In this example, we will: Implement matrix multiplication with a ReLU activation (matmul + ReLU), commonly used in machine learning algorithms. Generate two implementations: a naive algorithm and loop-based transformations. Compare the execution time of both implementations.","title":"Quickstart"},{"location":"#run-in-your-browser","text":"No installation is required. This will launch a Jupyter notebook with the quickstart example running in the cloud.","title":"Run in your browser"},{"location":"#run-on-your-machine","text":"Create a Python 3 script called quickstart.py : import accera as acc # define placeholder inputs/output A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 512 , 512 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 512 , 512 )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( 512 , 512 )) # implement the logic for matmul and relu matmul = acc . Nest ( shape = ( 512 , 512 , 512 )) i1 , j1 , k1 = matmul . get_indices () @matmul . iteration_logic def _ (): C [ i1 , j1 ] += A [ i1 , k1 ] * B [ k1 , j1 ] relu = acc . Nest ( shape = ( 512 , 512 )) i2 , j2 = relu . get_indices () @relu . iteration_logic def _ (): C [ i2 , j2 ] = acc . max ( C [ i2 , j2 ], 0.0 ) package = acc . Package () # fuse the i and j indices of matmul and relu, add to the package schedule = acc . fuse ( matmul . create_schedule (), relu . create_schedule (), partial = 2 ) package . add ( schedule , args = ( A , B , C ), base_name = \"matmul_relu_fusion_naive\" ) # transform the schedule, add to the package f , i , j , k = schedule . get_indices () ii , jj = schedule . tile ({ i : 16 , j : 16 }) # loop tiling schedule . reorder ( j , i , f , k , jj , ii ) # loop reordering plan = schedule . create_plan () plan . unroll ( ii ) # loop unrolling package . add ( plan , args = ( A , B , C ), base_name = \"matmul_relu_fusion_transformed\" ) # build a dynamically-linked package (a .dll or .so) that exports both functions print ( package . build ( name = \"hello_accera\" , format = acc . Package . Format . HAT_DYNAMIC )) Ensure that you have a compiler in your PATH: Windows: Install Microsoft Visual Studio and run vcvars64.bat to setup the command prompt. Linux/macOS: Install gcc Don't have a compiler handy? We recommend trying Accera in your browser instead Install Accera: pip install accera Generate the library that implements two versions of matmul + ReLU: python quickstart.py To consume and compare the library functions, create a file called benchmark.py in the same location: import hatlib as hat import numpy as np # load the package _ , functions = hat . load ( \"hello_accera.hat\" ) # call one of the functions with test inputs A_test = np . random . rand ( 512 , 512 ) . astype ( np . float32 ) B_test = np . random . rand ( 512 , 512 ) . astype ( np . float32 ) C_test = np . zeros (( 512 , 512 )) . astype ( np . float32 ) C_numpy = np . maximum ( C_test + A_test @ B_test , 0.0 ) matmul_relu = functions [ \"matmul_relu_fusion_transformed\" ] matmul_relu ( A_test , B_test , C_test ) # check correctness np . testing . assert_allclose ( C_test , C_numpy , atol = 1e-3 ) # benchmark all functions hat . run_benchmark ( \"hello_accera.hat\" , batch_size = 5 , min_time_in_sec = 5 ) Run the benchmark to get the execution time results: python benchmark.py","title":"Run on your machine"},{"location":"#next-steps","text":"The Manual is the best introductory resource for the Accera Python programming model. In particular, the schedule transformations describe how you can experiment with different loop transformations with just a few lines of Python code. Finally, the .hat format is just a C header file containing the metadata. Learn more about the HAT format and benchmarking .","title":"Next Steps"},{"location":"#how-it-works","text":"In a nutshell, Accera takes the Python code that defines the loop schedule and algorithm while converting it into MLIR intermediate representation (IR). Accera's compiler then takes this IR through a series of MLIR pipelines to perform transformations. The result is a binary library with a C header file. The library implements the algorithms that are defined in Python and it is compatible with the target. To peek into the stages of IR transformation that Accera does, try replacing format=acc.Package.Format.HAT_DYNAMIC with format=acc.Package.Format.MLIR_DYNAMIC in quickstart.py , re-run the script, and search the _tmp subfolder for the intermediate *.mlir files. We plan to document these IR constructs in the future.","title":"How it works"},{"location":"#documentation","text":"Get familiar with Accera's concepts and Python constructs in the Documentation page.","title":"Documentation"},{"location":"#tutorials","text":"Step-by-step examples are available on the Tutorials page. We're working on adding more complementary examples and tutorials.","title":"Tutorials"},{"location":"#contributions","text":"Accera is a research platform-in-progress that can certainly benefit from your contributions. We would love your feedback, recommendations, and feature requests. Not to mention that we are excited to answer your questions. Let\u2019s collaborate! Please file a Github issue or send us a pull request. Please review the Microsoft Code of Conduct to learn more.","title":"Contributions"},{"location":"#credits","text":"Accera is built using several open source libraries, including: LLVM , pybind11 , toml++ , tomlkit , vcpkg , pyyaml , and HAT . For testing, we used numpy and catch2 .","title":"Credits"},{"location":"#license","text":"This project is released under the MIT License .","title":"License"},{"location":"Case%20Studies/","text":"Accera Case Studies Accera case studies are community-provided samples that showcase the Accera language and programming model. To contribute a case study of your own, follow these instructions . MatMul Grid Search MatMul Grid Search Convolution NCHWc 2D Convolution Grid Search Three Matrix Multiplication (Coming soon)","title":"Index"},{"location":"Case%20Studies/#accera-case-studies","text":"Accera case studies are community-provided samples that showcase the Accera language and programming model. To contribute a case study of your own, follow these instructions .","title":"Accera Case Studies"},{"location":"Case%20Studies/#matmul-grid-search","text":"MatMul Grid Search","title":"MatMul Grid Search"},{"location":"Case%20Studies/#convolution","text":"NCHWc 2D Convolution Grid Search","title":"Convolution"},{"location":"Case%20Studies/#three-matrix-multiplication","text":"(Coming soon)","title":"Three Matrix Multiplication"},{"location":"Case%20Studies/CONTRIBUTING/","text":"Contributing Guide Thank you for investing your time contributing a community case study! In this guide, you will get an overview of the contribution workflow. Getting started Read our Code of Conduct to keep our community approachable and respectable. Refer to the Manual and Tutorials to familiarize yourself with the Accera language and programming model. Components of a good case study A good case study should have these components and characteristics: Solves one specific task, such as matrix multiplication, matrix convolution, vector addition. If you have a series of tasks to solve, break them up into multiple case studies that reference one another. Includes working Accera Python code implementing that task. At the end of the case study, the code should produce a HAT package using accera.Package.build() . Describes the thought process, considerations, pros and cons of your implementation in a README.md . If the case study generates several implementations (for example, using Parameter Grids ), include the following: Benchmark results on a target machine (for example, your laptop). You can run hatlib.run_benchmark on your HAT package. A description of the make and model of that target machine you used (for example, Intel Xeon E5). If you are unsure, you can use the output of this command: python -m cpuinfo For some examples, refer to the published case studies in the Table of Contents . Publishing your case study All community case studies are published directly from the author's GitHub repository and linked to from the Accera GitHub repository. Once you are ready to publish your case study: 1. Make your case study GitHub repository public (if you haven't done so already). Edit Case Studies/README.md to add your case study to the Table of Contents. The link should point to the git SHA for your latest commit. The format to use is: https://github.com/ user / repo /blob/ git_sha / path_to_case_study /README.md. Create a Pull Request to submit your edits to Case Studies/README.md .","title":"CONTRIBUTING"},{"location":"Case%20Studies/CONTRIBUTING/#contributing-guide","text":"Thank you for investing your time contributing a community case study! In this guide, you will get an overview of the contribution workflow.","title":"Contributing Guide"},{"location":"Case%20Studies/CONTRIBUTING/#getting-started","text":"Read our Code of Conduct to keep our community approachable and respectable. Refer to the Manual and Tutorials to familiarize yourself with the Accera language and programming model.","title":"Getting started"},{"location":"Case%20Studies/CONTRIBUTING/#components-of-a-good-case-study","text":"A good case study should have these components and characteristics: Solves one specific task, such as matrix multiplication, matrix convolution, vector addition. If you have a series of tasks to solve, break them up into multiple case studies that reference one another. Includes working Accera Python code implementing that task. At the end of the case study, the code should produce a HAT package using accera.Package.build() . Describes the thought process, considerations, pros and cons of your implementation in a README.md . If the case study generates several implementations (for example, using Parameter Grids ), include the following: Benchmark results on a target machine (for example, your laptop). You can run hatlib.run_benchmark on your HAT package. A description of the make and model of that target machine you used (for example, Intel Xeon E5). If you are unsure, you can use the output of this command: python -m cpuinfo For some examples, refer to the published case studies in the Table of Contents .","title":"Components of a good case study"},{"location":"Case%20Studies/CONTRIBUTING/#publishing-your-case-study","text":"All community case studies are published directly from the author's GitHub repository and linked to from the Accera GitHub repository. Once you are ready to publish your case study: 1. Make your case study GitHub repository public (if you haven't done so already). Edit Case Studies/README.md to add your case study to the Table of Contents. The link should point to the git SHA for your latest commit. The format to use is: https://github.com/ user / repo /blob/ git_sha / path_to_case_study /README.md. Create a Pull Request to submit your edits to Case Studies/README.md .","title":"Publishing your case study"},{"location":"Install/","text":"Install from PyPI The quickest way to get up and running is to install the pre-built Python packages: MacOS Ubuntu Windows Build and Install You can also build and install the latest version of Accera by following these instructions: MacOS Ubuntu Windows","title":"Index"},{"location":"Install/#install-from-pypi","text":"The quickest way to get up and running is to install the pre-built Python packages: MacOS Ubuntu Windows","title":"Install from PyPI"},{"location":"Install/#build-and-install","text":"You can also build and install the latest version of Accera by following these instructions: MacOS Ubuntu Windows","title":"Build and Install"},{"location":"Install/Building_on_MacOS/","text":"Installing on MacOS Install Dependencies Accera requires the following tools and libraries: A C++ compiler that supports C++ 17, such as clang , which is bundled in XCode CMake 3.14 or newer Python 3.7 or newer Ninja Ccache LLVM OpenMP 5, if using parallelization Homebrew is a package manager that makes it easy to install the prerequisites. Homebrew can be downloaded and installed by: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" If you already have Homebrew installed, update it to the latest version by typing: brew update Install the dependencies: Intel MacOS Apple Silicon brew install cmake python ninja-build ccache libomp pkg-config brew install cmake python ninja ccache libomp pkg-config Clang Select the clang compiler from XCode: xcode-select --install Clone Accera A version of git should already be included in XCode. Clone the git repository: git clone --recurse-submodules https://github.com/microsoft/Accera Build and install Accera Run the build.sh script to install dependencies and build the Accera Python package (replace <path_to_accera> with the path to the cloned Accera repository). cd <path_to_accera> sh ./build.sh Update or install the resulting .whl file from the dist sudirectory. The name depends on your Python version, your OS and your CPU architecture. pip install -U ./dist/accera-0.0.1-cp37-cp37-macosx_10_15_x86_64.whl --find-links = dist Build and install using CMake Accera can also be built using CMake (intended for expert users). Install dependencies cd <path_to_accera> git submodule init git submodule update ./external/vcpkg/bootstrap-vcpkg.sh ./external/vcpkg/vcpkg install catch2 tomlplusplus accera-llvm --overlay-ports = external/llvm The last command typically takes a few hours to build and then install Accera's fork of LLVM. We recommend reserving at least 20GB of disk space for the LLVM build. Configure CMake cd <path_to_accera> mkdir build cd build cmake .. -DCMAKE_BUILD_TYPE = Release -G Ninja Build and run tests cmake --build . --config Release ctest -C Release Install cmake --build . --config Release --target install","title":"Building on MacOS"},{"location":"Install/Building_on_MacOS/#installing-on-macos","text":"","title":"Installing on MacOS"},{"location":"Install/Building_on_MacOS/#install-dependencies","text":"Accera requires the following tools and libraries: A C++ compiler that supports C++ 17, such as clang , which is bundled in XCode CMake 3.14 or newer Python 3.7 or newer Ninja Ccache LLVM OpenMP 5, if using parallelization Homebrew is a package manager that makes it easy to install the prerequisites. Homebrew can be downloaded and installed by: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" If you already have Homebrew installed, update it to the latest version by typing: brew update Install the dependencies: Intel MacOS Apple Silicon brew install cmake python ninja-build ccache libomp pkg-config brew install cmake python ninja ccache libomp pkg-config","title":"Install Dependencies"},{"location":"Install/Building_on_MacOS/#clang","text":"Select the clang compiler from XCode: xcode-select --install","title":"Clang"},{"location":"Install/Building_on_MacOS/#clone-accera","text":"A version of git should already be included in XCode. Clone the git repository: git clone --recurse-submodules https://github.com/microsoft/Accera","title":"Clone Accera"},{"location":"Install/Building_on_MacOS/#build-and-install-accera","text":"Run the build.sh script to install dependencies and build the Accera Python package (replace <path_to_accera> with the path to the cloned Accera repository). cd <path_to_accera> sh ./build.sh Update or install the resulting .whl file from the dist sudirectory. The name depends on your Python version, your OS and your CPU architecture. pip install -U ./dist/accera-0.0.1-cp37-cp37-macosx_10_15_x86_64.whl --find-links = dist","title":"Build and install Accera"},{"location":"Install/Building_on_MacOS/#build-and-install-using-cmake","text":"Accera can also be built using CMake (intended for expert users).","title":"Build and install using CMake"},{"location":"Install/Building_on_MacOS/#install-dependencies_1","text":"cd <path_to_accera> git submodule init git submodule update ./external/vcpkg/bootstrap-vcpkg.sh ./external/vcpkg/vcpkg install catch2 tomlplusplus accera-llvm --overlay-ports = external/llvm The last command typically takes a few hours to build and then install Accera's fork of LLVM. We recommend reserving at least 20GB of disk space for the LLVM build.","title":"Install dependencies"},{"location":"Install/Building_on_MacOS/#configure-cmake","text":"cd <path_to_accera> mkdir build cd build cmake .. -DCMAKE_BUILD_TYPE = Release -G Ninja","title":"Configure CMake"},{"location":"Install/Building_on_MacOS/#build-and-run-tests","text":"cmake --build . --config Release ctest -C Release","title":"Build and run tests"},{"location":"Install/Building_on_MacOS/#install","text":"cmake --build . --config Release --target install","title":"Install"},{"location":"Install/Building_on_Ubuntu/","text":"Installing on Ubuntu Install Dependencies Accera requires the following tools and libraries: A C++ compiler that supports C++ 17, such as GCC 8 CMake 3.14 or newer Python 3.7 or newer Ninja Ccache LLVM OpenMP 5, if using parallelization sudo apt update sudo apt-get install gcc-8 g++-8 cmake python3 python3-pip ninja-build ccache libomp-11-dev pkg-config zip Some Ubuntu distributions install an older version of CMake. Check the version of cmake using cmake --version , and download a newer version if older than 3.14. Clone Accera Install git if you don't already have it: sudo apt-get install git Clone the git repository git clone --recurse-submodules https://github.com/microsoft/Accera Build and install Accera Run the build.sh script to install dependencies and build the Accera Python package (replace <path_to_accera> with the path to the cloned Accera repository). cd <path_to_accera> sh ./build.sh Update or install the resulting .whl files from the dist subdirectory. The --find-links option tells pip to look at the dist subdirectory for the dependent packages. The name depends on your Python version, your OS and your CPU architecture. pip install -U ./dist/accera-0.0.1-cp37-cp37m-linux_x86_64.whl --find-links = dist Build and install using CMake Accera can also be built using CMake (intended for expert users). Install dependencies cd <path_to_accera> git submodule init git submodule update ./external/vcpkg/bootstrap-vcpkg.sh ./external/vcpkg/vcpkg install catch2 tomlplusplus accera-llvm --overlay-ports = external/llvm The last command typically takes a few hours to build and then install Accera's fork of LLVM. We recommend reserving at least 20GB of disk space for the LLVM build. Configure CMake cd <path_to_accera> mkdir build cd build cmake .. -DCMAKE_BUILD_TYPE = Release -G Ninja Build and run tests cmake --build . --config Release ctest -C Release Install cmake --build . --config Release --target install","title":"Building on Ubuntu"},{"location":"Install/Building_on_Ubuntu/#installing-on-ubuntu","text":"","title":"Installing on Ubuntu"},{"location":"Install/Building_on_Ubuntu/#install-dependencies","text":"Accera requires the following tools and libraries: A C++ compiler that supports C++ 17, such as GCC 8 CMake 3.14 or newer Python 3.7 or newer Ninja Ccache LLVM OpenMP 5, if using parallelization sudo apt update sudo apt-get install gcc-8 g++-8 cmake python3 python3-pip ninja-build ccache libomp-11-dev pkg-config zip Some Ubuntu distributions install an older version of CMake. Check the version of cmake using cmake --version , and download a newer version if older than 3.14.","title":"Install Dependencies"},{"location":"Install/Building_on_Ubuntu/#clone-accera","text":"","title":"Clone Accera"},{"location":"Install/Building_on_Ubuntu/#install-git-if-you-dont-already-have-it","text":"sudo apt-get install git","title":"Install git if you don't already have it:"},{"location":"Install/Building_on_Ubuntu/#clone-the-git-repository","text":"git clone --recurse-submodules https://github.com/microsoft/Accera","title":"Clone the git repository"},{"location":"Install/Building_on_Ubuntu/#build-and-install-accera","text":"Run the build.sh script to install dependencies and build the Accera Python package (replace <path_to_accera> with the path to the cloned Accera repository). cd <path_to_accera> sh ./build.sh Update or install the resulting .whl files from the dist subdirectory. The --find-links option tells pip to look at the dist subdirectory for the dependent packages. The name depends on your Python version, your OS and your CPU architecture. pip install -U ./dist/accera-0.0.1-cp37-cp37m-linux_x86_64.whl --find-links = dist","title":"Build and install Accera"},{"location":"Install/Building_on_Ubuntu/#build-and-install-using-cmake","text":"Accera can also be built using CMake (intended for expert users).","title":"Build and install using CMake"},{"location":"Install/Building_on_Ubuntu/#install-dependencies_1","text":"cd <path_to_accera> git submodule init git submodule update ./external/vcpkg/bootstrap-vcpkg.sh ./external/vcpkg/vcpkg install catch2 tomlplusplus accera-llvm --overlay-ports = external/llvm The last command typically takes a few hours to build and then install Accera's fork of LLVM. We recommend reserving at least 20GB of disk space for the LLVM build.","title":"Install dependencies"},{"location":"Install/Building_on_Ubuntu/#configure-cmake","text":"cd <path_to_accera> mkdir build cd build cmake .. -DCMAKE_BUILD_TYPE = Release -G Ninja","title":"Configure CMake"},{"location":"Install/Building_on_Ubuntu/#build-and-run-tests","text":"cmake --build . --config Release ctest -C Release","title":"Build and run tests"},{"location":"Install/Building_on_Ubuntu/#install","text":"cmake --build . --config Release --target install","title":"Install"},{"location":"Install/Building_on_Windows/","text":"Installing on Windows Install Dependencies Visual Studio Accera requires a C++ compiler that supports C++ 17. You can download Visual Studio 2019 Enterprise Edition or Visual Studio 2022 Community Edition . Install Update 10 or later, which includes the LLVM OpenMP libraries only for VS 2019. Select Desktop Development with C++ . Accera requires Spectre-mitigated libraries : Go to Individual Components Type in \"Spectre\" in the search box Select the latest version of the MSVC libraries, e.g., MSVC v142 - VS 2019 C++ x64/x86 Spectre-mitigated libs (Latest) (your actual version may vary) CMake Accera requires CMake 3.14 or newer. A version of CMake that satisfies this requirement is included with Visual Studio 2019 and Visual Studio 2022. Python Accera's packages require Python 3.7 64-bit or newer, plus a version of pip that supports 64-bit packages ( win_amd64 ). One way to obtain this is to download and install Miniconda . Download \"Miniconda3 Windows 64-bit\". Optional: Create a conda environment After installing Miniconda, you can optionally create an environment to manage different Python versions. From an \"Anaconda Prompt\", create and then activate an environment for Python 3.7 (or a newer version if you prefer). Make sure to activate an environment from other applications that you use to develop Accera. conda create -n py37 python = 3 .7 conda activate py37 Clone Accera Visual Studio 2019 and 2022 include a version of git . To use it, launch Visual Studio 2019 or 2022, and select Clone a repository . Repository location: https://github.com/microsoft/Accera Build and install Accera From a command line with Python in your PATH, such as an Anaconda Command Prompt, setup the Visual Studio command line environment ( vcvars64.bat ) and then run build.bat to generate the Accera Python packages. For Visual Studio 2022: \"%ProgramFiles%\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\" For Visual Studio 2019: \"%ProgramFiles(x86)%\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\" cd <path_to_accera> build.bat Replace <path_to_accera> with the path to the cloned Accera repository. Update or install the resulting .whl file from the dist subdirectory. The --find-links option tells pip to look at the dist subdirectory for the dependent packages. The whl filename depends on your Python version, your OS, and your CPU architecture. pip install -U dist \\a ccera-0.0.1-cp37-cp37m-win_amd64.whl --find-links = dist Build and install using CMake Accera can also be built using CMake (intended for expert users). Install dependencies cd <path_to_accera> git submodule init git submodule update external \\v cpkg \\b ootstrap-vcpkg.bat external \\v cpkg \\v cpkg install catch2:x64-windows tomlplusplus:x64-windows accera-llvm:x64-windows --overlay-ports = external \\l lvm The last command typically takes a few hours to build and then install Accera's fork of LLVM. We recommend reserving at least 20GB of disk space for the LLVM build. Configure CMake cd <path_to_accera> mkdir build cd build # For Visual Studio 2019: cmake .. -DCMAKE_BUILD_TYPE = Release -G \"Visual Studio 16 2019\" -Ax64 # For Visual Studio 2022: cmake .. -DCMAKE_BUILD_TYPE = Release -G \"Visual Studio 17 2022\" -Ax64 Build and run tests cmake --build . --config Release -- /m ctest -C Release Install cmake --build . --config Release --target install -- /m","title":"Building on Windows"},{"location":"Install/Building_on_Windows/#installing-on-windows","text":"","title":"Installing on Windows"},{"location":"Install/Building_on_Windows/#install-dependencies","text":"","title":"Install Dependencies"},{"location":"Install/Building_on_Windows/#visual-studio","text":"Accera requires a C++ compiler that supports C++ 17. You can download Visual Studio 2019 Enterprise Edition or Visual Studio 2022 Community Edition . Install Update 10 or later, which includes the LLVM OpenMP libraries only for VS 2019. Select Desktop Development with C++ . Accera requires Spectre-mitigated libraries : Go to Individual Components Type in \"Spectre\" in the search box Select the latest version of the MSVC libraries, e.g., MSVC v142 - VS 2019 C++ x64/x86 Spectre-mitigated libs (Latest) (your actual version may vary)","title":"Visual Studio"},{"location":"Install/Building_on_Windows/#cmake","text":"Accera requires CMake 3.14 or newer. A version of CMake that satisfies this requirement is included with Visual Studio 2019 and Visual Studio 2022.","title":"CMake"},{"location":"Install/Building_on_Windows/#python","text":"Accera's packages require Python 3.7 64-bit or newer, plus a version of pip that supports 64-bit packages ( win_amd64 ). One way to obtain this is to download and install Miniconda . Download \"Miniconda3 Windows 64-bit\".","title":"Python"},{"location":"Install/Building_on_Windows/#optional-create-a-conda-environment","text":"After installing Miniconda, you can optionally create an environment to manage different Python versions. From an \"Anaconda Prompt\", create and then activate an environment for Python 3.7 (or a newer version if you prefer). Make sure to activate an environment from other applications that you use to develop Accera. conda create -n py37 python = 3 .7 conda activate py37","title":"Optional: Create a conda environment"},{"location":"Install/Building_on_Windows/#clone-accera","text":"Visual Studio 2019 and 2022 include a version of git . To use it, launch Visual Studio 2019 or 2022, and select Clone a repository . Repository location: https://github.com/microsoft/Accera","title":"Clone Accera"},{"location":"Install/Building_on_Windows/#build-and-install-accera","text":"From a command line with Python in your PATH, such as an Anaconda Command Prompt, setup the Visual Studio command line environment ( vcvars64.bat ) and then run build.bat to generate the Accera Python packages. For Visual Studio 2022: \"%ProgramFiles%\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\" For Visual Studio 2019: \"%ProgramFiles(x86)%\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\" cd <path_to_accera> build.bat Replace <path_to_accera> with the path to the cloned Accera repository. Update or install the resulting .whl file from the dist subdirectory. The --find-links option tells pip to look at the dist subdirectory for the dependent packages. The whl filename depends on your Python version, your OS, and your CPU architecture. pip install -U dist \\a ccera-0.0.1-cp37-cp37m-win_amd64.whl --find-links = dist","title":"Build and install Accera"},{"location":"Install/Building_on_Windows/#build-and-install-using-cmake","text":"Accera can also be built using CMake (intended for expert users).","title":"Build and install using CMake"},{"location":"Install/Building_on_Windows/#install-dependencies_1","text":"cd <path_to_accera> git submodule init git submodule update external \\v cpkg \\b ootstrap-vcpkg.bat external \\v cpkg \\v cpkg install catch2:x64-windows tomlplusplus:x64-windows accera-llvm:x64-windows --overlay-ports = external \\l lvm The last command typically takes a few hours to build and then install Accera's fork of LLVM. We recommend reserving at least 20GB of disk space for the LLVM build.","title":"Install dependencies"},{"location":"Install/Building_on_Windows/#configure-cmake","text":"cd <path_to_accera> mkdir build cd build # For Visual Studio 2019: cmake .. -DCMAKE_BUILD_TYPE = Release -G \"Visual Studio 16 2019\" -Ax64 # For Visual Studio 2022: cmake .. -DCMAKE_BUILD_TYPE = Release -G \"Visual Studio 17 2022\" -Ax64","title":"Configure CMake"},{"location":"Install/Building_on_Windows/#build-and-run-tests","text":"cmake --build . --config Release -- /m ctest -C Release","title":"Build and run tests"},{"location":"Install/Building_on_Windows/#install","text":"cmake --build . --config Release --target install -- /m","title":"Install"},{"location":"Install/Installing_Accera_on_MacOS/","text":"Installing on MacOS Install dependencies Accera requires the following tools and libraries for building the generated code: A C++ compiler, such as clang , which is bundled in XCode Python 3.7 or newer OpenMP 5, if using parallelization Homebrew is a package manager that makes it easy to install the prerequisites. Homebrew can be downloaded and installed by: /usr/bin/ruby -e \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install ) \" If you already have Homebrew installed, update it to the latest version by typing: brew update Install the dependencies: brew install cmake python@3.7 Install the optional dependency if using parallelization: brew install libomp Clang Select the clang compiler from XCode: xcode-select --install Install Accera The accera Python package can be installed from PyPI: pip install accera","title":"Installing Accera on MacOS"},{"location":"Install/Installing_Accera_on_MacOS/#installing-on-macos","text":"","title":"Installing on MacOS"},{"location":"Install/Installing_Accera_on_MacOS/#install-dependencies","text":"Accera requires the following tools and libraries for building the generated code: A C++ compiler, such as clang , which is bundled in XCode Python 3.7 or newer OpenMP 5, if using parallelization Homebrew is a package manager that makes it easy to install the prerequisites. Homebrew can be downloaded and installed by: /usr/bin/ruby -e \" $( curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install ) \" If you already have Homebrew installed, update it to the latest version by typing: brew update Install the dependencies: brew install cmake python@3.7 Install the optional dependency if using parallelization: brew install libomp","title":"Install dependencies"},{"location":"Install/Installing_Accera_on_MacOS/#clang","text":"Select the clang compiler from XCode: xcode-select --install","title":"Clang"},{"location":"Install/Installing_Accera_on_MacOS/#install-accera","text":"The accera Python package can be installed from PyPI: pip install accera","title":"Install Accera"},{"location":"Install/Installing_Accera_on_Ubuntu/","text":"Installing on Ubuntu Install dependencies Accera requires the following tools and libraries for building the generated code: A C++ compiler, such as GCC 8 Python 3.7 or newer OpenMP 5, if using parallelization Ubuntu 20.04 is recommended. A quick way to start is to use a new Docker container for Ubuntu 20.04: docker run -v $PWD :/code -it --entrypoint \"/bin/bash\" ubuntu:focal Install Accera's dependencies: apt update apt-get install gcc-8 g++-8 python3 python3-pip libncurses5 Install the optional dependency if using parallelization: apt-get install libomp-11-dev Install Accera The accera Python package can be installed from PyPI: pip install accera","title":"Installing Accera on Ubuntu"},{"location":"Install/Installing_Accera_on_Ubuntu/#installing-on-ubuntu","text":"","title":"Installing on Ubuntu"},{"location":"Install/Installing_Accera_on_Ubuntu/#install-dependencies","text":"Accera requires the following tools and libraries for building the generated code: A C++ compiler, such as GCC 8 Python 3.7 or newer OpenMP 5, if using parallelization Ubuntu 20.04 is recommended. A quick way to start is to use a new Docker container for Ubuntu 20.04: docker run -v $PWD :/code -it --entrypoint \"/bin/bash\" ubuntu:focal Install Accera's dependencies: apt update apt-get install gcc-8 g++-8 python3 python3-pip libncurses5 Install the optional dependency if using parallelization: apt-get install libomp-11-dev","title":"Install dependencies"},{"location":"Install/Installing_Accera_on_Ubuntu/#install-accera","text":"The accera Python package can be installed from PyPI: pip install accera","title":"Install Accera"},{"location":"Install/Installing_Accera_on_Windows/","text":"Installing on Windows Install dependencies Visual Studio Accera's generated code requires a C++ compiler. Download Visual Studio 2019 Enterprise Edition or Visual Studio 2022 Community Edition , and select Desktop development with C++ during installation. If you've selected VS 2019 and would like to use parallelization, ensure that Update 10 or later is installed. Both VS 2019 Update 10 or later and VS 2022 include the LLVM OpenMP libraries. Python Accera's packages require Python 3.7 64-bit or newer, plus a version of pip that supports 64-bit packages ( win_amd64 ). One way to obtain this is to download and install Miniconda . Download \"Miniconda3 Windows 64-bit\". Optional: Create a conda environment After installing Miniconda, you can optionally create an environment to manage different Python versions. From an \"Anaconda Prompt\", create and then activate an environment for Python 3.7 (or a newer version if you prefer): conda create -n py37 python = 3 .7 conda activate py37 Install Accera The accera Python package can be installed from PyPI: pip install accera","title":"Installing Accera on Windows"},{"location":"Install/Installing_Accera_on_Windows/#installing-on-windows","text":"","title":"Installing on Windows"},{"location":"Install/Installing_Accera_on_Windows/#install-dependencies","text":"","title":"Install dependencies"},{"location":"Install/Installing_Accera_on_Windows/#visual-studio","text":"Accera's generated code requires a C++ compiler. Download Visual Studio 2019 Enterprise Edition or Visual Studio 2022 Community Edition , and select Desktop development with C++ during installation. If you've selected VS 2019 and would like to use parallelization, ensure that Update 10 or later is installed. Both VS 2019 Update 10 or later and VS 2022 include the LLVM OpenMP libraries.","title":"Visual Studio"},{"location":"Install/Installing_Accera_on_Windows/#python","text":"Accera's packages require Python 3.7 64-bit or newer, plus a version of pip that supports 64-bit packages ( win_amd64 ). One way to obtain this is to download and install Miniconda . Download \"Miniconda3 Windows 64-bit\".","title":"Python"},{"location":"Install/Installing_Accera_on_Windows/#optional-create-a-conda-environment","text":"After installing Miniconda, you can optionally create an environment to manage different Python versions. From an \"Anaconda Prompt\", create and then activate an environment for Python 3.7 (or a newer version if you prefer): conda create -n py37 python = 3 .7 conda activate py37","title":"Optional: Create a conda environment"},{"location":"Install/Installing_Accera_on_Windows/#install-accera","text":"The accera Python package can be installed from PyPI: pip install accera","title":"Install Accera"},{"location":"Manual/","text":"Accera v1.2.1 Manual Introduction Arrays Simple Affine Loop Nests Schedules Fusing Targets Plans - Caching Plans - Vectorization and Parallelization Deferred layout of constant arrays Parameters Packages","title":"Index"},{"location":"Manual/#accera-v121-manual","text":"Introduction Arrays Simple Affine Loop Nests Schedules Fusing Targets Plans - Caching Plans - Vectorization and Parallelization Deferred layout of constant arrays Parameters Packages","title":"Accera v1.2.1 Manual"},{"location":"Manual/00%20Introduction/","text":"Introduction Accera is a framework with a Python-based Domain-specific Language (eDSL) that produces optimized compute-intensive code. Accera's primary focus is the optimization of affine and semi-affine nested for-loops for CPU and GPU targets. Optimization of compute-intensive code in a traditional programming language is not only challenging and time-consuming, but manual optimization of the simplest numerical algorithms demands significant engineering effort and requires an advanced understanding of computer architecture and fluency in C++, C, or Assembly Language. Even with all these efforts, implemented code is prone to critical bugs and requires extensive engineering effort for maintenance. Accera aims at resolving all these issues by providing optimized solutions for compute-intensive algorithms that are highly efficient, readable, and maintainable. Accera has THREE primary goals: Performance : To generate the fastest implementation for any compute-intensive algorithm. Readability : To ensure effective implementation of algorithms without sacrificing the readability of code. Writability : To provide a user-friendly programming model designed for agility and maintainability. Accera is designed based on the following guiding principles: 1: Strict separation of logic from implementation Traditional programming languages are prone to the tight coupling of code logic ( what the program does) with its implementation ( how the program is implemented). Consider an example of multiplying a 16\u00d711 matrix A by an 11\u00d710 matrix B . The algorithm's logic calculates the sum over k of A[i,k]\u00b7B[k,j] for each value of i and j . In Python, this logic can be expressed as: # C += A @ B for i in range ( 16 ): for j in range ( 10 ): for k in range ( 11 ): C [ i , j ] += A [ i , k ] * B [ k , j ] The above code expresses more than just the logic of matrix multiplication. It insists on a specific execution flow: first perform all the steps required to calculate C(0,0) in ascending order of k ; then proceed to C(0,1) . However, in principle, a single order of execution should not be imposed because the iterations of this loop can be performed in any order while keeping the logic intact. Moreover, the above logic doesn't utilize important optimization techniques, such as double-buffered caching or vectorization. Accera, on the other hand, provides a strict distinction between logic and its implementation. The programmer first implements the logic without performance considerations using a pseudocode-like syntax independent of the target platform. Once the logic is specified, only then does the programmer move to define the concrete implementation details. 2: Mindfully trade-off safety versus expressivity Accera offers a programming model where a default implementation of the specified logic can be transformed and manipulated in different ways. If used correctly, these transformations are safe , which means that the underlying logic remains intact. This allows the programmer to entirely focus on the performance of the logic without worrying about its correctness. Moreover, these safe transformations allow automatic search algorithms to aggressively search the space of transformations to converge faster and find better optima. Traditionally, this safety is achieved by trading off the true potential of a programming language since it demands restricting its scope. Nevertheless, extensive constraints significantly restrict the expressivity and the power of the programming language, eventually preventing the end-users from developing highly-optimized and sophisticated implementations. Accera moderates this trade-off between safety and expressivity by explicitly defining what level of safety guarantees are being given by each transformation under different circumstances. Some situations are safer than others. However, the programmer knows exactly what safeties are being guaranteed in all cases. 3: The programmer is in control Accera gives the programmer maximum control over the generated logic by providing access to the underlying knobs that determine how algorithms are optimized. Convenience methods and carefully used default values can prevent verbosity. As per the use case, these helper methods can always be tuned, even overridden.","title":"00 Introduction"},{"location":"Manual/00%20Introduction/#introduction","text":"Accera is a framework with a Python-based Domain-specific Language (eDSL) that produces optimized compute-intensive code. Accera's primary focus is the optimization of affine and semi-affine nested for-loops for CPU and GPU targets. Optimization of compute-intensive code in a traditional programming language is not only challenging and time-consuming, but manual optimization of the simplest numerical algorithms demands significant engineering effort and requires an advanced understanding of computer architecture and fluency in C++, C, or Assembly Language. Even with all these efforts, implemented code is prone to critical bugs and requires extensive engineering effort for maintenance. Accera aims at resolving all these issues by providing optimized solutions for compute-intensive algorithms that are highly efficient, readable, and maintainable. Accera has THREE primary goals: Performance : To generate the fastest implementation for any compute-intensive algorithm. Readability : To ensure effective implementation of algorithms without sacrificing the readability of code. Writability : To provide a user-friendly programming model designed for agility and maintainability. Accera is designed based on the following guiding principles:","title":"Introduction"},{"location":"Manual/00%20Introduction/#1-strict-separation-of-logic-from-implementation","text":"Traditional programming languages are prone to the tight coupling of code logic ( what the program does) with its implementation ( how the program is implemented). Consider an example of multiplying a 16\u00d711 matrix A by an 11\u00d710 matrix B . The algorithm's logic calculates the sum over k of A[i,k]\u00b7B[k,j] for each value of i and j . In Python, this logic can be expressed as: # C += A @ B for i in range ( 16 ): for j in range ( 10 ): for k in range ( 11 ): C [ i , j ] += A [ i , k ] * B [ k , j ] The above code expresses more than just the logic of matrix multiplication. It insists on a specific execution flow: first perform all the steps required to calculate C(0,0) in ascending order of k ; then proceed to C(0,1) . However, in principle, a single order of execution should not be imposed because the iterations of this loop can be performed in any order while keeping the logic intact. Moreover, the above logic doesn't utilize important optimization techniques, such as double-buffered caching or vectorization. Accera, on the other hand, provides a strict distinction between logic and its implementation. The programmer first implements the logic without performance considerations using a pseudocode-like syntax independent of the target platform. Once the logic is specified, only then does the programmer move to define the concrete implementation details.","title":"1: Strict separation of logic from implementation"},{"location":"Manual/00%20Introduction/#2-mindfully-trade-off-safety-versus-expressivity","text":"Accera offers a programming model where a default implementation of the specified logic can be transformed and manipulated in different ways. If used correctly, these transformations are safe , which means that the underlying logic remains intact. This allows the programmer to entirely focus on the performance of the logic without worrying about its correctness. Moreover, these safe transformations allow automatic search algorithms to aggressively search the space of transformations to converge faster and find better optima. Traditionally, this safety is achieved by trading off the true potential of a programming language since it demands restricting its scope. Nevertheless, extensive constraints significantly restrict the expressivity and the power of the programming language, eventually preventing the end-users from developing highly-optimized and sophisticated implementations. Accera moderates this trade-off between safety and expressivity by explicitly defining what level of safety guarantees are being given by each transformation under different circumstances. Some situations are safer than others. However, the programmer knows exactly what safeties are being guaranteed in all cases.","title":"2: Mindfully trade-off safety versus expressivity"},{"location":"Manual/00%20Introduction/#3-the-programmer-is-in-control","text":"Accera gives the programmer maximum control over the generated logic by providing access to the underlying knobs that determine how algorithms are optimized. Convenience methods and carefully used default values can prevent verbosity. As per the use case, these helper methods can always be tuned, even overridden.","title":"3: The programmer is in control"},{"location":"Manual/01%20Arrays/","text":"Section 1: Arrays Accera stores data in multi-dimensional arrays of scalar elements where all the array elements share the same primary data type (e.g., float32, int8). An array has a constant number of dimensions d known at compile-time (e.g., a matrix is a 2-dimensional array). Each dimension has a positive size, and the sequence of d sizes is called the shape of the array. An element of an array is referred to by a d -coordinate zero-based index vector . Affine memory layout Arrays are multi-dimensional, while computer memories have a linear (one-dimensional) address space. There are many strategies to represent a multi-dimensional array in one-dimensional computer memory. Accera arrays must have an affine memory layout, where each array has an affine memory map that is a d -dimensional vector denoted by a and a memory offset value denoted by o . The array element that corresponds to the index vector i is stored at memory address i\u00b7 a+o (where i\u00b7 a denotes a vector dot product). Affine memory maps are rich enough to represent many standard array layouts. For example, in affine maps, 2-dimensional arrays (matrices) can be represented as row-major , column-major , triangular , banded , and Toeplitz matrices. However, affine maps cannot represent z-ordering or striped or blocked layouts. Array shape In an affine memory map, each dimension corresponds to an element, where the dimension having the largest absolute value of the element is called the major dimension . The user must specify all dimension sizes except for the major dimension when constructing an Array. Accera assumes that the size is arbitrary (or infinite) if the major dimension is not specified. In other words, the iterations of the loops determine how much of the array is visited along this dimension. For example, a row-major matrix must have a compile-time-constant number of columns. However, the number of rows can be left undefined, and the loops' sizes control how many rows are processed. Default and inferred memory layout Although the user can explicitly specify the memory map, Accera offers some conveniences. The user can set the layout as FIRST_MAJOR (e.g., for two-dimensional arrays, first-major is equivalent to row-major) or LAST_MAJOR . In both cases, the affine map is inferred from the array shape. Specifically, if the layout is LAST_MAJOR and the shape is denoted by the vector s , then the map a is set to [1, s0, s0\u00d7s1, s0\u00d7s1\u00d7s2, ...] . If the layout is FIRST_MAJOR and the dimension equals 4, then a is set to [s0\u00d7s1\u00d7s2, s1\u00d7s2, s2, 1] . In both cases, the size of the major dimension is not used in the definition of a . This indicates that the major dimension size is not needed. If no layout is specified, the default layout is FIRST_MAJOR . Array properties Accera arrays are defined with either internal scope or external scope . An internal array is a private array that exists inside a specific Accera function only and cannot be accessed outside of that function. An external array is defined outside of an Accera function and passed in as an argument. The memory layout of an external array is specified as a part of the Accera function signature. Moreover, external arrays are assumed to be disjoint, i.e., they do not share any memory. Accera arrays are either mutable or immutable. The elements of a mutable array can be set by an Accera function, while an immutable array is read-only. Array properties are not explicitly set by the programmer but are implied by the role of the array (see below). Array roles Accera supports the following four array roles where each role is treated differently. - Input - Input/Output - Constant - Temporary Input arrays Input arrays are immutable external arrays whose element type, shape, and affine layout are known at compile-time. However, their contents are only available at runtime. If the Accera function is emitted as a function in C, each input array is passed as a const pointer argument. For example, we can construct a 10\u00d720 input array of 32-bit floating-point numbers by writing import accera as acc A = acc . Array ( shape = ( 10 , 20 ), role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 ) The layout of this array would be the default layout, which is acc.Array.Layout.FIRST_MAJOR . Input/output arrays Input/Output arrays are similar to the input arrays except that they are mutable external arrays, i.e., their values can be changed. This type of array is used to output the results of the loop-nest computation. If the Accera function is emitted as a function in C, each input array is passed as a non-const pointer argument. Constant arrays These are the only Accera arrays whose contents are known at compile-time. Constant arrays are immutable internal arrays whose memory layout can be chosen automatically without any external constraints since they are internally scoped. For example, a constant array can be automatically laid out according to the loop nest's memory access pattern. The layout of a constant array could even depend on its contents (e.g., its sparsity pattern). We must provide the constant array data (the element values) when constructing it. This data can be any Python buffer or a numpy array: import accera as acc import numpy as np matrix = np . random . rand ( 16 , 16 ) B = acc . Array ( role = acc . Array . Role . CONST , data = matrix ) Temporary arrays Temporary arrays are mutable internal arrays that are used when two Accera schedules are fused into one (more on fusing in Section 4 ). The elements of a temporary array are initialized to zeros and used to store intermediate values. Similar to constant arrays, temporary arrays can be laid out arbitrarily. In fact, the Accera compiler can even choose not to store them in physical memory at all.","title":"01 Arrays"},{"location":"Manual/01%20Arrays/#section-1-arrays","text":"Accera stores data in multi-dimensional arrays of scalar elements where all the array elements share the same primary data type (e.g., float32, int8). An array has a constant number of dimensions d known at compile-time (e.g., a matrix is a 2-dimensional array). Each dimension has a positive size, and the sequence of d sizes is called the shape of the array. An element of an array is referred to by a d -coordinate zero-based index vector .","title":"Section 1: Arrays"},{"location":"Manual/01%20Arrays/#affine-memory-layout","text":"Arrays are multi-dimensional, while computer memories have a linear (one-dimensional) address space. There are many strategies to represent a multi-dimensional array in one-dimensional computer memory. Accera arrays must have an affine memory layout, where each array has an affine memory map that is a d -dimensional vector denoted by a and a memory offset value denoted by o . The array element that corresponds to the index vector i is stored at memory address i\u00b7 a+o (where i\u00b7 a denotes a vector dot product). Affine memory maps are rich enough to represent many standard array layouts. For example, in affine maps, 2-dimensional arrays (matrices) can be represented as row-major , column-major , triangular , banded , and Toeplitz matrices. However, affine maps cannot represent z-ordering or striped or blocked layouts.","title":"Affine memory layout"},{"location":"Manual/01%20Arrays/#array-shape","text":"In an affine memory map, each dimension corresponds to an element, where the dimension having the largest absolute value of the element is called the major dimension . The user must specify all dimension sizes except for the major dimension when constructing an Array. Accera assumes that the size is arbitrary (or infinite) if the major dimension is not specified. In other words, the iterations of the loops determine how much of the array is visited along this dimension. For example, a row-major matrix must have a compile-time-constant number of columns. However, the number of rows can be left undefined, and the loops' sizes control how many rows are processed.","title":"Array shape"},{"location":"Manual/01%20Arrays/#default-and-inferred-memory-layout","text":"Although the user can explicitly specify the memory map, Accera offers some conveniences. The user can set the layout as FIRST_MAJOR (e.g., for two-dimensional arrays, first-major is equivalent to row-major) or LAST_MAJOR . In both cases, the affine map is inferred from the array shape. Specifically, if the layout is LAST_MAJOR and the shape is denoted by the vector s , then the map a is set to [1, s0, s0\u00d7s1, s0\u00d7s1\u00d7s2, ...] . If the layout is FIRST_MAJOR and the dimension equals 4, then a is set to [s0\u00d7s1\u00d7s2, s1\u00d7s2, s2, 1] . In both cases, the size of the major dimension is not used in the definition of a . This indicates that the major dimension size is not needed. If no layout is specified, the default layout is FIRST_MAJOR .","title":"Default and inferred memory layout"},{"location":"Manual/01%20Arrays/#array-properties","text":"Accera arrays are defined with either internal scope or external scope . An internal array is a private array that exists inside a specific Accera function only and cannot be accessed outside of that function. An external array is defined outside of an Accera function and passed in as an argument. The memory layout of an external array is specified as a part of the Accera function signature. Moreover, external arrays are assumed to be disjoint, i.e., they do not share any memory. Accera arrays are either mutable or immutable. The elements of a mutable array can be set by an Accera function, while an immutable array is read-only. Array properties are not explicitly set by the programmer but are implied by the role of the array (see below).","title":"Array properties"},{"location":"Manual/01%20Arrays/#array-roles","text":"Accera supports the following four array roles where each role is treated differently. - Input - Input/Output - Constant - Temporary","title":"Array roles"},{"location":"Manual/01%20Arrays/#input-arrays","text":"Input arrays are immutable external arrays whose element type, shape, and affine layout are known at compile-time. However, their contents are only available at runtime. If the Accera function is emitted as a function in C, each input array is passed as a const pointer argument. For example, we can construct a 10\u00d720 input array of 32-bit floating-point numbers by writing import accera as acc A = acc . Array ( shape = ( 10 , 20 ), role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 ) The layout of this array would be the default layout, which is acc.Array.Layout.FIRST_MAJOR .","title":"Input arrays"},{"location":"Manual/01%20Arrays/#inputoutput-arrays","text":"Input/Output arrays are similar to the input arrays except that they are mutable external arrays, i.e., their values can be changed. This type of array is used to output the results of the loop-nest computation. If the Accera function is emitted as a function in C, each input array is passed as a non-const pointer argument.","title":"Input/output arrays"},{"location":"Manual/01%20Arrays/#constant-arrays","text":"These are the only Accera arrays whose contents are known at compile-time. Constant arrays are immutable internal arrays whose memory layout can be chosen automatically without any external constraints since they are internally scoped. For example, a constant array can be automatically laid out according to the loop nest's memory access pattern. The layout of a constant array could even depend on its contents (e.g., its sparsity pattern). We must provide the constant array data (the element values) when constructing it. This data can be any Python buffer or a numpy array: import accera as acc import numpy as np matrix = np . random . rand ( 16 , 16 ) B = acc . Array ( role = acc . Array . Role . CONST , data = matrix )","title":"Constant arrays"},{"location":"Manual/01%20Arrays/#temporary-arrays","text":"Temporary arrays are mutable internal arrays that are used when two Accera schedules are fused into one (more on fusing in Section 4 ). The elements of a temporary array are initialized to zeros and used to store intermediate values. Similar to constant arrays, temporary arrays can be laid out arbitrarily. In fact, the Accera compiler can even choose not to store them in physical memory at all.","title":"Temporary arrays"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/","text":"Section 2: Simple affine loop nests This section introduces loop nests and their different types that are provided in Accera programming model. Affine loop nests Many important compute-intensive workloads can be expressed using nested for-loops. An algorithm that can be defined using nested for-loops is called a loop nest . Accera only supports the class of affine loop nests . A loop nest is affine if the indices of the elements accessed on each iteration are an affine function of the loop iterator variables. For example, the following loop nest is affine: for i in range ( M ): for j in range ( N ): C [ 2 * i + 2 , j + 2 ] += A [ 3 * i , j ] + B [ j , i ] because 2*i+2 , j+2 , 3*i , j and i are all affine functions of the iterator variables i and j . On the other hand, the following loop nest is not affine: for i in range ( M ): for j in range ( N ): C [ i * i , j ] += A [ i * i , j ] + B [ i * j , i ] because i*i and i*j are quadratic (non-affine) functions of i and j . Simple affine loops nests, a.k.a. simple nests Simple Affine Loop Nests , hereinafter referred to as simple nests , is an important subclass of affine loop nests that satisfies the following properties: 1. The loops are perfectly nested : all the computation is entirely contained within the deepest loop. 2. All the loops are normalized : each loop starts at 0, increments by 1, and ends at a compile-time constant size. 3. The loop iterations are order invariant : the logic doesn't change if the loop iterations are executed in a different sequential order. 4. No conditional exit : the loop doesn't contain break or continue commands. The matrix-matrix multiplication example given in the introduction is an example of a simple nest. Another example is 2-dimensional convolution , which is the fundamental operation in convolutional neural networks, and can be written in Python as: # Convolve M x N data matrix A with S x T filter matrix B and add output to matrix C for i in range ( M ): for j in range ( N ): for k in range ( S ): for l in range ( T ): C [ i , j ] += A [ i + k , j + l ] * B [ k , l ] While Accera supports arbitrary affine loop nests, the programmer defines the logic of their algorithms using simple nests. More complex nests are obtained by applying schedule transformations (see Section 3 ) or by fusing multiple schedules (see Section 4 ). Defining the loop nest logic The programmer's goal is to create a highly optimized target-specific implementation of an affine loop nest. The first step towards this goal is to define the logic of one or more simple nests. The logic is a target-independent pseudo-code of a simple nest, written without considering performance. For example, the following code defines the logic of the matrix-matrix multiplication loop nest: # Import accera import accera as acc # Define matrix sizes M = 16 N = 10 S = 11 A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , S )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( S , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) # Define a simple affine loop nest and name its loops i, j, k nest = acc . Nest ( shape = ( M , N , S )) i , j , k = nest . get_indices () # Define the logic of each iteration in the nest @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We start by defining the arrays that participate in the computation: A and B are input arrays and C is an input/output array. Next, we initialize nest to be an empty skeleton of a loop nest, with nested loops of sizes M , N , S . These loops are logical -- think of them as pseudo-code loops -- they do not define the execution order of the iterations. The index variables that correspond to the three loops are named i, j, k respectively. The last part of the example sets the iteration logic to C[i, j] += A[i, k] * B[k, j] . Note that this iteration logic follows an affine memory access pattern. The syntax in the example makes use of Python decorators and is shorthand for the more explicit syntax: def logic_fn (): C [ i , j ] += A [ i , k ] * B [ k , j ] nest . iteration_logic ( logic_fn ) Supported operations The iteration logic can include the following operations (assuming accera was imported as acc ): Assignment operators Operation Types (Operands must be of same type) Description a = b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Assigns the value of scalar b to scalar a Arithmetic operators Operation Types (Operands must be of same type) Description a + b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the sum of scalars a and b a - b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the difference between scalars a and b a * b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the product of scalars a and b a / b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the quotient of scalars a and b . If the operands are integers, an integer division result is returned a ** b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the b 'th power of scalar a a // b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the floor of the quotient of scalars a and b a % b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the signed remainder after dividing scalar a by scalar b -a acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the additive inverse of scalar a Comment: Accera also supports the corresponding compound-assignment operators, such as a += b , a -= b , etc. Relational operators Operation Types (Operands must be of same type) Description a == b acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a equals scalar b , else False a != b acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is not equal to scalar b , else False a < b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is strictly smaller than scalar b , else False a <= b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is smaller than or equal to scalar b , else False a > b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is strictly greater than scalar b , else False a >= b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is greater than or equal to scalar b , else False Logical operators Operation Types (Operands must be of same type) Description acc.logical_and(a, b) acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalars a and b are non-zero, else False acc.logical_or(a, b) acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if either scalar a or scalar b are non-zero, else False acc.logical_not(a) acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if a is zero, else False Bitwise operators Operation Types (Operands must be of same type) Description a & b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise AND of the bits in scalars a and b a \\| b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise OR of the bits in scalars a and b a ^ b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise XOR of the bits in scalars a and b ~a acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise inverse of the bits in scalar a a << b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns scalar a whose bitwise representation is shifted left by b bits a >> b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns scalar a whose bitwise representation is shifted right by b bits Comment: Accera also supports the corresponding compound-assignment operators, such as a &= b , a |= b , etc. Intrinsics Operation Types (Operands must be of same type) Description acc.abs(a) acc.ScalarType.float16/32/64 Returns the absolute value of scalar a acc.max(a, b) acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the larger of the two scalars a and b acc.min(a, b) acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the smaller of the two scalars a and b acc.ceil(a) acc.ScalarType.float16/32/64 Returns the value of scalar a rounded up to the nearest integer as an int64 type acc.floor(a) acc.ScalarType.float16/32/64 Returns the value of scalar a rounded down to the nearest integer as an int64 type acc.sqrt(a) acc.ScalarType.float16/32/64 Returns the square root of scalar a acc.exp(a) acc.ScalarType.float16/32/64 Returns the exponential e raised to the scalar a acc.log(a) acc.ScalarType.float16/32/64 Returns the natural logarithm (base e ) of scalar a acc.log10(a) acc.ScalarType.float16/32/64 Returns the common logarithm (base 10) of scalar a acc.log2(a) acc.ScalarType.float16/32/64 Returns the binary logarithm (base 2) of scalar a acc.sin(a) acc.ScalarType.float16/32/64 Returns the sine of scalar a , where a is in radians acc.cos(a) acc.ScalarType.float16/32/64 Returns the cosine of scalar a , where a is in radians acc.tan(a) acc.ScalarType.float16/32/64 Returns the tangent of scalar a , where a is in radians acc.sinh(a) acc.ScalarType.float16/32/64 Returns the hyperbolic sine of scalar a , where a is in radians acc.cosh(a) acc.ScalarType.float16/32/64 Returns the hyperbolic cosine of scalar a , where a is in radians acc.tanh(a) acc.ScalarType.float16/32/64 Returns the hyperbolic tangent of scalar a , where a is in radians Implicit type casting Accera operators require operands to be the same type. Computations that use multiple types can take advantage of Accera's implicit type casting support when converting from smaller-sized types to larger-sized types. To do implicit casting, simply assign a source type to its implicitly-castable destination type. No additional casting operation is needed for converting between these types. Source types Destination type (implicitly-castable) acc.ScalarType.bool , acc.ScalarType.uint8 acc.ScalarType.int8 acc.ScalarType.bool , acc.ScalarType.int8 acc.ScalarType.uint8 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.uint16 acc.ScalarType.int16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 acc.ScalarType.uint16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.uint32 acc.ScalarType.int32 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 acc.ScalarType.uint32 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.uint64 acc.ScalarType.int64 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.int64 acc.ScalarType.uint64 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 acc.ScalarType.float16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 acc.ScalarType.bfloat16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.int64 , acc.ScalarType.float16 , acc.ScalarType.bfloat16 acc.ScalarType.float32 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.int64 , acc.ScalarType.float16 , acc.ScalarType.bfloat16 , acc.ScalarType.float32 acc.ScalarType.float64 To override the casting behavior above, or cast a larger-sized type to a smaller-sized type, use the acc.cast operation. Comment: implicit casting of constants may result in truncation. Accera program stages Let\u2019s take a step back to describe the stages of Accera program: Nest : A nest captures the logic of a simple nest, without any optimizations or implementation details. Schedule : A Nest is used to create a schedule. The schedule controls the order in which the nest iterations are visited. Multiple schedules can be fused into a single schedule, which may no longer represent a simple nest. Plan : A Schedule is used to create a plan. A plan controls the implementation details that are specific for a target platform (e.g., data caching strategy, vectorization, assignment of arrays and caches to different types of memory). Package : A Plan is used to create a function in a function package. The package is then compiled and emitted. Once a package is emitted, the Accera functions contained in it can be called from external client code. This external code is typically not written using Accera. Accera currently supports the following package formats: HAT , which is a schematized version of a standard C library. The external client code can be written in C or C++ and linked with the HAT package. MLIR , which uses standard MLIR dialects. The external code must also be in MLIR. Overall, to build and emit nest (defined above), we would write: # create a default schedule from the nest schedule = nest . create_schedule () # create a default plan from the schedule plan = schedule . create_plan () # create a HAT package. Create a function in the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"simple_matmul\" ) # build the HAT package package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"linear_algebra\" ) It may not be immediately clear why so many stages are needed just to compile a simple nest. Therefore, let\u2019s discuss each stage in detail to understand their importance. In the example above, the call to package.add takes three arguments: the first is the plan that defines the function's implementation; the second is the order of the input and input/output arrays in the function signature; and the third is a base name for the function. The full name of the function is the base name followed by an automatically-generated unique identifier. For example, the function in the example could appear in the package as simple_matmul_8f24bef5 . The automatically-generated suffix ensures that each function in the package has a unique name. More details on function packages can be found in Section 10 . Convenience syntax For convenience, Accera also provides shortcuts to avoid unnecessary verbosity. Specifically, we can create a function in a package directly from a nest, as follows: package . add ( nest , args = ( A , B , C ), base_name = \"simple_matmul\" ) The abbreviated syntax makes it seem like a callable function is generated directly from nest . However, what actually happens behind the scenes is that nest creates a default schedule, which creates a default plan, which is added as a function in the package. Accera has a similar convenience syntax to create a function from a schedule: package . add ( schedule , args = ( A , B , C ), base_name = \"simple_matmul\" ) and to create a plan directly from a nest: plan = nest . create_plan ()","title":"02 Simple Affine Loop Nests"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#section-2-simple-affine-loop-nests","text":"This section introduces loop nests and their different types that are provided in Accera programming model.","title":"Section 2: Simple affine loop nests"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#affine-loop-nests","text":"Many important compute-intensive workloads can be expressed using nested for-loops. An algorithm that can be defined using nested for-loops is called a loop nest . Accera only supports the class of affine loop nests . A loop nest is affine if the indices of the elements accessed on each iteration are an affine function of the loop iterator variables. For example, the following loop nest is affine: for i in range ( M ): for j in range ( N ): C [ 2 * i + 2 , j + 2 ] += A [ 3 * i , j ] + B [ j , i ] because 2*i+2 , j+2 , 3*i , j and i are all affine functions of the iterator variables i and j . On the other hand, the following loop nest is not affine: for i in range ( M ): for j in range ( N ): C [ i * i , j ] += A [ i * i , j ] + B [ i * j , i ] because i*i and i*j are quadratic (non-affine) functions of i and j .","title":"Affine loop nests"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#simple-affine-loops-nests-aka-simple-nests","text":"Simple Affine Loop Nests , hereinafter referred to as simple nests , is an important subclass of affine loop nests that satisfies the following properties: 1. The loops are perfectly nested : all the computation is entirely contained within the deepest loop. 2. All the loops are normalized : each loop starts at 0, increments by 1, and ends at a compile-time constant size. 3. The loop iterations are order invariant : the logic doesn't change if the loop iterations are executed in a different sequential order. 4. No conditional exit : the loop doesn't contain break or continue commands. The matrix-matrix multiplication example given in the introduction is an example of a simple nest. Another example is 2-dimensional convolution , which is the fundamental operation in convolutional neural networks, and can be written in Python as: # Convolve M x N data matrix A with S x T filter matrix B and add output to matrix C for i in range ( M ): for j in range ( N ): for k in range ( S ): for l in range ( T ): C [ i , j ] += A [ i + k , j + l ] * B [ k , l ] While Accera supports arbitrary affine loop nests, the programmer defines the logic of their algorithms using simple nests. More complex nests are obtained by applying schedule transformations (see Section 3 ) or by fusing multiple schedules (see Section 4 ).","title":"Simple affine loops nests, a.k.a. simple nests"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#defining-the-loop-nest-logic","text":"The programmer's goal is to create a highly optimized target-specific implementation of an affine loop nest. The first step towards this goal is to define the logic of one or more simple nests. The logic is a target-independent pseudo-code of a simple nest, written without considering performance. For example, the following code defines the logic of the matrix-matrix multiplication loop nest: # Import accera import accera as acc # Define matrix sizes M = 16 N = 10 S = 11 A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , S )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( S , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) # Define a simple affine loop nest and name its loops i, j, k nest = acc . Nest ( shape = ( M , N , S )) i , j , k = nest . get_indices () # Define the logic of each iteration in the nest @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We start by defining the arrays that participate in the computation: A and B are input arrays and C is an input/output array. Next, we initialize nest to be an empty skeleton of a loop nest, with nested loops of sizes M , N , S . These loops are logical -- think of them as pseudo-code loops -- they do not define the execution order of the iterations. The index variables that correspond to the three loops are named i, j, k respectively. The last part of the example sets the iteration logic to C[i, j] += A[i, k] * B[k, j] . Note that this iteration logic follows an affine memory access pattern. The syntax in the example makes use of Python decorators and is shorthand for the more explicit syntax: def logic_fn (): C [ i , j ] += A [ i , k ] * B [ k , j ] nest . iteration_logic ( logic_fn )","title":"Defining the loop nest logic"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#supported-operations","text":"The iteration logic can include the following operations (assuming accera was imported as acc ):","title":"Supported operations"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#assignment-operators","text":"Operation Types (Operands must be of same type) Description a = b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Assigns the value of scalar b to scalar a","title":"Assignment operators"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#arithmetic-operators","text":"Operation Types (Operands must be of same type) Description a + b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the sum of scalars a and b a - b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the difference between scalars a and b a * b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the product of scalars a and b a / b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the quotient of scalars a and b . If the operands are integers, an integer division result is returned a ** b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the b 'th power of scalar a a // b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the floor of the quotient of scalars a and b a % b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the signed remainder after dividing scalar a by scalar b -a acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the additive inverse of scalar a Comment: Accera also supports the corresponding compound-assignment operators, such as a += b , a -= b , etc.","title":"Arithmetic operators"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#relational-operators","text":"Operation Types (Operands must be of same type) Description a == b acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a equals scalar b , else False a != b acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is not equal to scalar b , else False a < b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is strictly smaller than scalar b , else False a <= b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is smaller than or equal to scalar b , else False a > b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is strictly greater than scalar b , else False a >= b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalar a is greater than or equal to scalar b , else False","title":"Relational operators"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#logical-operators","text":"Operation Types (Operands must be of same type) Description acc.logical_and(a, b) acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if scalars a and b are non-zero, else False acc.logical_or(a, b) acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if either scalar a or scalar b are non-zero, else False acc.logical_not(a) acc.ScalarType.bool, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if a is zero, else False","title":"Logical operators"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#bitwise-operators","text":"Operation Types (Operands must be of same type) Description a & b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise AND of the bits in scalars a and b a \\| b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise OR of the bits in scalars a and b a ^ b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise XOR of the bits in scalars a and b ~a acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise inverse of the bits in scalar a a << b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns scalar a whose bitwise representation is shifted left by b bits a >> b acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns scalar a whose bitwise representation is shifted right by b bits Comment: Accera also supports the corresponding compound-assignment operators, such as a &= b , a |= b , etc.","title":"Bitwise operators"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#intrinsics","text":"Operation Types (Operands must be of same type) Description acc.abs(a) acc.ScalarType.float16/32/64 Returns the absolute value of scalar a acc.max(a, b) acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the larger of the two scalars a and b acc.min(a, b) acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the smaller of the two scalars a and b acc.ceil(a) acc.ScalarType.float16/32/64 Returns the value of scalar a rounded up to the nearest integer as an int64 type acc.floor(a) acc.ScalarType.float16/32/64 Returns the value of scalar a rounded down to the nearest integer as an int64 type acc.sqrt(a) acc.ScalarType.float16/32/64 Returns the square root of scalar a acc.exp(a) acc.ScalarType.float16/32/64 Returns the exponential e raised to the scalar a acc.log(a) acc.ScalarType.float16/32/64 Returns the natural logarithm (base e ) of scalar a acc.log10(a) acc.ScalarType.float16/32/64 Returns the common logarithm (base 10) of scalar a acc.log2(a) acc.ScalarType.float16/32/64 Returns the binary logarithm (base 2) of scalar a acc.sin(a) acc.ScalarType.float16/32/64 Returns the sine of scalar a , where a is in radians acc.cos(a) acc.ScalarType.float16/32/64 Returns the cosine of scalar a , where a is in radians acc.tan(a) acc.ScalarType.float16/32/64 Returns the tangent of scalar a , where a is in radians acc.sinh(a) acc.ScalarType.float16/32/64 Returns the hyperbolic sine of scalar a , where a is in radians acc.cosh(a) acc.ScalarType.float16/32/64 Returns the hyperbolic cosine of scalar a , where a is in radians acc.tanh(a) acc.ScalarType.float16/32/64 Returns the hyperbolic tangent of scalar a , where a is in radians","title":"Intrinsics"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#implicit-type-casting","text":"Accera operators require operands to be the same type. Computations that use multiple types can take advantage of Accera's implicit type casting support when converting from smaller-sized types to larger-sized types. To do implicit casting, simply assign a source type to its implicitly-castable destination type. No additional casting operation is needed for converting between these types. Source types Destination type (implicitly-castable) acc.ScalarType.bool , acc.ScalarType.uint8 acc.ScalarType.int8 acc.ScalarType.bool , acc.ScalarType.int8 acc.ScalarType.uint8 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.uint16 acc.ScalarType.int16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 acc.ScalarType.uint16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.uint32 acc.ScalarType.int32 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 acc.ScalarType.uint32 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.uint64 acc.ScalarType.int64 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.int64 acc.ScalarType.uint64 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 acc.ScalarType.float16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 acc.ScalarType.bfloat16 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.int64 , acc.ScalarType.float16 , acc.ScalarType.bfloat16 acc.ScalarType.float32 acc.ScalarType.bool , acc.ScalarType.int8 , acc.ScalarType.uint8 , acc.ScalarType.int16 , acc.ScalarType.uint16 , acc.ScalarType.int32 , acc.ScalarType.uint32 , acc.ScalarType.int64 , acc.ScalarType.float16 , acc.ScalarType.bfloat16 , acc.ScalarType.float32 acc.ScalarType.float64 To override the casting behavior above, or cast a larger-sized type to a smaller-sized type, use the acc.cast operation. Comment: implicit casting of constants may result in truncation.","title":"Implicit type casting"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#accera-program-stages","text":"Let\u2019s take a step back to describe the stages of Accera program: Nest : A nest captures the logic of a simple nest, without any optimizations or implementation details. Schedule : A Nest is used to create a schedule. The schedule controls the order in which the nest iterations are visited. Multiple schedules can be fused into a single schedule, which may no longer represent a simple nest. Plan : A Schedule is used to create a plan. A plan controls the implementation details that are specific for a target platform (e.g., data caching strategy, vectorization, assignment of arrays and caches to different types of memory). Package : A Plan is used to create a function in a function package. The package is then compiled and emitted. Once a package is emitted, the Accera functions contained in it can be called from external client code. This external code is typically not written using Accera. Accera currently supports the following package formats: HAT , which is a schematized version of a standard C library. The external client code can be written in C or C++ and linked with the HAT package. MLIR , which uses standard MLIR dialects. The external code must also be in MLIR. Overall, to build and emit nest (defined above), we would write: # create a default schedule from the nest schedule = nest . create_schedule () # create a default plan from the schedule plan = schedule . create_plan () # create a HAT package. Create a function in the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"simple_matmul\" ) # build the HAT package package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"linear_algebra\" ) It may not be immediately clear why so many stages are needed just to compile a simple nest. Therefore, let\u2019s discuss each stage in detail to understand their importance. In the example above, the call to package.add takes three arguments: the first is the plan that defines the function's implementation; the second is the order of the input and input/output arrays in the function signature; and the third is a base name for the function. The full name of the function is the base name followed by an automatically-generated unique identifier. For example, the function in the example could appear in the package as simple_matmul_8f24bef5 . The automatically-generated suffix ensures that each function in the package has a unique name. More details on function packages can be found in Section 10 .","title":"Accera program stages"},{"location":"Manual/02%20Simple%20Affine%20Loop%20Nests/#convenience-syntax","text":"For convenience, Accera also provides shortcuts to avoid unnecessary verbosity. Specifically, we can create a function in a package directly from a nest, as follows: package . add ( nest , args = ( A , B , C ), base_name = \"simple_matmul\" ) The abbreviated syntax makes it seem like a callable function is generated directly from nest . However, what actually happens behind the scenes is that nest creates a default schedule, which creates a default plan, which is added as a function in the package. Accera has a similar convenience syntax to create a function from a schedule: package . add ( schedule , args = ( A , B , C ), base_name = \"simple_matmul\" ) and to create a plan directly from a nest: plan = nest . create_plan ()","title":"Convenience syntax"},{"location":"Manual/03%20Schedules/","text":"Section 3: Schedules We begin with nest from Section 2 which captures the logic of matrix-matrix multiplication. We use nest to create a Schedule that controls the execution order of the nest's iterations. Schedules are target-independent in the sense that the same schedule can be used to emit code for multiple target platforms. We create a default schedule as follows: schedule = nest . create_schedule () The default schedule is equivalent to the following straightforward for-loop version of the loop nest: for i in range ( 3 ): for j in range ( 12 ): for k in range ( 15 ): C [ i , j ] += A [ i , k ] * B [ k , j ] In other words, each of the logical pseudo-code loops in nest becomes an actual for-loop in the default schedule. We can now transform this schedule in various ways. However, these transformations do not change the underlying logic defined in nest and merely change the order of the loop iterations. We can even generate as many independent schedules as we want by calling nest.create_schedule() . Iteration spaces: a geometric representation of schedules In the Accera programming model, a schedule is geometrically interpreted as a multi-dimensional discrete hypercube called the iteration space of the nest. The elements of the iteration space represent the individual iterations of the loop nest. Initially, the dimensions of the iteration space correspond to the logical loops defined in nest . For example, the default iteration space for the matrix-matrix multiplication nest forms a three-dimensional discrete hypercube, whose shape is (3, 12, 15): The (3, 12, 15) iteration space. The arrows labelled 1, 2, and 3 indicate the dimension order and direction. How does an iteration space imply an order over the iterations? The dimensions of the iteration space are ordered, and this order corresponds to the original order of the logical loops in nest by default. In fact, the order over the dimensions induces a lexicographic sequence over the individual elements of the iteration space. Video showing sequence of iterations for the (3, 12, 15) iteration space. This geometric interpretation of schedules helps us visualize how different transformations modify them. While some transformations merely rearrange the elements of the iteration space, others increase its dimensions, and some even pad the space with empty (no-op) elements. The transformed iteration space defines a new lexicographic order over the individual iterations. Comment: It is important not to confuse arrays, like A , B , C , with iteration spaces, like schedule . A possible source of confusion could be that both arrays and iteration spaces have a multidimensional rectilinear structure (i.e., they both look like hypercubes). However, arrays and iteration spaces are fundamentally different. Arrays are data structures whose elements are scalars. Iteration spaces are abstract geometric representations of schedules and their elements represent individual iterations of a loop nest. Transformations apply to iteration spaces, not to arrays. Comment: Accera's geometric interpretation of schedules resembles the iteration domain polyhedron , which is the cornerstone of the polyhedral model of compiler optimization. However, unlike polyhedrons, Accera iteration spaces are not embedded in a continuous space and cannot be manipulated by algebraic transformations. Accera iteration spaces always remain rectilinear and are inherently discrete objects. Iteration space slices Iteration space slices is an abstract concept that affects different aspects of the Accera programming model. Since the iteration space dimensions are ordered, each element of the iteration space can be identified by a vector of coordinates. For example, the vector (1, 6, 7) identifies the iteration at position 1 along the first dimension, position 6 along the second dimension, and position 7 along the third dimension. If one or more coordinates are replaced with the wildcard symbol * , we get an iteration space slice , which is a set of iterations obtained by replacing the wildcard with all possible values. For example, (*, *, 2) represents a slice containing all the elements with 2 as their last coordinate. The dimension of a slice equals the number of wildcards in its definition. The (3, 12, 15) iteration space. Highlighted elements belong to the (*, *, 2) slice. Iteration space slices in four dimensions, denoted by indices ( i , j , jj , k ): (1, *, *, *) (*, *, *, 3) (2, *, 0, *) Loops, indices, and dimensions When we defined nest , we used variables such as i , j , and k to name the loops in the loop-nest. When we described the default schedule using equivalent for-loops, i , j , and k became the index variables of those loops. Now, when we represent a schedule as an iteration space, these variables are used as the names of the corresponding iteration space dimensions. From here on, we move seamlessly between these different representations and use the terms loop , index , and dimension interchangeably. Schedule transformations Iteration space transformations change the shape of the iteration space, possibly by adding dimensions or padding the space with empty elements. The iterations space always retains its rectilinear (hypercube) shape. In some cases, Accera transformations must pad the iteration space with empty elements to avoid reaching a jagged iteration space structure. reorder # Reorder the indices. schedule . reorder ( k , i , j ) The reorder transformation sets the order of indices in the schedule. From the iteration space point-of-view, reorder performs a pivot rotation of the iteration space, which orients its dimensions in a specified order. Since the iteration space elements are executed in lexicographic order, pivoting the iteration space is equivalent to reordering the loops. For example, we can write: schedule . reorder ( j , k , i ) After this transformation, schedule becomes equivalent to: for j in range ( 12 ): for k in range ( 15 ): for i in range ( 3 ): C [ i , j ] += A [ i , k ] * B [ k , j ] Default schedule After reorder(j, k, i) Invalid orders Some orders are not allowed. Describing these restrictions in full will require concepts that are yet to be introduced. Therefore, we are stating these restrictions here and will discuss them later in the upcoming sections. The restrictions are: 1. The inner dimension created by a split transformation (see below) must be ordered later than its corresponding outer dimension . 2. The fusing dimension created by a fuse operation (see Section 4 ) must always precede any unfused dimensions . Also note that reorder can also have the following overloaded form: schedule . reorder ( order = ( j , k , i )) This form is better suited for use with parameters (see Section 9 ). split # Splits dimension i into equally-sized parts, orients those parts along a new dimension ii, and stacks those parts along dimension i ii = schedule . split ( i , size ) From the iteration space point-of-view, the split transformation takes a dimension i and a size , modifies i , and creates a new dimension ii . Assume that the original size of dimension i was n : The split transformation splits the dimension i into ceil(n/size) parts of size size , orients each of these parts along dimension ii , and stacks the ceil(n/size) parts along the dimension i . If the split size does not divide the dimension size, empty elements are added such that the split size does divide the dimension size. As a result of the split, the size of i becomes ceil(n/size) , the size of the new dimension ii equals size , and the iteration space remains rectilinear. In loop terms, ii = split(i, size) splits loop i into two loops: an inner loop ii and an outer loop, which inherits the original name i . Note that the outer loop always precedes the corresponding inner loop in the loop ordering. For example, starting from nest defined in Section 2 , we could write: schedule = nest . create_schedule () jj = schedule . split ( j , 3 ) The resulting iteration space has a shape of (3, 4, 3, 15) and corresponds to the following python code: for i in range ( 3 ): for j in range ( 0 , 12 , 3 ): # length 4, stride 3 for jj in range ( 3 ): for k in range ( 15 ): C [ i , j + jj ] += A [ i , k ] * B [ k , j + jj ] Note that loop j is no longer normalized (it has a stride of 3 rather than 1), which means that the nest is no longer a simple nest. As mentioned in the previous section, Nest objects always represent simple nests, but Schedule objects can represent more complex affine loop nests. Default schedule After split(j, 3) After performing a split, both the outer index and the inner index can be split again. For example, schedule = nest . create_schedule () jj = schedule . split ( j , 3 ) jjj = schedule . split ( j , 2 ) # split the outer index j again After the first split, the iteration space has the shape (3, 4, 3, 15). After the second split, the shape becomes (3, 2, 2, 3, 15). The transformed schedule corresponds to the following Python code: for i in range ( 3 ): for j in range ( 0 , 12 , 6 ): # length 2, stride 6 for jjj in range ( 0 , 6 , 3 ): # length 2, stride 3 for jj in range ( 3 ): for k in range ( 15 ): C [ i , j + jj + jjj ] += A [ i , k ] * B [ k , j + jj + jjj ] The split does not necessarily need to divide the dimension size. For example, consider the following code: schedule = nest . create_schedule () jj = schedule . split ( j , 5 ) # original size of dimension j was 12 From the iteration space point-of-view, this code splits dimension j into three parts of size 5, where the last part is padded with empty (no-op) elements. Before the transformation, the iteration space shape is (3, 12, 15), and after the transformation, the shape is (3, 3, 5, 15) (so, 135 empty elements were added). Default schedule (no-op elements in blue) After split(j, 5) In loop form, the transformed iteration space corresponds to the following Python code: for i in range ( 3 ): for j in range ( 0 , 12 , 5 ): for jj in range ( 5 ): for k in range ( 15 ): if j + jj < 12 C [ i , j + jj ] += A [ i , k ] * B [ k , j + jj ] Note that Accera optimizes away costly if statements by unswitching the loops, which results in code that looks more like this: for i in range ( 3 ): for j in range ( 0 , 10 , 5 ): for jj in range ( 5 ): for k in range ( 15 ): C [ i , j + jj ] += A [ i , k ] * B [ k , j + jj ] # loop unswitching: handle the last iteration of the j loop separately for j in range ( 10 , 12 ): for k in range ( 15 ): C [ i , j ] += A [ i , k ] * B [ k , j ] Meaningless splits Next, we will describe Accera\u2019s behavior in a few degenerate cases. If the split size equals the dimension size, the transformation simply renames the split dimension. For example, schedule = nest . create_schedule () jj = schedule . split ( j , 12 ) # original size of dimension j was 12 After the split, the size of j becomes 1 and the size of jj is 12 . The new shape of the iteration space is (3, 1, 12, 15). The dimension j becomes meaningless and therefore the schedule is basically unchanged. If the split size exceeds the dimension size, Accera will treat it as if the split size doesn't divide the dimension size. This special case is handled by adding empty elements. For example, schedule = nest . create_schedule () jj = schedule . split ( j , 13 ) # original size of dimension j was 12 After the split, the size of j becomes 1 and the size of jj , 13. The new shape of the iteration space is (3, 1, 13, 15), which means that 45 empty elements were added. These empty elements are removed during code generation, which means that the schedule is basically unchanged. Finally, note that jj = schedule.split(j, 1) simply adds a meaningless new dimension jj of size 1, and again, the schedule is unchanged. Convenience syntax: tile The tile transformation is a convenience syntax and does not provide any unique functionality. Consider the following code schedule = nest . create_schedule () jj , kk = schedule . tile ({ j : 2 , k : 3 }) The tile transformation above is shorthand for the following sequence of transformations: jj = schedule . split ( j , 2 ) kk = schedule . split ( k , 3 ) It will result in a sequence of indices that are ordered as: (i, j, jj, k, kk) In other words, the tile transformation takes a tuple of indices and a tuple of sizes, splitting each index by the corresponding size. The indices involved in the split are then ordered such that each of the outer indices (parent index) precedes its inner indices (child index). On the other hand, indices that did not participate in the transformation retain their relative positions. skew # Skew dimension i with respect to dimension j. schedule . skew ( i , j ) The skew transformation is the easiest to explain for a two-dimensional iteration space of shape (N, M) . Skewing dimension i (the row dimension) with respect to j (the column dimension) modifies the iteration space column-by-column: column j gets j empty elements added to its start and M-j-1 empty elements to its end. As a result, each column grows from size N to size N+M-1 . Geometrically, the original iteration space elements take the form of a 45-degree parallelogram, embedded within a bounding rectangle of shape (N+M-1, M) . The element that used to be at coordinate (i, j) moves to coordinate (i+j, j) . Similarly, skewing j with respect to i adds empty elements at the beginning and end of each row, resulting in an iteration space of shape (N, N+M-1) . In higher dimensions, we simply apply the two-dimensional skew transformation independently to each two-dimensional slice along the two specified dimensions. To demonstrate the importance of this transformation, consider convolving a 10-element vector with a 3-element filter. The loop logic for this operation is defined as follows: import accera as acc N = 10 # input size K = 3 # filter size M = N - K + 1 # output size = 8 A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( N ,)) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( K ,)) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( M ,)) nest = acc . Nest ( shape = ( M , K )) i , j = nest . get_indices () @nest . iteration_logic def _ (): C [ i ] += A [ i + j ] * B [ j ] schedule = nest . create_schedule () schedule corresponds to an iteration space of shape (8,3), where the first dimension corresponds to the 8 elements of the output vector. This schedule calculates the outputs one by one: first C[0] , then C[1] , etc. Here is the equivalent Python code: for i in range ( 8 ): for j in range ( 3 ): C [ i ] += A [ i + j ] * B [ j ] Now, say that we apply the skew transformation as follows: schedule . skew ( i , j ) This transformation results in an iteration space of shape (10, 3), where the first dimension corresponds to the 10 elements of the input. This transformed schedule processes the input elements one-by-one: it extracts all the information from A[0] ( A[0] is only used in the calculation of C[0] ), then moves on to A[1] (which contributes to both C[0] and C[1] ), and so on. In this example, the default schedule achieves memory locality with respect to array C , whereas the skewed schedule achieves memory locality with respect to array A . In loop form, the transformed iteration space corresponds to the following Python code: for i in range ( 10 ): for j in range ( 3 ): if ( i - j ) >= 0 and ( i - j ) < 8 : C [ i - j ] += A [ i ] * B [ j ] Behind the scenes, unswitching the loops results in code that looks more like this: # triangle of height 2, width 3 for j in range ( 1 ): C [ 0 - j ] += A [ 0 ] * B [ j ] for j in range ( 2 ): C [ 1 - j ] += A [ 1 ] * B [ j ] # rectangle of shape (6, 3) for i in range ( 2 , 8 ): for j in range ( 3 ): C [ i - j ] += A [ i ] * B [ j ] # upside-down triangle of height 2, width 3 for j in range ( 2 ): C [ 6 + j ] += A [ 8 ] * B [ 2 - j ] for j in range ( 1 ): C [ 7 + j ] += A [ 9 ] * B [ 2 - j ] Finally, note that some loops have small sizes that can be replaced by unrolls. To enable the unrolling of these small loops, we can use this optional parameter: schedule . skew ( i , j , unroll_loops_smaller_than = 3 ) This will unroll all loops that are smaller than 3, which include the range(2) and range(1) loops in the example above. pad # Adds empty elements to the beginning of dimension i. schedule . pad ( i , size ) The pad transformation pads the beginning of dimension i with empty elements. This operation is meaningless by itself, but can be useful when used with splitting or fusing. Order-invariant schedules and safety A schedule is order-invariant if its underlying logic doesn't depend on the execution order of its iterations. For example, schedules created from a single Nest (via create_schedule() ) are order-invariant. All of the schedules discussed so far have been order-invariant. A schedule is safe if its underlying logic is guaranteed to remain intact regardless of the applied transformations. Not all schedules are safe, but order-invariant schedules are. This is because the transformations introduced in this section only change the execution order of iterations without adding or removing any work. In Section 4 , we introduce fused schedules, which are not order-invariant, but may still be safe.","title":"03 Schedules"},{"location":"Manual/03%20Schedules/#section-3-schedules","text":"We begin with nest from Section 2 which captures the logic of matrix-matrix multiplication. We use nest to create a Schedule that controls the execution order of the nest's iterations. Schedules are target-independent in the sense that the same schedule can be used to emit code for multiple target platforms. We create a default schedule as follows: schedule = nest . create_schedule () The default schedule is equivalent to the following straightforward for-loop version of the loop nest: for i in range ( 3 ): for j in range ( 12 ): for k in range ( 15 ): C [ i , j ] += A [ i , k ] * B [ k , j ] In other words, each of the logical pseudo-code loops in nest becomes an actual for-loop in the default schedule. We can now transform this schedule in various ways. However, these transformations do not change the underlying logic defined in nest and merely change the order of the loop iterations. We can even generate as many independent schedules as we want by calling nest.create_schedule() .","title":"Section 3: Schedules"},{"location":"Manual/03%20Schedules/#iteration-spaces-a-geometric-representation-of-schedules","text":"In the Accera programming model, a schedule is geometrically interpreted as a multi-dimensional discrete hypercube called the iteration space of the nest. The elements of the iteration space represent the individual iterations of the loop nest. Initially, the dimensions of the iteration space correspond to the logical loops defined in nest . For example, the default iteration space for the matrix-matrix multiplication nest forms a three-dimensional discrete hypercube, whose shape is (3, 12, 15): The (3, 12, 15) iteration space. The arrows labelled 1, 2, and 3 indicate the dimension order and direction.","title":"Iteration spaces: a geometric representation of schedules"},{"location":"Manual/03%20Schedules/#how-does-an-iteration-space-imply-an-order-over-the-iterations","text":"The dimensions of the iteration space are ordered, and this order corresponds to the original order of the logical loops in nest by default. In fact, the order over the dimensions induces a lexicographic sequence over the individual elements of the iteration space. Video showing sequence of iterations for the (3, 12, 15) iteration space. This geometric interpretation of schedules helps us visualize how different transformations modify them. While some transformations merely rearrange the elements of the iteration space, others increase its dimensions, and some even pad the space with empty (no-op) elements. The transformed iteration space defines a new lexicographic order over the individual iterations. Comment: It is important not to confuse arrays, like A , B , C , with iteration spaces, like schedule . A possible source of confusion could be that both arrays and iteration spaces have a multidimensional rectilinear structure (i.e., they both look like hypercubes). However, arrays and iteration spaces are fundamentally different. Arrays are data structures whose elements are scalars. Iteration spaces are abstract geometric representations of schedules and their elements represent individual iterations of a loop nest. Transformations apply to iteration spaces, not to arrays. Comment: Accera's geometric interpretation of schedules resembles the iteration domain polyhedron , which is the cornerstone of the polyhedral model of compiler optimization. However, unlike polyhedrons, Accera iteration spaces are not embedded in a continuous space and cannot be manipulated by algebraic transformations. Accera iteration spaces always remain rectilinear and are inherently discrete objects.","title":"How does an iteration space imply an order over the iterations?"},{"location":"Manual/03%20Schedules/#iteration-space-slices","text":"Iteration space slices is an abstract concept that affects different aspects of the Accera programming model. Since the iteration space dimensions are ordered, each element of the iteration space can be identified by a vector of coordinates. For example, the vector (1, 6, 7) identifies the iteration at position 1 along the first dimension, position 6 along the second dimension, and position 7 along the third dimension. If one or more coordinates are replaced with the wildcard symbol * , we get an iteration space slice , which is a set of iterations obtained by replacing the wildcard with all possible values. For example, (*, *, 2) represents a slice containing all the elements with 2 as their last coordinate. The dimension of a slice equals the number of wildcards in its definition. The (3, 12, 15) iteration space. Highlighted elements belong to the (*, *, 2) slice. Iteration space slices in four dimensions, denoted by indices ( i , j , jj , k ): (1, *, *, *) (*, *, *, 3) (2, *, 0, *)","title":"Iteration space slices"},{"location":"Manual/03%20Schedules/#loops-indices-and-dimensions","text":"When we defined nest , we used variables such as i , j , and k to name the loops in the loop-nest. When we described the default schedule using equivalent for-loops, i , j , and k became the index variables of those loops. Now, when we represent a schedule as an iteration space, these variables are used as the names of the corresponding iteration space dimensions. From here on, we move seamlessly between these different representations and use the terms loop , index , and dimension interchangeably.","title":"Loops, indices, and dimensions"},{"location":"Manual/03%20Schedules/#schedule-transformations","text":"Iteration space transformations change the shape of the iteration space, possibly by adding dimensions or padding the space with empty elements. The iterations space always retains its rectilinear (hypercube) shape. In some cases, Accera transformations must pad the iteration space with empty elements to avoid reaching a jagged iteration space structure.","title":"Schedule transformations"},{"location":"Manual/03%20Schedules/#reorder","text":"# Reorder the indices. schedule . reorder ( k , i , j ) The reorder transformation sets the order of indices in the schedule. From the iteration space point-of-view, reorder performs a pivot rotation of the iteration space, which orients its dimensions in a specified order. Since the iteration space elements are executed in lexicographic order, pivoting the iteration space is equivalent to reordering the loops. For example, we can write: schedule . reorder ( j , k , i ) After this transformation, schedule becomes equivalent to: for j in range ( 12 ): for k in range ( 15 ): for i in range ( 3 ): C [ i , j ] += A [ i , k ] * B [ k , j ] Default schedule After reorder(j, k, i)","title":"reorder"},{"location":"Manual/03%20Schedules/#invalid-orders","text":"Some orders are not allowed. Describing these restrictions in full will require concepts that are yet to be introduced. Therefore, we are stating these restrictions here and will discuss them later in the upcoming sections. The restrictions are: 1. The inner dimension created by a split transformation (see below) must be ordered later than its corresponding outer dimension . 2. The fusing dimension created by a fuse operation (see Section 4 ) must always precede any unfused dimensions . Also note that reorder can also have the following overloaded form: schedule . reorder ( order = ( j , k , i )) This form is better suited for use with parameters (see Section 9 ).","title":"Invalid orders"},{"location":"Manual/03%20Schedules/#split","text":"# Splits dimension i into equally-sized parts, orients those parts along a new dimension ii, and stacks those parts along dimension i ii = schedule . split ( i , size ) From the iteration space point-of-view, the split transformation takes a dimension i and a size , modifies i , and creates a new dimension ii . Assume that the original size of dimension i was n : The split transformation splits the dimension i into ceil(n/size) parts of size size , orients each of these parts along dimension ii , and stacks the ceil(n/size) parts along the dimension i . If the split size does not divide the dimension size, empty elements are added such that the split size does divide the dimension size. As a result of the split, the size of i becomes ceil(n/size) , the size of the new dimension ii equals size , and the iteration space remains rectilinear. In loop terms, ii = split(i, size) splits loop i into two loops: an inner loop ii and an outer loop, which inherits the original name i . Note that the outer loop always precedes the corresponding inner loop in the loop ordering. For example, starting from nest defined in Section 2 , we could write: schedule = nest . create_schedule () jj = schedule . split ( j , 3 ) The resulting iteration space has a shape of (3, 4, 3, 15) and corresponds to the following python code: for i in range ( 3 ): for j in range ( 0 , 12 , 3 ): # length 4, stride 3 for jj in range ( 3 ): for k in range ( 15 ): C [ i , j + jj ] += A [ i , k ] * B [ k , j + jj ] Note that loop j is no longer normalized (it has a stride of 3 rather than 1), which means that the nest is no longer a simple nest. As mentioned in the previous section, Nest objects always represent simple nests, but Schedule objects can represent more complex affine loop nests. Default schedule After split(j, 3) After performing a split, both the outer index and the inner index can be split again. For example, schedule = nest . create_schedule () jj = schedule . split ( j , 3 ) jjj = schedule . split ( j , 2 ) # split the outer index j again After the first split, the iteration space has the shape (3, 4, 3, 15). After the second split, the shape becomes (3, 2, 2, 3, 15). The transformed schedule corresponds to the following Python code: for i in range ( 3 ): for j in range ( 0 , 12 , 6 ): # length 2, stride 6 for jjj in range ( 0 , 6 , 3 ): # length 2, stride 3 for jj in range ( 3 ): for k in range ( 15 ): C [ i , j + jj + jjj ] += A [ i , k ] * B [ k , j + jj + jjj ] The split does not necessarily need to divide the dimension size. For example, consider the following code: schedule = nest . create_schedule () jj = schedule . split ( j , 5 ) # original size of dimension j was 12 From the iteration space point-of-view, this code splits dimension j into three parts of size 5, where the last part is padded with empty (no-op) elements. Before the transformation, the iteration space shape is (3, 12, 15), and after the transformation, the shape is (3, 3, 5, 15) (so, 135 empty elements were added). Default schedule (no-op elements in blue) After split(j, 5) In loop form, the transformed iteration space corresponds to the following Python code: for i in range ( 3 ): for j in range ( 0 , 12 , 5 ): for jj in range ( 5 ): for k in range ( 15 ): if j + jj < 12 C [ i , j + jj ] += A [ i , k ] * B [ k , j + jj ] Note that Accera optimizes away costly if statements by unswitching the loops, which results in code that looks more like this: for i in range ( 3 ): for j in range ( 0 , 10 , 5 ): for jj in range ( 5 ): for k in range ( 15 ): C [ i , j + jj ] += A [ i , k ] * B [ k , j + jj ] # loop unswitching: handle the last iteration of the j loop separately for j in range ( 10 , 12 ): for k in range ( 15 ): C [ i , j ] += A [ i , k ] * B [ k , j ]","title":"split"},{"location":"Manual/03%20Schedules/#meaningless-splits","text":"Next, we will describe Accera\u2019s behavior in a few degenerate cases. If the split size equals the dimension size, the transformation simply renames the split dimension. For example, schedule = nest . create_schedule () jj = schedule . split ( j , 12 ) # original size of dimension j was 12 After the split, the size of j becomes 1 and the size of jj is 12 . The new shape of the iteration space is (3, 1, 12, 15). The dimension j becomes meaningless and therefore the schedule is basically unchanged. If the split size exceeds the dimension size, Accera will treat it as if the split size doesn't divide the dimension size. This special case is handled by adding empty elements. For example, schedule = nest . create_schedule () jj = schedule . split ( j , 13 ) # original size of dimension j was 12 After the split, the size of j becomes 1 and the size of jj , 13. The new shape of the iteration space is (3, 1, 13, 15), which means that 45 empty elements were added. These empty elements are removed during code generation, which means that the schedule is basically unchanged. Finally, note that jj = schedule.split(j, 1) simply adds a meaningless new dimension jj of size 1, and again, the schedule is unchanged.","title":"Meaningless splits"},{"location":"Manual/03%20Schedules/#convenience-syntax-tile","text":"The tile transformation is a convenience syntax and does not provide any unique functionality. Consider the following code schedule = nest . create_schedule () jj , kk = schedule . tile ({ j : 2 , k : 3 }) The tile transformation above is shorthand for the following sequence of transformations: jj = schedule . split ( j , 2 ) kk = schedule . split ( k , 3 ) It will result in a sequence of indices that are ordered as: (i, j, jj, k, kk) In other words, the tile transformation takes a tuple of indices and a tuple of sizes, splitting each index by the corresponding size. The indices involved in the split are then ordered such that each of the outer indices (parent index) precedes its inner indices (child index). On the other hand, indices that did not participate in the transformation retain their relative positions.","title":"Convenience syntax: tile"},{"location":"Manual/03%20Schedules/#skew","text":"# Skew dimension i with respect to dimension j. schedule . skew ( i , j ) The skew transformation is the easiest to explain for a two-dimensional iteration space of shape (N, M) . Skewing dimension i (the row dimension) with respect to j (the column dimension) modifies the iteration space column-by-column: column j gets j empty elements added to its start and M-j-1 empty elements to its end. As a result, each column grows from size N to size N+M-1 . Geometrically, the original iteration space elements take the form of a 45-degree parallelogram, embedded within a bounding rectangle of shape (N+M-1, M) . The element that used to be at coordinate (i, j) moves to coordinate (i+j, j) . Similarly, skewing j with respect to i adds empty elements at the beginning and end of each row, resulting in an iteration space of shape (N, N+M-1) . In higher dimensions, we simply apply the two-dimensional skew transformation independently to each two-dimensional slice along the two specified dimensions. To demonstrate the importance of this transformation, consider convolving a 10-element vector with a 3-element filter. The loop logic for this operation is defined as follows: import accera as acc N = 10 # input size K = 3 # filter size M = N - K + 1 # output size = 8 A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( N ,)) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( K ,)) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( M ,)) nest = acc . Nest ( shape = ( M , K )) i , j = nest . get_indices () @nest . iteration_logic def _ (): C [ i ] += A [ i + j ] * B [ j ] schedule = nest . create_schedule () schedule corresponds to an iteration space of shape (8,3), where the first dimension corresponds to the 8 elements of the output vector. This schedule calculates the outputs one by one: first C[0] , then C[1] , etc. Here is the equivalent Python code: for i in range ( 8 ): for j in range ( 3 ): C [ i ] += A [ i + j ] * B [ j ] Now, say that we apply the skew transformation as follows: schedule . skew ( i , j ) This transformation results in an iteration space of shape (10, 3), where the first dimension corresponds to the 10 elements of the input. This transformed schedule processes the input elements one-by-one: it extracts all the information from A[0] ( A[0] is only used in the calculation of C[0] ), then moves on to A[1] (which contributes to both C[0] and C[1] ), and so on. In this example, the default schedule achieves memory locality with respect to array C , whereas the skewed schedule achieves memory locality with respect to array A . In loop form, the transformed iteration space corresponds to the following Python code: for i in range ( 10 ): for j in range ( 3 ): if ( i - j ) >= 0 and ( i - j ) < 8 : C [ i - j ] += A [ i ] * B [ j ] Behind the scenes, unswitching the loops results in code that looks more like this: # triangle of height 2, width 3 for j in range ( 1 ): C [ 0 - j ] += A [ 0 ] * B [ j ] for j in range ( 2 ): C [ 1 - j ] += A [ 1 ] * B [ j ] # rectangle of shape (6, 3) for i in range ( 2 , 8 ): for j in range ( 3 ): C [ i - j ] += A [ i ] * B [ j ] # upside-down triangle of height 2, width 3 for j in range ( 2 ): C [ 6 + j ] += A [ 8 ] * B [ 2 - j ] for j in range ( 1 ): C [ 7 + j ] += A [ 9 ] * B [ 2 - j ] Finally, note that some loops have small sizes that can be replaced by unrolls. To enable the unrolling of these small loops, we can use this optional parameter: schedule . skew ( i , j , unroll_loops_smaller_than = 3 ) This will unroll all loops that are smaller than 3, which include the range(2) and range(1) loops in the example above.","title":"skew"},{"location":"Manual/03%20Schedules/#pad","text":"# Adds empty elements to the beginning of dimension i. schedule . pad ( i , size ) The pad transformation pads the beginning of dimension i with empty elements. This operation is meaningless by itself, but can be useful when used with splitting or fusing.","title":"pad"},{"location":"Manual/03%20Schedules/#order-invariant-schedules-and-safety","text":"A schedule is order-invariant if its underlying logic doesn't depend on the execution order of its iterations. For example, schedules created from a single Nest (via create_schedule() ) are order-invariant. All of the schedules discussed so far have been order-invariant. A schedule is safe if its underlying logic is guaranteed to remain intact regardless of the applied transformations. Not all schedules are safe, but order-invariant schedules are. This is because the transformations introduced in this section only change the execution order of iterations without adding or removing any work. In Section 4 , we introduce fused schedules, which are not order-invariant, but may still be safe.","title":"Order-invariant schedules and safety"},{"location":"Manual/04%20Fusing/","text":"Section 4: Fusing With fuse operation, multiple schedules can be combined into a single schedule representing the union of the work in the original schedules. These fused schedules can be transformed by any of the transformations presented in Section 3 . Full fusing import accera as acc # Fuse three schedules to create a fused schedule schedule = acc . fuse ( schedule0 , schedule1 , ... ) Full fusing is the most straightforward, where each dimension is fused with the corresponding dimension from other schedules. Full fusing of same-shaped iteration spaces First, consider the simplest case where we fuse schedules with identical iteration space shapes. This fusing assigns a new dimension called fusing dimension to the fused schedule schedule that does not exist in the original schedules. By default, the fusing dimension is the first dimension in the fused schedule. Its size is equal to the number of fused schedules. The slices along the fusing dimension contain a copy of schedule0 , schedule1 . The first slice along the fusing dimension contains a copy of schedule0 , the second slice contains a copy of schedule1 , and so on. Since the fusing dimension is the first dimension, the fused schedule is logically equivalent to fully executing schedule0 , followed by schedule1 , and so on. We apply additional transformations to the fused schedule to interleave the original schedules. Consider a scenario where we want first to shift and then scale each element of a matrix. In other words, we want to perform the equivalent of the below Python code: C = ( C + A ) * B If all three matrices are 10 by 10, one way to do this without fusing is to write: A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 10 , 10 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 10 , 10 )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( 10 , 10 )) # Create nest_simple and schedule_simple nest_simple = acc . Nest ( shape = ( 10 , 10 )) i , j = nest_simple . get_indices () @nest_simple . iteration_logic def _ (): C [ i , j ] = ( C [ i , j ] + A [ i , j ]) * B [ i , j ] schedule_simple = nest_simple . create_schedule () Note that each iteration in schedule_simple executes simultaneously on all three arrays. However, there can be a case where concurrent operation on these arrays creates excessive pressure on the computer\u2019s memory cache, resulting in lower performance. In such a case, simultaneous operation on two arrays instead of three has a computational advantage. Therefore, we may first want to compute C += A and then compute C *= B . Better yet, we may want to compute C in 2\u00d72 blocks. We first compute C[0:2, 0:2] += A[0:2, 0:2] . Subsequently, we compute C[0:2, 0:2] *= B[0:2, 0:2] . Finally, we move on to the next block and compute C[2:4, 0:2] += A[2:4, 0:2] , and so on. This way, fusing offers remarkable flexibility to explore all of these different execution possibilities. First, we define two separate nests, one for the C += A logic and one for the C *= B logic, and get their corresponding default schedules: # Create nest0 and schedule0 nest0 = acc . Nest ( shape = ( 10 , 10 )) i0 , j0 = nest0 . get_indices () @nest0 . iteration_logic def _ (): C [ i0 , j0 ] += A [ i0 , j0 ] schedule0 = nest0 . create_schedule () # Create nest1 and schedule1 nest1 = acc . Nest ( shape = ( 10 , 10 )) i1 , j1 = nest1 . get_indices () @nest1 . iteration_logic def _ (): C [ i1 , j1 ] *= B [ i1 , j1 ] schedule1 = nest1 . create_schedule () Before fusing, both schedule0 and schedule1 have a shape (10, 10). Now, let\u2019s fuse them: # Create a fused schedule schedule = acc . fuse ( schedule0 , schedule1 ) f , i , j = schedule . get_indices () Fusing creates a new fused schedule schedule with a shape (2, 10, 10). It does not change schedule0 and schedule1 . The first dimension in schedule is the so-called fusing dimension f . Its slice (0, *, *) contains a copy of schedule0 , and its slice (1, *, *) contains a copy of schedule1 . Before fusing After fuse(schedule0, schedule1) In loop form, schedule is now equivalent to the following Python code: # f = 0 for i in range ( 10 ): for j in range ( 10 ): C [ i , j ] += A [ i , j ] # f = 1 for i in range ( 10 ): for j in range ( 10 ): C [ i , j ] *= B [ i , j ] Not much has happened until now since executing schedule as-is is equivalent to executing schedule0 followed by schedule1 . However, this can be changed by transforming the fused schedule. For example, we can recover schedule_simple by reordering the indices as follows: schedule . reorder ( i , j , f ) Before reorder(i, j, f) After reorder(i, j, f) The fusing dimension moves from the first position to the last position. Now, schedule is equivalent to the following Python code: for i in range ( 10 ): for j in range ( 10 ): # f = 0 C [ i , j ] += A [ i , j ] # f = 1 C [ i , j ] *= B [ i , j ] Resulting iteration sequence for C = (C + A) * B . (White elements represent C + A ; purple elements are C * B ) Tiling Recall that we discussed computing the output block-by-block: first computing C[0:2, 0:2] += A[0:2, 0:2] , then computing C[0:2, 0:2] *= B[0:2, 0:2] , and so on. This can be achieved with the following sequence of transformations: ii , jj = schedule . tile ({ i : 2 , j : 2 }) schedule . reorder ( i , j , f , ii , jj ) The resulting schedule is equivalent to the following Python code: for i in range ( 0 , 10 , 2 ): for j in range ( 0 , 10 , 2 ): # f = 0 for ii in range ( 2 ): for jj in range ( 2 ): C [ i + ii , j + jj ] += A [ i + ii , j + jj ] # f = 1 for ii in range ( 2 ): for jj in range ( 2 ): C [ i + ii , j + jj ] *= B [ i + ii , j + jj ] Constraints of Fusing Dimension The fusing dimension comes with certain constraints that are discussed from the safety perspective with examples. Constraint 1: the fusing dimension is executed sequentially Unlike other dimensions that allow parallelization, vectorization, or tensorization (see Section 7 ), none of these operations can be applied to the fusing dimension. The fusing dimension must be executed sequentially. This constraint enables the safety guarantee discussed below. Safety Before applying any subsequent transformations, the fused schedule is always logically equal to executing the original schedules sequentially. However, is it safe? Recall that a schedule is considered safe if the underlying logic is guaranteed to be unchanged regardless of the applied transformation. The safety of a fused schedule depends on circumstances that may break logic equivalence: Accera preserves the order of the fused schedules for each value of the fused dimensions , regardless of how the fused schedule is transformed. For example, in the example above, the fused dimensions are i and j . Therefore, for any concrete value of i and j , the corresponding operation from schedule0 is guaranteed to execute before the corresponding operation from schedule1 , regardless of how the fused schedule is transformed. More specifically, for each i and j , the operation C[i, j] += A[i, j] is guaranteed to execute before the operation C[i, j] *= B[i, j] , no matter how we transform the fused schedule. Since those are the only operations that interact with C[i,j] , the Accera guarantee is sufficient, and we can claim that the fused schedule is safe. With this assurance, the programmer can apply any sequence of transformations without worrying about the correctness of the resulting implementation. However, not every fusing operation creates a safe schedule. For example, consider a scenario where we fused schedule0 and schedule1 differently: # Reorder schedule1 before fusing schedule1 . reorder ( j1 , i1 ) # Fuse schedule0 with the reordered schedule1 schedule_t = acc . fuse ( schedule0 , schedule1 ) f , a , b = schedule_t . get_indices () In this unnatural example, i0 and j1 are fused and named a . Similarly, i1 and j0 are fused and named b . As mentioned above, Accera guarantees that, for each value of a and b , the operation C[a, b] += A[a, b] is executed before C[b, a] *= B[b, a] . The fusing operation itself preserves the logical equivalence. However, the underlying logic is changed if we transform the fused schedule as follows: schedule_t . reorder ( a , b , f ) To understand this change in the logic, note that the resulting schedule is equivalent to the following Python code: for a in range ( 10 ): for b in range ( 10 ): C [ a , b ] += A [ a , b ] C [ b , a ] *= B [ b , a ] The above code sets C[1,0] to C[1,0] * B[1,0] + A[1,0] , whereas the original fused logic set C[1,0] to (C[1,0] + A[1,0]) * B[1,0] . In this case, we can conclude that schedule_t is definitely not safe. If the programmer decides to create an unsafe schedule, they take upon themselves the responsibility of maintaining logical equivalence. Fusing iteration spaces with different shapes If the iterations spaces have different shapes, Accera matches their shapes by padding them appropriately with empty cells. Partial fusing Instead of fusing all the dimensions, we may want to fuse a subset of dimensions, leaving the rest unfused. To fuse the first s dimensions, we use the syntax: # Fuse the first s dimensions of three schedules schedule = acc . fuse (( schedule0 , schedule1 , ... ), partial = s ) The order of the dimensions in the fused schedule is as follows: first the fusing dimension f , then the fused dimensions s , followed by the unfused dimensions of schedule0 , schedule1 , and so on. We can easily calculate the number of dimensions in the fused schedule. For example, if we fuse the first s dimensions of a d0 -dimensional space schedule0 and a d1 -dimensional space schedule1 , the fused iteration space will have s fused dimensions, d0 + d1 - 2s unfused dimensions, and the special fusing dimension f , for a total of d0 + d1 - s + 1 dimensions. The fuse operation uses padding to ensure that the fused iteration space is not jagged in any direction. For example, say that we partially fuse the first 2 dimensions of schedule0 , which is 4-dimensional, and schedule1 , which is 3-dimensional: schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k , l , m = schedule . get_indices () The first dimension is the fusing dimensions f of size 2. Next comes the fused dimensions i and j , followed by the unfused dimensions k and l from schedule0 and m from schedule1 . The slice (0, *, *, *, *, 0) contains a copy of schedule0 , the slice (1, *, *, 0, 0, *) contains a copy of schedule1 , and the rest of schedule is padded with empty elements. Note that full fusing is a special case of partial fusing, where s is the larger of the dimensions of schedule0 and schedule1 . Constraint 2: the fusing dimension always precedes unfused dimensions Another constraint introduced by partial fusing is that the fusing dimension must precede all of the unfused dimensions in its dimension order. This constraint applies to dimensions derived from the fusing dimension and the unfused dimensions via splitting. Safety The safety guarantees for partial fusing are a natural extension of the guarantees for full fusing. For each value of the fused dimensions , Accera preserves the fused schedules' order regardless of how the fused schedule is transformed. In other words, for each concrete value of fused dimensions, all the corresponding work in schedule0 (across all of its unfused dimensions) is performed before the corresponding work in schedule1 (across all of its unfused dimensions). This remains true no matter how we transform the fused schedule. While fusing, the programmer needs to consider if this property implies safety. The below examples shows how this can be done. Partial fusing example: fully-connected neural layer with activation Consider applying an element-wise operation, such as the ReLU function of AI, to the result of a matrix-matrix multiplication. This is called a fully connected layer with a ReLU activation in the language of neural networks. The function relu(x) is simply max(x,0) . Imagine that we have an element-wise operator relu , and we want to implement the equivalent Python code: C = relu ( C + A @ B ) Here, A has a shape of (8, 4), B has a shape of (4, 8), and C has a shape of (8, 8). Let\u2019s now define two nests, one for C += A @ B and the other for C = relu(C) , and obtain their corresponding default schedules: # Create nest0 and schedule0 nest0 = acc . Nest ( shape = ( 8 , 8 , 4 )) i0 , j0 , k0 = nest0 . get_indices () # nest0 performs C += A @ B @nest0 . iteration_logic def _ (): C [ i0 , j0 ] += A [ i0 , k0 ] * B [ k0 , j0 ] schedule0 = nest0 . create_schedule () # Create nest1 and schedule1 nest1 = acc . Nest ( shape = ( 8 , 8 )) i1 , j1 = nest1 . get_indices () # nest1 performs C = relu(C) @nest1 . iteration_logic def _ (): C [ i1 , j1 ] = acc . max ( C [ i1 , j1 ], 0 ) schedule1 = nest1 . create_schedule () In schedule0 and schedule1 , the first dimension represents the rows of C and the second dimension represents the columns of C . Additionally, schedule0 has a third dimension that schedule1 does not have. Therefore, we fuse the first two dimensions of the iteration spaces and leave the third dimension of schedule0 unfused. schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k0 = schedule . get_indices () The fused iteration space schedule has a shape of (2, 8, 8, 4). Its slice (0, *, *, *) contains a copy of schedule0 , the slice (1, *, *, 0) contains a copy of schedule1 , and the rest of its elements are padded. Note that the code above overwrites the index k0 , which initially was an index of schedule0 . However, now it corresponds to the unfused index in schedule . Note that the name k0 is a stylistic choice, we could have chosen a different name. Before fusing After fuse((schedule0, schedule1), partial=2) (padded elements in blue) Safety Is schedule safe? Recall that for each value of i and j , Accera guarantees that the corresponding work in schedule0 ( C[i,j] += A[i,k0] * B[k0,j] for all values of k0 ) is executed before the corresponding work in schedule1 ( C[i,j] = max(C[i,j], 0) ), and this holds regardless of how the fused schedule is transformed. Since these are the only operations that touch C[i,j] and the ReLU operation is always executed last, this warrants that schedule is safe. Therefore, we can focus all of our attention on optimizing performance without worrying about correctness from this point onwards. Executing schedule as-is is equivalent to executing schedule0 in its entirety, followed by executing schedule1 . Suppose we want to interleave the two schedules and perform relu immediately after calculating each element of the matrix product. In that case, we reorder the dimensions such that i and j preceded f : schedule . reorder ( i , j , f , k0 ) Before reorder(i, j, f, k0) After reorder(i, j, f, k0) The resulting schedule is now equivalent to the following Python code: for i in range ( 16 ): for j in range ( 10 ): # f = 0 for k0 in range ( 11 ): C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] # f = 1 C [ i , j ] = max ( C [ i , j ], 0 ) Iteration sequence for C = relu(C + A @ B) . (White elements represent C + A @ B ; purple elements are relu(C) ; blue elements are padding.) Partial fusing example: multiplying three matrices Consider fusing two matrix-matrix multiplications to get matrix-matrix-matrix multiplication. Specifically, say that our goal is to calculate the equivalent of the following Python code: E += A @ B @ D Where A has a shape (4, 5), B (5, 6), D (6, 10), and E (4, 10). We start by defining the arrays. In addition to A , B , D , and E , we define a temporary array C to store the intermediate result of A@B . A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 4 , 5 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 5 , 6 )) C = acc . Array ( role = acc . Array . Role . TEMP , shape = ( 4 , 6 )) D = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 6 , 10 )) E = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( 4 , 10 )) Note that C has the role of TEMP . Temporary arrays are mutable and initialized with zeros. Moreover, these arrays are logical objects that may not exist in memory during the entire computation. Next, define a simple nest to compute C += A @ B and another simple nest to compute E += C @ D . # Create nest0 and schedule0 for C = A @ B nest0 = acc . Nest ( shape = ( 4 , 6 , 5 )) i0 , j0 , k0 = nest0 . get_indices () @nest0 . iteration_logic def _ (): C [ i0 , j0 ] += A [ i0 , k0 ] * B [ k0 , j0 ] schedule0 = nest0 . create_schedule () # Create nest1 and schedule1 E += C @ D nest1 = acc . Nest ( shape = ( 4 , 10 , 6 )) i1 , j1 , k1 = nest1 . get_indices () @nest1 . iteration_logic def _ (): E [ i1 , j1 ] += C [ i1 , k1 ] * D [ k1 , j1 ] schedule1 = nest1 . create_schedule () The temporary array C stores the output of schedule0 , which is then used as one of the inputs of schedule1 . Dimensions i0 and j0 correspond to the rows and columns of C in schedule0 . Similarly, dimensions i1 and k1 correspond to the rows and columns of C in schedule1 . Therefore, we fuse i0 with i1 and j0 with k1 . We need to correctly line up the dimensions of the two iteration spaces and perform partial fusing. schedule1 . reorder ( i1 , k1 , j1 ) schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k0 , j1 = schedule . get_indices () Before reorder(i1, k1, j1) After reorder(i1, k1, j1) The fused iteration space has a shape of (2, 4, 6, 5, 10). f is the fusing dimension, i is the result of fusing i0 and i1 , and j is the result of fusing j0 and k1 . On the other hand, k0 is the unfused dimension from schedule0 , and j1 is the unfused dimension from schedule1 . The slice (0, *, *, *, 0) contains a copy of schedule0 and the slice (1, *, *, 0, *) contains a copy of schedule1 . The rest of the iteration space is padded with empty elements. After fuse((schedule0, schedule1), partial=2) (White elements represent C += A @ B ; purple elements are E += C @ D ; blue elements are padding.) Safety Is schedule safe? Again, recall that for each value of i and j , Accera guarantees that all of the corresponding work in schedule0 ( C[i, j] += A[i, k0] * B[k0, j] for all values of k0 ) is executed before any of the corresponding work in schedule1 ( E[i, j1] += C[i, j] * D[j, j1] for all values of j1 ). In other words, each element of C is entirely computed before it is used. This confirms that the schedule is safe. Initially, the fused schedule is equivalent to the following Python code: # f = 0 for i in range ( 4 ): for j in range ( 6 ): for k0 in range ( 5 ): C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] # f = 1 for i in range ( 4 ): for j in range ( 6 ): for j1 in range ( 10 ): E [ i , j1 ] += C [ i , j ] * D [ j , j1 ] We can now manipulate the fused schedule in various ways. For example, we can do all the work to create one element of C and then immediately do all the work that uses this element before moving on to the next element. schedule . reorder ( i , j , f , k0 , j1 ) This schedule is equivalent to the following Python loops: for i in range ( 4 ): for j in range ( 6 ): for f in range ( 2 ): for k0 in range ( 5 ): for j1 in range ( 7 ): if f == 0 and j1 == 0 : # f = 0, create C[i, j] C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] if f == 1 and k0 == 0 : # f = 1, use C[i, j] E [ i , j1 ] += C [ i , j ] * D [ j , j1 ] The simplified loops after unswitching: for i in range ( 4 ): for j in range ( 6 ): # f = 0, create C[i, j] for k0 in range ( 5 ): C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] # f = 1, use C[i, j] for j1 in range ( 7 ): E [ i , j1 ] += C [ i , j ] * D [ j , j1 ] The advantage of this schedule is that only one element of C is active at any time in the computation. Accera can reuse the same memory location to store the active element of C instead of storing all of C in physical memory. After reorder(i, j, f, k0, j1) (White elements represent C += A @ B ; purple elements are E += C @ D ; blue elements are padding.) Tiling As a further optimization, we can compute a 2\u00d73 block of C . Do all the work that uses this block and then move on to the next block: ii , jj = schedule . tile ({ i : 2 , j : 3 }) schedule . reorder ( i , j , f , ii , jj , k0 , j1 ) This schedule is equivalent to the following Python code: for i in range ( 0 , 4 , 2 ): for j in range ( 0 , 6 , 3 ): # f = 0 for ii in range ( 2 ): for jj in range ( 3 ): for k0 in range ( 11 ): C [ i + ii , j + jj ] += A [ i + ii , k0 ] * B [ k0 , j + jj ] # f = 1 for ii in range ( 2 ): for jj in range ( 3 ): for j1 in range ( 7 ): E [ i + ii , j1 ] += C [ i + ii , j + jj ] * D [ j + jj , j1 ]","title":"04 Fusing"},{"location":"Manual/04%20Fusing/#section-4-fusing","text":"With fuse operation, multiple schedules can be combined into a single schedule representing the union of the work in the original schedules. These fused schedules can be transformed by any of the transformations presented in Section 3 .","title":"Section 4: Fusing"},{"location":"Manual/04%20Fusing/#full-fusing","text":"import accera as acc # Fuse three schedules to create a fused schedule schedule = acc . fuse ( schedule0 , schedule1 , ... ) Full fusing is the most straightforward, where each dimension is fused with the corresponding dimension from other schedules.","title":"Full fusing"},{"location":"Manual/04%20Fusing/#full-fusing-of-same-shaped-iteration-spaces","text":"First, consider the simplest case where we fuse schedules with identical iteration space shapes. This fusing assigns a new dimension called fusing dimension to the fused schedule schedule that does not exist in the original schedules. By default, the fusing dimension is the first dimension in the fused schedule. Its size is equal to the number of fused schedules. The slices along the fusing dimension contain a copy of schedule0 , schedule1 . The first slice along the fusing dimension contains a copy of schedule0 , the second slice contains a copy of schedule1 , and so on. Since the fusing dimension is the first dimension, the fused schedule is logically equivalent to fully executing schedule0 , followed by schedule1 , and so on. We apply additional transformations to the fused schedule to interleave the original schedules. Consider a scenario where we want first to shift and then scale each element of a matrix. In other words, we want to perform the equivalent of the below Python code: C = ( C + A ) * B If all three matrices are 10 by 10, one way to do this without fusing is to write: A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 10 , 10 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 10 , 10 )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( 10 , 10 )) # Create nest_simple and schedule_simple nest_simple = acc . Nest ( shape = ( 10 , 10 )) i , j = nest_simple . get_indices () @nest_simple . iteration_logic def _ (): C [ i , j ] = ( C [ i , j ] + A [ i , j ]) * B [ i , j ] schedule_simple = nest_simple . create_schedule () Note that each iteration in schedule_simple executes simultaneously on all three arrays. However, there can be a case where concurrent operation on these arrays creates excessive pressure on the computer\u2019s memory cache, resulting in lower performance. In such a case, simultaneous operation on two arrays instead of three has a computational advantage. Therefore, we may first want to compute C += A and then compute C *= B . Better yet, we may want to compute C in 2\u00d72 blocks. We first compute C[0:2, 0:2] += A[0:2, 0:2] . Subsequently, we compute C[0:2, 0:2] *= B[0:2, 0:2] . Finally, we move on to the next block and compute C[2:4, 0:2] += A[2:4, 0:2] , and so on. This way, fusing offers remarkable flexibility to explore all of these different execution possibilities. First, we define two separate nests, one for the C += A logic and one for the C *= B logic, and get their corresponding default schedules: # Create nest0 and schedule0 nest0 = acc . Nest ( shape = ( 10 , 10 )) i0 , j0 = nest0 . get_indices () @nest0 . iteration_logic def _ (): C [ i0 , j0 ] += A [ i0 , j0 ] schedule0 = nest0 . create_schedule () # Create nest1 and schedule1 nest1 = acc . Nest ( shape = ( 10 , 10 )) i1 , j1 = nest1 . get_indices () @nest1 . iteration_logic def _ (): C [ i1 , j1 ] *= B [ i1 , j1 ] schedule1 = nest1 . create_schedule () Before fusing, both schedule0 and schedule1 have a shape (10, 10). Now, let\u2019s fuse them: # Create a fused schedule schedule = acc . fuse ( schedule0 , schedule1 ) f , i , j = schedule . get_indices () Fusing creates a new fused schedule schedule with a shape (2, 10, 10). It does not change schedule0 and schedule1 . The first dimension in schedule is the so-called fusing dimension f . Its slice (0, *, *) contains a copy of schedule0 , and its slice (1, *, *) contains a copy of schedule1 . Before fusing After fuse(schedule0, schedule1) In loop form, schedule is now equivalent to the following Python code: # f = 0 for i in range ( 10 ): for j in range ( 10 ): C [ i , j ] += A [ i , j ] # f = 1 for i in range ( 10 ): for j in range ( 10 ): C [ i , j ] *= B [ i , j ] Not much has happened until now since executing schedule as-is is equivalent to executing schedule0 followed by schedule1 . However, this can be changed by transforming the fused schedule. For example, we can recover schedule_simple by reordering the indices as follows: schedule . reorder ( i , j , f ) Before reorder(i, j, f) After reorder(i, j, f) The fusing dimension moves from the first position to the last position. Now, schedule is equivalent to the following Python code: for i in range ( 10 ): for j in range ( 10 ): # f = 0 C [ i , j ] += A [ i , j ] # f = 1 C [ i , j ] *= B [ i , j ] Resulting iteration sequence for C = (C + A) * B . (White elements represent C + A ; purple elements are C * B )","title":"Full fusing of same-shaped iteration spaces"},{"location":"Manual/04%20Fusing/#tiling","text":"Recall that we discussed computing the output block-by-block: first computing C[0:2, 0:2] += A[0:2, 0:2] , then computing C[0:2, 0:2] *= B[0:2, 0:2] , and so on. This can be achieved with the following sequence of transformations: ii , jj = schedule . tile ({ i : 2 , j : 2 }) schedule . reorder ( i , j , f , ii , jj ) The resulting schedule is equivalent to the following Python code: for i in range ( 0 , 10 , 2 ): for j in range ( 0 , 10 , 2 ): # f = 0 for ii in range ( 2 ): for jj in range ( 2 ): C [ i + ii , j + jj ] += A [ i + ii , j + jj ] # f = 1 for ii in range ( 2 ): for jj in range ( 2 ): C [ i + ii , j + jj ] *= B [ i + ii , j + jj ]","title":"Tiling"},{"location":"Manual/04%20Fusing/#constraints-of-fusing-dimension","text":"The fusing dimension comes with certain constraints that are discussed from the safety perspective with examples.","title":"Constraints of Fusing Dimension"},{"location":"Manual/04%20Fusing/#constraint-1-the-fusing-dimension-is-executed-sequentially","text":"Unlike other dimensions that allow parallelization, vectorization, or tensorization (see Section 7 ), none of these operations can be applied to the fusing dimension. The fusing dimension must be executed sequentially. This constraint enables the safety guarantee discussed below.","title":"Constraint 1: the fusing dimension is executed sequentially"},{"location":"Manual/04%20Fusing/#safety","text":"Before applying any subsequent transformations, the fused schedule is always logically equal to executing the original schedules sequentially. However, is it safe? Recall that a schedule is considered safe if the underlying logic is guaranteed to be unchanged regardless of the applied transformation. The safety of a fused schedule depends on circumstances that may break logic equivalence: Accera preserves the order of the fused schedules for each value of the fused dimensions , regardless of how the fused schedule is transformed. For example, in the example above, the fused dimensions are i and j . Therefore, for any concrete value of i and j , the corresponding operation from schedule0 is guaranteed to execute before the corresponding operation from schedule1 , regardless of how the fused schedule is transformed. More specifically, for each i and j , the operation C[i, j] += A[i, j] is guaranteed to execute before the operation C[i, j] *= B[i, j] , no matter how we transform the fused schedule. Since those are the only operations that interact with C[i,j] , the Accera guarantee is sufficient, and we can claim that the fused schedule is safe. With this assurance, the programmer can apply any sequence of transformations without worrying about the correctness of the resulting implementation. However, not every fusing operation creates a safe schedule. For example, consider a scenario where we fused schedule0 and schedule1 differently: # Reorder schedule1 before fusing schedule1 . reorder ( j1 , i1 ) # Fuse schedule0 with the reordered schedule1 schedule_t = acc . fuse ( schedule0 , schedule1 ) f , a , b = schedule_t . get_indices () In this unnatural example, i0 and j1 are fused and named a . Similarly, i1 and j0 are fused and named b . As mentioned above, Accera guarantees that, for each value of a and b , the operation C[a, b] += A[a, b] is executed before C[b, a] *= B[b, a] . The fusing operation itself preserves the logical equivalence. However, the underlying logic is changed if we transform the fused schedule as follows: schedule_t . reorder ( a , b , f ) To understand this change in the logic, note that the resulting schedule is equivalent to the following Python code: for a in range ( 10 ): for b in range ( 10 ): C [ a , b ] += A [ a , b ] C [ b , a ] *= B [ b , a ] The above code sets C[1,0] to C[1,0] * B[1,0] + A[1,0] , whereas the original fused logic set C[1,0] to (C[1,0] + A[1,0]) * B[1,0] . In this case, we can conclude that schedule_t is definitely not safe. If the programmer decides to create an unsafe schedule, they take upon themselves the responsibility of maintaining logical equivalence.","title":"Safety"},{"location":"Manual/04%20Fusing/#fusing-iteration-spaces-with-different-shapes","text":"If the iterations spaces have different shapes, Accera matches their shapes by padding them appropriately with empty cells.","title":"Fusing iteration spaces with different shapes"},{"location":"Manual/04%20Fusing/#partial-fusing","text":"Instead of fusing all the dimensions, we may want to fuse a subset of dimensions, leaving the rest unfused. To fuse the first s dimensions, we use the syntax: # Fuse the first s dimensions of three schedules schedule = acc . fuse (( schedule0 , schedule1 , ... ), partial = s ) The order of the dimensions in the fused schedule is as follows: first the fusing dimension f , then the fused dimensions s , followed by the unfused dimensions of schedule0 , schedule1 , and so on. We can easily calculate the number of dimensions in the fused schedule. For example, if we fuse the first s dimensions of a d0 -dimensional space schedule0 and a d1 -dimensional space schedule1 , the fused iteration space will have s fused dimensions, d0 + d1 - 2s unfused dimensions, and the special fusing dimension f , for a total of d0 + d1 - s + 1 dimensions. The fuse operation uses padding to ensure that the fused iteration space is not jagged in any direction. For example, say that we partially fuse the first 2 dimensions of schedule0 , which is 4-dimensional, and schedule1 , which is 3-dimensional: schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k , l , m = schedule . get_indices () The first dimension is the fusing dimensions f of size 2. Next comes the fused dimensions i and j , followed by the unfused dimensions k and l from schedule0 and m from schedule1 . The slice (0, *, *, *, *, 0) contains a copy of schedule0 , the slice (1, *, *, 0, 0, *) contains a copy of schedule1 , and the rest of schedule is padded with empty elements. Note that full fusing is a special case of partial fusing, where s is the larger of the dimensions of schedule0 and schedule1 .","title":"Partial fusing"},{"location":"Manual/04%20Fusing/#constraint-2-the-fusing-dimension-always-precedes-unfused-dimensions","text":"Another constraint introduced by partial fusing is that the fusing dimension must precede all of the unfused dimensions in its dimension order. This constraint applies to dimensions derived from the fusing dimension and the unfused dimensions via splitting.","title":"Constraint 2: the fusing dimension always precedes unfused dimensions"},{"location":"Manual/04%20Fusing/#safety_1","text":"The safety guarantees for partial fusing are a natural extension of the guarantees for full fusing. For each value of the fused dimensions , Accera preserves the fused schedules' order regardless of how the fused schedule is transformed. In other words, for each concrete value of fused dimensions, all the corresponding work in schedule0 (across all of its unfused dimensions) is performed before the corresponding work in schedule1 (across all of its unfused dimensions). This remains true no matter how we transform the fused schedule. While fusing, the programmer needs to consider if this property implies safety. The below examples shows how this can be done.","title":"Safety"},{"location":"Manual/04%20Fusing/#partial-fusing-example-fully-connected-neural-layer-with-activation","text":"Consider applying an element-wise operation, such as the ReLU function of AI, to the result of a matrix-matrix multiplication. This is called a fully connected layer with a ReLU activation in the language of neural networks. The function relu(x) is simply max(x,0) . Imagine that we have an element-wise operator relu , and we want to implement the equivalent Python code: C = relu ( C + A @ B ) Here, A has a shape of (8, 4), B has a shape of (4, 8), and C has a shape of (8, 8). Let\u2019s now define two nests, one for C += A @ B and the other for C = relu(C) , and obtain their corresponding default schedules: # Create nest0 and schedule0 nest0 = acc . Nest ( shape = ( 8 , 8 , 4 )) i0 , j0 , k0 = nest0 . get_indices () # nest0 performs C += A @ B @nest0 . iteration_logic def _ (): C [ i0 , j0 ] += A [ i0 , k0 ] * B [ k0 , j0 ] schedule0 = nest0 . create_schedule () # Create nest1 and schedule1 nest1 = acc . Nest ( shape = ( 8 , 8 )) i1 , j1 = nest1 . get_indices () # nest1 performs C = relu(C) @nest1 . iteration_logic def _ (): C [ i1 , j1 ] = acc . max ( C [ i1 , j1 ], 0 ) schedule1 = nest1 . create_schedule () In schedule0 and schedule1 , the first dimension represents the rows of C and the second dimension represents the columns of C . Additionally, schedule0 has a third dimension that schedule1 does not have. Therefore, we fuse the first two dimensions of the iteration spaces and leave the third dimension of schedule0 unfused. schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k0 = schedule . get_indices () The fused iteration space schedule has a shape of (2, 8, 8, 4). Its slice (0, *, *, *) contains a copy of schedule0 , the slice (1, *, *, 0) contains a copy of schedule1 , and the rest of its elements are padded. Note that the code above overwrites the index k0 , which initially was an index of schedule0 . However, now it corresponds to the unfused index in schedule . Note that the name k0 is a stylistic choice, we could have chosen a different name. Before fusing After fuse((schedule0, schedule1), partial=2) (padded elements in blue)","title":"Partial fusing example: fully-connected neural layer with activation"},{"location":"Manual/04%20Fusing/#safety_2","text":"Is schedule safe? Recall that for each value of i and j , Accera guarantees that the corresponding work in schedule0 ( C[i,j] += A[i,k0] * B[k0,j] for all values of k0 ) is executed before the corresponding work in schedule1 ( C[i,j] = max(C[i,j], 0) ), and this holds regardless of how the fused schedule is transformed. Since these are the only operations that touch C[i,j] and the ReLU operation is always executed last, this warrants that schedule is safe. Therefore, we can focus all of our attention on optimizing performance without worrying about correctness from this point onwards. Executing schedule as-is is equivalent to executing schedule0 in its entirety, followed by executing schedule1 . Suppose we want to interleave the two schedules and perform relu immediately after calculating each element of the matrix product. In that case, we reorder the dimensions such that i and j preceded f : schedule . reorder ( i , j , f , k0 ) Before reorder(i, j, f, k0) After reorder(i, j, f, k0) The resulting schedule is now equivalent to the following Python code: for i in range ( 16 ): for j in range ( 10 ): # f = 0 for k0 in range ( 11 ): C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] # f = 1 C [ i , j ] = max ( C [ i , j ], 0 ) Iteration sequence for C = relu(C + A @ B) . (White elements represent C + A @ B ; purple elements are relu(C) ; blue elements are padding.)","title":"Safety"},{"location":"Manual/04%20Fusing/#partial-fusing-example-multiplying-three-matrices","text":"Consider fusing two matrix-matrix multiplications to get matrix-matrix-matrix multiplication. Specifically, say that our goal is to calculate the equivalent of the following Python code: E += A @ B @ D Where A has a shape (4, 5), B (5, 6), D (6, 10), and E (4, 10). We start by defining the arrays. In addition to A , B , D , and E , we define a temporary array C to store the intermediate result of A@B . A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 4 , 5 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 5 , 6 )) C = acc . Array ( role = acc . Array . Role . TEMP , shape = ( 4 , 6 )) D = acc . Array ( role = acc . Array . Role . INPUT , shape = ( 6 , 10 )) E = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( 4 , 10 )) Note that C has the role of TEMP . Temporary arrays are mutable and initialized with zeros. Moreover, these arrays are logical objects that may not exist in memory during the entire computation. Next, define a simple nest to compute C += A @ B and another simple nest to compute E += C @ D . # Create nest0 and schedule0 for C = A @ B nest0 = acc . Nest ( shape = ( 4 , 6 , 5 )) i0 , j0 , k0 = nest0 . get_indices () @nest0 . iteration_logic def _ (): C [ i0 , j0 ] += A [ i0 , k0 ] * B [ k0 , j0 ] schedule0 = nest0 . create_schedule () # Create nest1 and schedule1 E += C @ D nest1 = acc . Nest ( shape = ( 4 , 10 , 6 )) i1 , j1 , k1 = nest1 . get_indices () @nest1 . iteration_logic def _ (): E [ i1 , j1 ] += C [ i1 , k1 ] * D [ k1 , j1 ] schedule1 = nest1 . create_schedule () The temporary array C stores the output of schedule0 , which is then used as one of the inputs of schedule1 . Dimensions i0 and j0 correspond to the rows and columns of C in schedule0 . Similarly, dimensions i1 and k1 correspond to the rows and columns of C in schedule1 . Therefore, we fuse i0 with i1 and j0 with k1 . We need to correctly line up the dimensions of the two iteration spaces and perform partial fusing. schedule1 . reorder ( i1 , k1 , j1 ) schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k0 , j1 = schedule . get_indices () Before reorder(i1, k1, j1) After reorder(i1, k1, j1) The fused iteration space has a shape of (2, 4, 6, 5, 10). f is the fusing dimension, i is the result of fusing i0 and i1 , and j is the result of fusing j0 and k1 . On the other hand, k0 is the unfused dimension from schedule0 , and j1 is the unfused dimension from schedule1 . The slice (0, *, *, *, 0) contains a copy of schedule0 and the slice (1, *, *, 0, *) contains a copy of schedule1 . The rest of the iteration space is padded with empty elements. After fuse((schedule0, schedule1), partial=2) (White elements represent C += A @ B ; purple elements are E += C @ D ; blue elements are padding.)","title":"Partial fusing example: multiplying three matrices"},{"location":"Manual/04%20Fusing/#safety_3","text":"Is schedule safe? Again, recall that for each value of i and j , Accera guarantees that all of the corresponding work in schedule0 ( C[i, j] += A[i, k0] * B[k0, j] for all values of k0 ) is executed before any of the corresponding work in schedule1 ( E[i, j1] += C[i, j] * D[j, j1] for all values of j1 ). In other words, each element of C is entirely computed before it is used. This confirms that the schedule is safe. Initially, the fused schedule is equivalent to the following Python code: # f = 0 for i in range ( 4 ): for j in range ( 6 ): for k0 in range ( 5 ): C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] # f = 1 for i in range ( 4 ): for j in range ( 6 ): for j1 in range ( 10 ): E [ i , j1 ] += C [ i , j ] * D [ j , j1 ] We can now manipulate the fused schedule in various ways. For example, we can do all the work to create one element of C and then immediately do all the work that uses this element before moving on to the next element. schedule . reorder ( i , j , f , k0 , j1 ) This schedule is equivalent to the following Python loops: for i in range ( 4 ): for j in range ( 6 ): for f in range ( 2 ): for k0 in range ( 5 ): for j1 in range ( 7 ): if f == 0 and j1 == 0 : # f = 0, create C[i, j] C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] if f == 1 and k0 == 0 : # f = 1, use C[i, j] E [ i , j1 ] += C [ i , j ] * D [ j , j1 ] The simplified loops after unswitching: for i in range ( 4 ): for j in range ( 6 ): # f = 0, create C[i, j] for k0 in range ( 5 ): C [ i , j ] += A [ i , k0 ] * B [ k0 , j ] # f = 1, use C[i, j] for j1 in range ( 7 ): E [ i , j1 ] += C [ i , j ] * D [ j , j1 ] The advantage of this schedule is that only one element of C is active at any time in the computation. Accera can reuse the same memory location to store the active element of C instead of storing all of C in physical memory. After reorder(i, j, f, k0, j1) (White elements represent C += A @ B ; purple elements are E += C @ D ; blue elements are padding.)","title":"Safety"},{"location":"Manual/04%20Fusing/#tiling_1","text":"As a further optimization, we can compute a 2\u00d73 block of C . Do all the work that uses this block and then move on to the next block: ii , jj = schedule . tile ({ i : 2 , j : 3 }) schedule . reorder ( i , j , f , ii , jj , k0 , j1 ) This schedule is equivalent to the following Python code: for i in range ( 0 , 4 , 2 ): for j in range ( 0 , 6 , 3 ): # f = 0 for ii in range ( 2 ): for jj in range ( 3 ): for k0 in range ( 11 ): C [ i + ii , j + jj ] += A [ i + ii , k0 ] * B [ k0 , j + jj ] # f = 1 for ii in range ( 2 ): for jj in range ( 3 ): for j1 in range ( 7 ): E [ i + ii , j1 ] += C [ i + ii , j + jj ] * D [ j + jj , j1 ]","title":"Tiling"},{"location":"Manual/05%20Targets/","text":"Section 5: Targets Accera is a cross compiler, which means that it can generate executable code for different target platforms. A target is described using the Target class. Accera already supports many different targets, for example: import accera as acc corei9 = acc . Target ( Target . Model . INTEL_7960X , num_threads = 44 ) or v100 = acc . Target ( Target . Model . NVIDIA_V100 ) We can also define custom targets: my_target = acc . Target ( name = \"Custom processor\" , category = acc . Target . Category . CPU , architecture = acc . Target . Architecture . X86_64 , family = \"Broadwell\" , extensions = [ \"MMX\" , \"SSE\" , \"SSE2\" , \"SSE3\" , \"SSSE3\" , \"SSE4\" , \"SSE4.1\" , \"SSE4.2\" , \"AVX\" , \"AVX2\" , \"FMA3\" ], num_cores = 22 , num_threads = 44 , frequency_GHz = 3.2 , turbo_frequency_GHz = 3.8 , cache_sizes = [ 32 , 256 , 56320 ], cache_lines = [ 64 , 64 , 64 ]) One benefit of targets is that they provide a standard way of accessing useful constants. For example, we may want to split an iteration space dimension by the number of elements that fit in a vector register. schedule . split ( i , size = corei9 . vector_bytes / 4 ) We may tile the iteration space for GPU targets based on input shapes and available resources like shared memory. If you are not sure of what to use, try starting with the default: # find block_x and block_y in powers of two, such that block_x*block_y=v100.default_block_size. block_x = pow ( 2 , math . log2 ( v100 . default_block_size ) // 2 ) block_y = v100 . default_block_size // block_x ii , jj = schedule . tile ({ i : block_x , j : block_y })","title":"05 Targets"},{"location":"Manual/05%20Targets/#section-5-targets","text":"Accera is a cross compiler, which means that it can generate executable code for different target platforms. A target is described using the Target class. Accera already supports many different targets, for example: import accera as acc corei9 = acc . Target ( Target . Model . INTEL_7960X , num_threads = 44 ) or v100 = acc . Target ( Target . Model . NVIDIA_V100 ) We can also define custom targets: my_target = acc . Target ( name = \"Custom processor\" , category = acc . Target . Category . CPU , architecture = acc . Target . Architecture . X86_64 , family = \"Broadwell\" , extensions = [ \"MMX\" , \"SSE\" , \"SSE2\" , \"SSE3\" , \"SSSE3\" , \"SSE4\" , \"SSE4.1\" , \"SSE4.2\" , \"AVX\" , \"AVX2\" , \"FMA3\" ], num_cores = 22 , num_threads = 44 , frequency_GHz = 3.2 , turbo_frequency_GHz = 3.8 , cache_sizes = [ 32 , 256 , 56320 ], cache_lines = [ 64 , 64 , 64 ]) One benefit of targets is that they provide a standard way of accessing useful constants. For example, we may want to split an iteration space dimension by the number of elements that fit in a vector register. schedule . split ( i , size = corei9 . vector_bytes / 4 ) We may tile the iteration space for GPU targets based on input shapes and available resources like shared memory. If you are not sure of what to use, try starting with the default: # find block_x and block_y in powers of two, such that block_x*block_y=v100.default_block_size. block_x = pow ( 2 , math . log2 ( v100 . default_block_size ) // 2 ) block_y = v100 . default_block_size // block_x ii , jj = schedule . tile ({ i : block_x , j : block_y })","title":"Section 5: Targets"},{"location":"Manual/06%20Plans%20-%20Caching/","text":"Section 6: Plans - Caching In the previous sections, we defined the logic and then scheduled its iterations. Now, let's move on to completing the implementation with target-specific options. First, we create a plan from the schedule: plan = schedule . create_plan () The Accera programming model allows us to create multiple plans from a single schedule. More importantly, we can modify individual plans without changing the schedule. We can manually specify the target platform by calling create_plan that takes a target argument. The default value of this target argument is acc.Target.HOST , which refers to the current host computer. In this section, we discuss how to add data caching strategies to a plan. Key slices Recall that a slice is a set of iteration space elements that match a coordinate template with wildcards, such as (1, *, 3) . A key-slice is a slice with only right-aligned wildcards, such as (1, 2, *) and (3, *, *) . The level of a key-slice is determined by the number of wildcards in its definition. For example, (1, 2, *) is a level 1 key-slice and (3, *, *) is a level 2 key-slice. Note that the key-slices are changed by reordering the dimensions of the iteration space. However, it is always true that the entire d -dimensional iteration space is a level d key-slice and each individual element is a level zero key-slice. For a total of d+1 different key-slices, each iteration belongs to one key-slice from each level, zero to d . When the schedule is executed, the key-slices containing the current iteration are called the current key-slices . In the Accera programming model, key-slices are significant because they partition the iteration space into sets of consecutive iterations. Therefore, they can describe the phases of computation at different levels of granularity. The term key-slice suggests using them to key (trigger) different actions. Specifically, each time the current level- l key slice changes, we use this event to trigger a cache update. As mentioned above, a key-slice can be identified by its level. Another way to specify a key-slice is to take advantage of the iteration space dimensions being named in the order. To specify a key-slice for a dimension, replace it and subsequent dimensions with wildcard symbols. For example, if the names of the iteration space dimensions are (i, j, k) , then a key-slice that corresponds to the dimension j is one of (0, *, *) , (1, *, *) , etc. Both ways of specifying a key-slice are useful and Accera uses them interchangeably. Active elements and active blocks A loop nest operates on the data that is stored in arrays. Each key-slice can access a subset of the array elements, which we call the active elements that correspond to that specific key-slice. Since the current iteration belongs to key-slices at different levels, we need to define corresponding sets of active elements at different levels. More precisely, array A elements that are read from or written to by the iterations of the current level l key-slice are called the level l active elements of A . This set of elements does not necessarily take the shape of a block. Therefore, the level l active block of A can be defined as the smallest block of elements that contains all of the level l active elements in A . Accera uses active blocks to define caching strategies. Just like we can specify a key-slice using a dimension, we can also refer to the active block that corresponds to a specific dimension. For example, if the names of the iteration space dimensions are (i, j, k) and the current iteration is one of the iterations for which i=3 , then the active block in A that corresponds to dimension j is the block that includes all the elements touched by the key-slice (3, *, *) . Caches An Accera cache is a local copy of an active block. A cache is contiguous in memory and its memory layout may differ from the layout of the original array. The loop nest iterations operate on the cache elements instead of the original array elements. The contents of the active block are copied into the cache at the start of the corresponding key-slice. If the array is mutable (namely, an input/output array or a temporary array), the cache contents are copied back into the original array at the end of the key-slice. Caching by level To define a cache for a given array, all we need is to specify the desired level.For example: AA = plan . cache ( A , level = 2 ) The return value AA is a handle that can be used to refer to the cache in subsequent operations. We can choose the cache layout, just as we did when we defined the original array. AA = plan . cache ( A , level = 2 , layout = acc . Array . Layout . FIRST_MAJOR ) Caching by dimension As mentioned above, we can specify an active block using a dimension. We use this to define a cache as follows: AA = plan . cache ( A , index = j ) Caching by element budget Note that the current active blocks of an array are nested, and their sizes are monotonic (nondecreasing) in their level. Therefore, we can also select the largest active block that does not exceed a certain number of elements: AA = plan . cache ( A , max_elements = 1024 ) Thrifty caching By default, Accera caching strategies are thrifty in the sense that the data is physically copied into an allocated cache only if the cached data somehow differs from the original active block. Therefore, if the original active block is already in the correct memory layout and resides contiguous in memory. Accera skips the caching steps and uses the original array instead. Note that a physical copy is created on a GPU if the cache is supposed to be allocated a different type of memory than the original array (e.g., the array is in global memory, but the cache is supposed to be in shared memory). For example, assume that A is a two-dimensional array and its active block at the chosen level is always one of its rows. If A is row-major, the rows are already stored contiguously. Additionally, the data in the active block and the data to be copied to cache are identical: both are contiguous and share the same memory layout. In this case, there is no benefit in using cache over the original array. The thrifty caching strategy will skip the caching steps and use the original array instead. On the other hand, if A is column-major, its rows are not stored contiguously. In this case, copying the active row into a contiguous temporary location could be computationally advantageous. Therefore, the thrifty caching strategy would create the cache and populate it with the data. Thrifty caching can be turned off using the optional argument thrifty=False . If turned off, a physical copy is always created. Hierarchical caching Caches can be composed hierarchically. Namely, a high-level key-slice can trigger a copy from the original array into a big cache, and a lower level key-slice can be used to trigger a copy from the big cache into a smaller cache. For example, AA = plan . cache ( A , level = 4 ) AAA = plan . cache ( AA , level = 2 ) Multicaching While caches are defined with a key-slice level , a higher-level key slice trigger_level can be specified as the trigger key-slice for copying multiple successive active blocks of elements to a local copy. These copied active blocks have their layouts defined as usual, and only the trigger level for copying them has been changed. Since active blocks are not mutually exclusive, this can result in the same element being copied into multiple locations as separate caches. Therefore, a trigger_level may only be specified on an INPUT or CONST array as Accera does not support multicache write coherence. For example, AA = plan . cache ( A , level = 2 , trigger_level = 4 ) Mapping caches to specific types of memory Some target platforms have different types of memory that can hold Accera caches. In the case of a GPU target, caches can be located in global or shared memory . To explicitly choose the location of the cache, we write: AA = plan . cache ( A , level = 4 , location = v100 . MemorySpace . SHARED ) Double buffering Caches can double-buffer data by loading the next active block's cache data into a temporary buffer during the current active block's usage and then moving that data into the cache buffer after the current active block is done being used. If the cache trigger level is the highest level in the loopnest then this does nothing as it is dependent on having another loop outside of the cache trigger loop. In shared memory caches on GPU this temporary buffer will automatically be allocated in private memory. Since the next iteration's data is loaded into a temporary buffer while the current iteration's data is in the cache buffer, any overlap in these active blocks would result in a write coherency issue similar to what occurs with Multicaching. Because of this, double_buffer may only be specified on an INPUT or CONST array as Accera does not perform multicache write coherence. AA = plan . cache ( A , level = 3 , double_buffer = True ) Full schedule with equivalent pseudo-code: ... M , N , K = 1024 , 1024 , 1024 m_tile , n_tile , k_tile = 32 , 64 , 128 nest = Nest (( M , N , K )) i , j , k = nest . get_indices () @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] schedule = nest . create_schedule () schedule . tile ({ i : m_tile , j : n_tile , k : k_tile }) schedule . reorder ( i , j , k , ii , jj , kk ) plan = schedule . create_plan () plan . cache ( A , index = ii , double_buffer = True ) ... equivalent to: for i in range ( 0 , M , m_tile ): for j in range ( 0 , N , n_tile ): for ii_cache in range ( 0 , m_tile ): for kk_cache in range ( 0 , k_tile ): cache_A [ ii_cache , kk_cache ] = A [ i + ii_cache , kk_cache ] for k in range ( 0 , K - k_tile , k_tile ): # Note: this loop doesn't run for the final K tile for ii_cache in range ( 0 , m_tile ): for kk_cache in range ( 0 , k_tile ): temp_A [ ii_cache , kk_cache ] = A [ i + ii_cache , ( k + k_tile ) + kk_cache ] for ii in range ( 0 , m_tile ): for jj in range ( 0 , n_tile ): for kk in range ( 0 , k_tile ): C [ i + ii , j + jj ] += cache_A [ ii , kk ] * B [ k + kk , j + jj ] for ii_cache in range ( 0 , m_tile ): for kk_cache in range ( 0 , k_tile ): cache_A [ ii_cache , kk_cache ] = temp_A [ ii_cache , kk_cache ] for ii in range ( 0 , m_tile ): for jj in range ( 0 , n_tile ): for kk in range ( 0 , k_tile ): C [ i + ii , j + jj ] += cache_A [ ii , kk ] * B [ k + kk , j + jj ]","title":"06 Plans   Caching"},{"location":"Manual/06%20Plans%20-%20Caching/#section-6-plans-caching","text":"In the previous sections, we defined the logic and then scheduled its iterations. Now, let's move on to completing the implementation with target-specific options. First, we create a plan from the schedule: plan = schedule . create_plan () The Accera programming model allows us to create multiple plans from a single schedule. More importantly, we can modify individual plans without changing the schedule. We can manually specify the target platform by calling create_plan that takes a target argument. The default value of this target argument is acc.Target.HOST , which refers to the current host computer. In this section, we discuss how to add data caching strategies to a plan.","title":"Section 6: Plans - Caching"},{"location":"Manual/06%20Plans%20-%20Caching/#key-slices","text":"Recall that a slice is a set of iteration space elements that match a coordinate template with wildcards, such as (1, *, 3) . A key-slice is a slice with only right-aligned wildcards, such as (1, 2, *) and (3, *, *) . The level of a key-slice is determined by the number of wildcards in its definition. For example, (1, 2, *) is a level 1 key-slice and (3, *, *) is a level 2 key-slice. Note that the key-slices are changed by reordering the dimensions of the iteration space. However, it is always true that the entire d -dimensional iteration space is a level d key-slice and each individual element is a level zero key-slice. For a total of d+1 different key-slices, each iteration belongs to one key-slice from each level, zero to d . When the schedule is executed, the key-slices containing the current iteration are called the current key-slices . In the Accera programming model, key-slices are significant because they partition the iteration space into sets of consecutive iterations. Therefore, they can describe the phases of computation at different levels of granularity. The term key-slice suggests using them to key (trigger) different actions. Specifically, each time the current level- l key slice changes, we use this event to trigger a cache update. As mentioned above, a key-slice can be identified by its level. Another way to specify a key-slice is to take advantage of the iteration space dimensions being named in the order. To specify a key-slice for a dimension, replace it and subsequent dimensions with wildcard symbols. For example, if the names of the iteration space dimensions are (i, j, k) , then a key-slice that corresponds to the dimension j is one of (0, *, *) , (1, *, *) , etc. Both ways of specifying a key-slice are useful and Accera uses them interchangeably.","title":"Key slices"},{"location":"Manual/06%20Plans%20-%20Caching/#active-elements-and-active-blocks","text":"A loop nest operates on the data that is stored in arrays. Each key-slice can access a subset of the array elements, which we call the active elements that correspond to that specific key-slice. Since the current iteration belongs to key-slices at different levels, we need to define corresponding sets of active elements at different levels. More precisely, array A elements that are read from or written to by the iterations of the current level l key-slice are called the level l active elements of A . This set of elements does not necessarily take the shape of a block. Therefore, the level l active block of A can be defined as the smallest block of elements that contains all of the level l active elements in A . Accera uses active blocks to define caching strategies. Just like we can specify a key-slice using a dimension, we can also refer to the active block that corresponds to a specific dimension. For example, if the names of the iteration space dimensions are (i, j, k) and the current iteration is one of the iterations for which i=3 , then the active block in A that corresponds to dimension j is the block that includes all the elements touched by the key-slice (3, *, *) .","title":"Active elements and active blocks"},{"location":"Manual/06%20Plans%20-%20Caching/#caches","text":"An Accera cache is a local copy of an active block. A cache is contiguous in memory and its memory layout may differ from the layout of the original array. The loop nest iterations operate on the cache elements instead of the original array elements. The contents of the active block are copied into the cache at the start of the corresponding key-slice. If the array is mutable (namely, an input/output array or a temporary array), the cache contents are copied back into the original array at the end of the key-slice.","title":"Caches"},{"location":"Manual/06%20Plans%20-%20Caching/#caching-by-level","text":"To define a cache for a given array, all we need is to specify the desired level.For example: AA = plan . cache ( A , level = 2 ) The return value AA is a handle that can be used to refer to the cache in subsequent operations. We can choose the cache layout, just as we did when we defined the original array. AA = plan . cache ( A , level = 2 , layout = acc . Array . Layout . FIRST_MAJOR )","title":"Caching by level"},{"location":"Manual/06%20Plans%20-%20Caching/#caching-by-dimension","text":"As mentioned above, we can specify an active block using a dimension. We use this to define a cache as follows: AA = plan . cache ( A , index = j )","title":"Caching by dimension"},{"location":"Manual/06%20Plans%20-%20Caching/#caching-by-element-budget","text":"Note that the current active blocks of an array are nested, and their sizes are monotonic (nondecreasing) in their level. Therefore, we can also select the largest active block that does not exceed a certain number of elements: AA = plan . cache ( A , max_elements = 1024 )","title":"Caching by element budget"},{"location":"Manual/06%20Plans%20-%20Caching/#thrifty-caching","text":"By default, Accera caching strategies are thrifty in the sense that the data is physically copied into an allocated cache only if the cached data somehow differs from the original active block. Therefore, if the original active block is already in the correct memory layout and resides contiguous in memory. Accera skips the caching steps and uses the original array instead. Note that a physical copy is created on a GPU if the cache is supposed to be allocated a different type of memory than the original array (e.g., the array is in global memory, but the cache is supposed to be in shared memory). For example, assume that A is a two-dimensional array and its active block at the chosen level is always one of its rows. If A is row-major, the rows are already stored contiguously. Additionally, the data in the active block and the data to be copied to cache are identical: both are contiguous and share the same memory layout. In this case, there is no benefit in using cache over the original array. The thrifty caching strategy will skip the caching steps and use the original array instead. On the other hand, if A is column-major, its rows are not stored contiguously. In this case, copying the active row into a contiguous temporary location could be computationally advantageous. Therefore, the thrifty caching strategy would create the cache and populate it with the data. Thrifty caching can be turned off using the optional argument thrifty=False . If turned off, a physical copy is always created.","title":"Thrifty caching"},{"location":"Manual/06%20Plans%20-%20Caching/#hierarchical-caching","text":"Caches can be composed hierarchically. Namely, a high-level key-slice can trigger a copy from the original array into a big cache, and a lower level key-slice can be used to trigger a copy from the big cache into a smaller cache. For example, AA = plan . cache ( A , level = 4 ) AAA = plan . cache ( AA , level = 2 )","title":"Hierarchical caching"},{"location":"Manual/06%20Plans%20-%20Caching/#multicaching","text":"While caches are defined with a key-slice level , a higher-level key slice trigger_level can be specified as the trigger key-slice for copying multiple successive active blocks of elements to a local copy. These copied active blocks have their layouts defined as usual, and only the trigger level for copying them has been changed. Since active blocks are not mutually exclusive, this can result in the same element being copied into multiple locations as separate caches. Therefore, a trigger_level may only be specified on an INPUT or CONST array as Accera does not support multicache write coherence. For example, AA = plan . cache ( A , level = 2 , trigger_level = 4 )","title":"Multicaching"},{"location":"Manual/06%20Plans%20-%20Caching/#mapping-caches-to-specific-types-of-memory","text":"Some target platforms have different types of memory that can hold Accera caches. In the case of a GPU target, caches can be located in global or shared memory . To explicitly choose the location of the cache, we write: AA = plan . cache ( A , level = 4 , location = v100 . MemorySpace . SHARED )","title":"Mapping caches to specific types of memory"},{"location":"Manual/06%20Plans%20-%20Caching/#double-buffering","text":"Caches can double-buffer data by loading the next active block's cache data into a temporary buffer during the current active block's usage and then moving that data into the cache buffer after the current active block is done being used. If the cache trigger level is the highest level in the loopnest then this does nothing as it is dependent on having another loop outside of the cache trigger loop. In shared memory caches on GPU this temporary buffer will automatically be allocated in private memory. Since the next iteration's data is loaded into a temporary buffer while the current iteration's data is in the cache buffer, any overlap in these active blocks would result in a write coherency issue similar to what occurs with Multicaching. Because of this, double_buffer may only be specified on an INPUT or CONST array as Accera does not perform multicache write coherence. AA = plan . cache ( A , level = 3 , double_buffer = True ) Full schedule with equivalent pseudo-code: ... M , N , K = 1024 , 1024 , 1024 m_tile , n_tile , k_tile = 32 , 64 , 128 nest = Nest (( M , N , K )) i , j , k = nest . get_indices () @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] schedule = nest . create_schedule () schedule . tile ({ i : m_tile , j : n_tile , k : k_tile }) schedule . reorder ( i , j , k , ii , jj , kk ) plan = schedule . create_plan () plan . cache ( A , index = ii , double_buffer = True ) ... equivalent to: for i in range ( 0 , M , m_tile ): for j in range ( 0 , N , n_tile ): for ii_cache in range ( 0 , m_tile ): for kk_cache in range ( 0 , k_tile ): cache_A [ ii_cache , kk_cache ] = A [ i + ii_cache , kk_cache ] for k in range ( 0 , K - k_tile , k_tile ): # Note: this loop doesn't run for the final K tile for ii_cache in range ( 0 , m_tile ): for kk_cache in range ( 0 , k_tile ): temp_A [ ii_cache , kk_cache ] = A [ i + ii_cache , ( k + k_tile ) + kk_cache ] for ii in range ( 0 , m_tile ): for jj in range ( 0 , n_tile ): for kk in range ( 0 , k_tile ): C [ i + ii , j + jj ] += cache_A [ ii , kk ] * B [ k + kk , j + jj ] for ii_cache in range ( 0 , m_tile ): for kk_cache in range ( 0 , k_tile ): cache_A [ ii_cache , kk_cache ] = temp_A [ ii_cache , kk_cache ] for ii in range ( 0 , m_tile ): for jj in range ( 0 , n_tile ): for kk in range ( 0 , k_tile ): C [ i + ii , j + jj ] += cache_A [ ii , kk ] * B [ k + kk , j + jj ]","title":"Double buffering"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/","text":"Section 7: Plans - Operations and Optimizations We can control target-specific operations and optimizations using a plan. Examples include instruction pipelining, applying SIMD vector instructions, and so on. unroll By default, each dimension of the iteration space is implemented as a for-loop. The unroll instruction marks a dimension for unrolling rather than looping. Imagine the following nest that multiplies the entries of an array by a constant: import accera as acc my_target = acc . Target ( type = acc . Target . Category . CPU ) nest = acc . Nest ( shape = ( 3 , 5 )) i , j = nest . get_indices () @nest . iteration_logic def _ (): A [ i , j ] *= 2.0 plan = nest . create_plan ( my_target ) If we build plan as is, the resulting implementation would be equivalent to the following Python code: for i in range ( 3 ): for j in range ( 5 ): A [ i , j ] *= 2.0 If we add the instruction plan.unroll(index=j) , the resulting implementation becomes equivalent to: for i in range ( 3 ): A [ i , 0 ] *= 2.0 A [ i , 1 ] *= 2.0 A [ i , 2 ] *= 2.0 A [ i , 3 ] *= 2.0 A [ i , 4 ] *= 2.0 If, instead of unrolling j , we add the instruction plan.unroll(index=i) , the resulting implementation becomes equivalent to: for j in range ( 5 ): A [ 0 , j ] *= 2.0 for j in range ( 5 ): A [ 1 , j ] *= 2.0 for j in range ( 5 ): A [ 2 , j ] *= 2.0 And, of course, we can also unroll both dimensions, removing for-loops completely. vectorize Modern target platforms support SIMD vector instructions. These instructions perform the same operation on an entire vector of elements, all at once. By default, each dimension of an iteration space becomes a for-loop. The vectorize instruction instead labels a dimension for vectorized execution, rather than for-looping. For example, assume that a host supports 256-bit vector instructions, indicating that its vector instructions operate on eight floating-point elements at once. Also, consider that we already have arrays A , B , and C , and we write the following code: nest = acc . Nest ( shape = ( 64 ,)) i = nest . get_indices () @nest . iteration_logic def _ (): C [ i ] = A [ i ] * B [ i ] schedule = nest . create_schedule () ii = schedule . split ( i , 8 ) plan = nest . create_plan () plan . vectorize ( index = ii ) The dimension marked for the vectorization is of size 8, which is a supported vector size on the specific target platform. Therefore, the resulting binary will contain something like: 00000001400010B0: C5 FC 10 0C 11 vmovups ymm1,ymmword ptr [rcx+rdx] 00000001400010B5: C5 F4 59 0A vmulps ymm1,ymm1,ymmword ptr [rdx] 00000001400010B9: C4 C1 7C 11 0C 10 vmovups ymmword ptr [r8+rdx],ymm1 00000001400010BF: 48 8D 52 20 lea rdx,[rdx+20h] 00000001400010C3: 48 83 E8 01 sub rax,1 00000001400010C7: 75 E7 jne 00000001400010B0 Note how the multiplication instruction vmulps and the memory move instruction vmovups deal with eight 32-bit floating-point values at a time. Different targets support different vector instructions having different vector sizes. The following table includes iteration logic that vectorizes correctly on most targets with vectorization support, such as Intel Haswell, Broadwell or newer, and ARM v7/A32. Other examples of iteration logic may or may not vectorize correctly. Variables prefixed with v are vector types, and those prefixed with s are scalar types. Vector pseudocode Equivalent to Supported types v1 += s0 * v0 for i in range(vector_size): \u2003 v1[i] += s0 * v0[i] float32 v1 += v0 * s0 for i in range(vector_size): \u2003 v1[i] += v0[i] * s0 float32 v1 += v0 / s0 for i in range(vector_size): \u2003 v1[i] += v0[i] / s0 float32 v1 -= s0 * v0 for i in range(vector_size): \u2003 v1[i] -= s0 * v0[i] float32 v1 -= v0 * s0 for i in range(vector_size): \u2003 v1[i] -= v0[i] * s0 float32 v1 -= v0 / s0 for i in range(vector_size): \u2003 v1[i] -= v0[i] / s0 float32 v2 += v0 * v1 for i in range(vector_size): \u2003 v2[i] += v0[i] * v1[i] float32 vector inner (dot) product: s0 += dot(v0, v1) for i in range(vector_size): \u2003 s0 += v0[i] * v1[i] float32 v2 = v0 + v1 for i in range(vector_size): \u2003 v2[i] = v0[i] + v1[i] int8/16/32/64, float32 v2 = v0 - v1 for i in range(vector_size): \u2003 v2[i] = v0[i] - v1[i] int8/16/32/64, float32 v2 = v0 * v1 for i in range(vector_size): \u2003 v2[i] = v0[i] * v1[i] int8/16/32/64, float32 v2 = v0 / v1 for i in range(vector_size): \u2003 v2[i] = v0[i] / v1[i] float32 v1 = abs(v[0]) for i in range(vector_size): \u2003 v1[i] = abs(v0[i]) int8/16/32/64, float32 v2 = (v0 == v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] == v1[i] else 0 int8/16/32/64, float32 v2 = (v0 > v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] > v1[i] else 0 int8/16/32/64, float32 v2 = (v0 >= v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] >= v1[i] else 0 int8/16/32/64, float32 v2 = (v0 < v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] < v1[i] else 0 int8/16/32/64, float32 v2 = (v0 <= v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] <= v1[i] else 0 int8/16/32/64, float32 v1 = v0 << s0 for i in range(vector_size): \u2003 v1[i] = v0[i] << s0 int16/32/64, float32 v1 = v0 >> s0 for i in range(vector_size): \u2003 v1[i] = v0[i] >> s0 int16/32/64, float32 s0 = sum(v0) for i in range(vector_size): \u2003 s0 += v0[i] int8/16/32/64, float32 s0 = max(v0 + v1) for i in range(vector_size): \u2003 s0 = max(v0[i] + v1[i], s0) int8/16/32/64, float32 s0 = max(v0 - v1) for i in range(vector_size): \u2003 s0 = max(v0[i] - v1[i], s0) int8/16/32/64, float32 Additionally, Accera can perform vectorized load and store operations to/from vector registers and memory if the memory locations are contiguous. To vectorize dimension i , the number of active elements that corresponds to dimension i must exactly match the vector instruction width of the target processor. For example, if the target processor has vector instructions that operate on either 4 or 8 floating-point elements at once, then the number of active elements can either be 4 or 8. Additionally, those active elements must occupy adjacent memory locations (they cannot be spread out). tensorize Some hardware also have specialized instructions for performing matrix multiplications. These instructions operate on certain matrix dimensions with specific data types. The tensorization instructions take tiles of the A , B , and C matrices and compute the C = A * B + C operation. The tensorize operation takes 3 indices: plan . tensorize ( indices = ( i , j , k )) Tensorization is limited and is only valid on loop structures of the form for i in range ( M ): for k in range ( N ): for j in range ( K ): C [ i , j ] += A [ i , k ] * B [ k , j ] Where there is MxNxK tensorization hardware support using the A , B , and C element data types. Convenience syntax: kernelize The kernelize instruction is a convenience syntax that does not provide any unique functionality. Specifically, kernelize is equivalent to a sequence of unroll instructions, followed by an optional vectorize instruction. A typical Accera design pattern is to first break a loop-nest into tiles and then apply an optimized kernel to each tile. For example, imagine that the loop nest multiplies two 256\u00d7256 matrices and the kernel is a highly optimized procedure for multiplying 4\u00d74 matrices. Accera will introduce different ways to write highly optimized kernels in the future. However, currently, it only supports automatic kernelization using the kernelize instruction. As mentioned above, kernelize is shorthand for unrolling and vectorizing. These instructions structure the code in a way that makes it easy for downstream compiler heuristics to automatically generate kernels. Consider, once again, the matrix multiplication example we discussed previously in Section 2 . Assume that we declare the schedule and reorder as follows: schedule = nest . create_schedule () schedule . reorder ( i , k , j ) Notice that i, k, j are the last three dimensions in the iteration space and the resulting implementation becomes equivalent to: for i in range ( M ): for k in range ( S ): for j in range ( N ): C [ i , j ] += A [ i , k ] * B [ k , j ] The instruction: plan . kernelize ( unroll_indices = ( i , k ), vectorize_indices = j ) is just shorthand for plan . unroll ( i ) plan . unroll ( k ) plan . vectorize ( j ) Applying this sequence of instructions allows the compiler to automatically create an optimized kernel from loops i, k, j . For simplicity, assume that the matrix sizes defined by M, N, and S are 3, 4, and 2 respectively. After applying kernelize , the schedule is equivalent to the following Python code: C [ 0 , 0 : 4 ] += A [ 0 , 0 ] * B [ 0 , 0 : 4 ] # vectorized C [ 0 , 0 : 4 ] += A [ 0 , 1 ] * B [ 1 , 0 : 4 ] # vectorized C [ 1 , 0 : 4 ] += A [ 1 , 0 ] * B [ 0 , 0 : 4 ] # vectorized C [ 1 , 0 : 4 ] += A [ 1 , 1 ] * B [ 1 , 0 : 4 ] # vectorized C [ 2 , 0 : 4 ] += A [ 2 , 0 ] * B [ 0 , 0 : 4 ] # vectorized C [ 2 , 0 : 4 ] += A [ 2 , 1 ] * B [ 1 , 0 : 4 ] # vectorized This would result in the following vectorized instructions on an Intel Haswell CPU: 0000000000000200: C4 C1 78 10 00 vmovups xmm0,xmmword ptr [r8] 0000000000000205: C4 E2 79 18 09 vbroadcastss xmm1,dword ptr [rcx] 000000000000020A: C5 F8 10 12 vmovups xmm2,xmmword ptr [rdx] 000000000000020E: C4 E2 69 A8 C8 vfmadd213ps xmm1,xmm2,xmm0 0000000000000213: C5 F8 10 5A 10 vmovups xmm3,xmmword ptr [rdx+10h] 0000000000000218: C4 E2 79 18 61 04 vbroadcastss xmm4,dword ptr [rcx+4] 000000000000021E: C4 E2 61 A8 E1 vfmadd213ps xmm4,xmm3,xmm1 0000000000000223: C4 E2 79 18 49 08 vbroadcastss xmm1,dword ptr [rcx+8] 0000000000000229: C4 E2 69 A8 C8 vfmadd213ps xmm1,xmm2,xmm0 000000000000022E: C4 E2 79 18 69 0C vbroadcastss xmm5,dword ptr [rcx+0Ch] 0000000000000234: C4 E2 61 A8 E9 vfmadd213ps xmm5,xmm3,xmm1 0000000000000239: C4 E2 79 18 49 10 vbroadcastss xmm1,dword ptr [rcx+10h] 000000000000023F: C4 E2 69 A8 C8 vfmadd213ps xmm1,xmm2,xmm0 0000000000000244: C4 E2 79 18 41 14 vbroadcastss xmm0,dword ptr [rcx+14h] 000000000000024A: C4 E2 61 A8 C1 vfmadd213ps xmm0,xmm3,xmm1 000000000000024F: C4 C1 58 58 09 vaddps xmm1,xmm4,xmmword ptr [r9] 0000000000000254: C4 C1 50 58 51 10 vaddps xmm2,xmm5,xmmword ptr [r9+10h] 000000000000025A: C4 C1 78 58 41 20 vaddps xmm0,xmm0,xmmword ptr [r9+20h] parallelize The parallelize instruction performs one or more loops in parallel on multiple cores. xeonPlat = acc . Target ( \"Intel 9221\" , num_threads = 16 ) plan = schedule . create_plan ( xeonPlat ) plan . parallelize ( indices = ( i , j , k )) Specifying multiple dimensions is equivalent to the collapse argument in OpenMP. Therefore, the dimensions must be contiguous in the iteration space dimension order. Static scheduling policy Static scheduling strategy is invoked by setting the argument policy=\"static\" in the call to parallelize . If n iterations are parallelized across c cores, the static scheduling partitions the work into c fixed parts, some of size floor(n/c) , some of size ceil(n/c) , and executes each part on a different core. Dynamic scheduling policy Dynamic scheduling strategy is invoked by setting the argument policy=\"dynamic\" in the call to parallelize . Dynamic scheduling creates a single work queue that is shared across different cores. Not yet implemented: Pinning to specific cores The pin argument allows the parallel work to be pinned to specific cores. bind Some target platforms, such as GPUs, are specifically designed to execute nested loops. They can take an entire grid of work and schedule its execution on multiple cores. On a GPU, this grid is broken up into multiple blocks, where each block contains multiple threads. Block iterators and thread iterators are identified by special variables in the Target object. To take advantage of a target platform's ability to execute grids, we must bind dimensions of the iteration space with these special iterator variables. For example, v100 = acc . Target ( \"Tesla V100\" ) plan . bind ( mapping = { i : v100 . GridUnit . BLOCK_X , j : v100 . GridUnit . THREAD_X , k : v100 . GridUnit . THREAD_Y } )","title":"07 Plans   Operations and Optimizations"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#section-7-plans-operations-and-optimizations","text":"We can control target-specific operations and optimizations using a plan. Examples include instruction pipelining, applying SIMD vector instructions, and so on.","title":"Section 7: Plans - Operations and Optimizations"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#unroll","text":"By default, each dimension of the iteration space is implemented as a for-loop. The unroll instruction marks a dimension for unrolling rather than looping. Imagine the following nest that multiplies the entries of an array by a constant: import accera as acc my_target = acc . Target ( type = acc . Target . Category . CPU ) nest = acc . Nest ( shape = ( 3 , 5 )) i , j = nest . get_indices () @nest . iteration_logic def _ (): A [ i , j ] *= 2.0 plan = nest . create_plan ( my_target ) If we build plan as is, the resulting implementation would be equivalent to the following Python code: for i in range ( 3 ): for j in range ( 5 ): A [ i , j ] *= 2.0 If we add the instruction plan.unroll(index=j) , the resulting implementation becomes equivalent to: for i in range ( 3 ): A [ i , 0 ] *= 2.0 A [ i , 1 ] *= 2.0 A [ i , 2 ] *= 2.0 A [ i , 3 ] *= 2.0 A [ i , 4 ] *= 2.0 If, instead of unrolling j , we add the instruction plan.unroll(index=i) , the resulting implementation becomes equivalent to: for j in range ( 5 ): A [ 0 , j ] *= 2.0 for j in range ( 5 ): A [ 1 , j ] *= 2.0 for j in range ( 5 ): A [ 2 , j ] *= 2.0 And, of course, we can also unroll both dimensions, removing for-loops completely.","title":"unroll"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#vectorize","text":"Modern target platforms support SIMD vector instructions. These instructions perform the same operation on an entire vector of elements, all at once. By default, each dimension of an iteration space becomes a for-loop. The vectorize instruction instead labels a dimension for vectorized execution, rather than for-looping. For example, assume that a host supports 256-bit vector instructions, indicating that its vector instructions operate on eight floating-point elements at once. Also, consider that we already have arrays A , B , and C , and we write the following code: nest = acc . Nest ( shape = ( 64 ,)) i = nest . get_indices () @nest . iteration_logic def _ (): C [ i ] = A [ i ] * B [ i ] schedule = nest . create_schedule () ii = schedule . split ( i , 8 ) plan = nest . create_plan () plan . vectorize ( index = ii ) The dimension marked for the vectorization is of size 8, which is a supported vector size on the specific target platform. Therefore, the resulting binary will contain something like: 00000001400010B0: C5 FC 10 0C 11 vmovups ymm1,ymmword ptr [rcx+rdx] 00000001400010B5: C5 F4 59 0A vmulps ymm1,ymm1,ymmword ptr [rdx] 00000001400010B9: C4 C1 7C 11 0C 10 vmovups ymmword ptr [r8+rdx],ymm1 00000001400010BF: 48 8D 52 20 lea rdx,[rdx+20h] 00000001400010C3: 48 83 E8 01 sub rax,1 00000001400010C7: 75 E7 jne 00000001400010B0 Note how the multiplication instruction vmulps and the memory move instruction vmovups deal with eight 32-bit floating-point values at a time. Different targets support different vector instructions having different vector sizes. The following table includes iteration logic that vectorizes correctly on most targets with vectorization support, such as Intel Haswell, Broadwell or newer, and ARM v7/A32. Other examples of iteration logic may or may not vectorize correctly. Variables prefixed with v are vector types, and those prefixed with s are scalar types. Vector pseudocode Equivalent to Supported types v1 += s0 * v0 for i in range(vector_size): \u2003 v1[i] += s0 * v0[i] float32 v1 += v0 * s0 for i in range(vector_size): \u2003 v1[i] += v0[i] * s0 float32 v1 += v0 / s0 for i in range(vector_size): \u2003 v1[i] += v0[i] / s0 float32 v1 -= s0 * v0 for i in range(vector_size): \u2003 v1[i] -= s0 * v0[i] float32 v1 -= v0 * s0 for i in range(vector_size): \u2003 v1[i] -= v0[i] * s0 float32 v1 -= v0 / s0 for i in range(vector_size): \u2003 v1[i] -= v0[i] / s0 float32 v2 += v0 * v1 for i in range(vector_size): \u2003 v2[i] += v0[i] * v1[i] float32 vector inner (dot) product: s0 += dot(v0, v1) for i in range(vector_size): \u2003 s0 += v0[i] * v1[i] float32 v2 = v0 + v1 for i in range(vector_size): \u2003 v2[i] = v0[i] + v1[i] int8/16/32/64, float32 v2 = v0 - v1 for i in range(vector_size): \u2003 v2[i] = v0[i] - v1[i] int8/16/32/64, float32 v2 = v0 * v1 for i in range(vector_size): \u2003 v2[i] = v0[i] * v1[i] int8/16/32/64, float32 v2 = v0 / v1 for i in range(vector_size): \u2003 v2[i] = v0[i] / v1[i] float32 v1 = abs(v[0]) for i in range(vector_size): \u2003 v1[i] = abs(v0[i]) int8/16/32/64, float32 v2 = (v0 == v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] == v1[i] else 0 int8/16/32/64, float32 v2 = (v0 > v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] > v1[i] else 0 int8/16/32/64, float32 v2 = (v0 >= v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] >= v1[i] else 0 int8/16/32/64, float32 v2 = (v0 < v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] < v1[i] else 0 int8/16/32/64, float32 v2 = (v0 <= v1) for i in range(vector_size): \u2003 v2[i] = 0XF..F if v0[i] <= v1[i] else 0 int8/16/32/64, float32 v1 = v0 << s0 for i in range(vector_size): \u2003 v1[i] = v0[i] << s0 int16/32/64, float32 v1 = v0 >> s0 for i in range(vector_size): \u2003 v1[i] = v0[i] >> s0 int16/32/64, float32 s0 = sum(v0) for i in range(vector_size): \u2003 s0 += v0[i] int8/16/32/64, float32 s0 = max(v0 + v1) for i in range(vector_size): \u2003 s0 = max(v0[i] + v1[i], s0) int8/16/32/64, float32 s0 = max(v0 - v1) for i in range(vector_size): \u2003 s0 = max(v0[i] - v1[i], s0) int8/16/32/64, float32 Additionally, Accera can perform vectorized load and store operations to/from vector registers and memory if the memory locations are contiguous. To vectorize dimension i , the number of active elements that corresponds to dimension i must exactly match the vector instruction width of the target processor. For example, if the target processor has vector instructions that operate on either 4 or 8 floating-point elements at once, then the number of active elements can either be 4 or 8. Additionally, those active elements must occupy adjacent memory locations (they cannot be spread out).","title":"vectorize"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#tensorize","text":"Some hardware also have specialized instructions for performing matrix multiplications. These instructions operate on certain matrix dimensions with specific data types. The tensorization instructions take tiles of the A , B , and C matrices and compute the C = A * B + C operation. The tensorize operation takes 3 indices: plan . tensorize ( indices = ( i , j , k )) Tensorization is limited and is only valid on loop structures of the form for i in range ( M ): for k in range ( N ): for j in range ( K ): C [ i , j ] += A [ i , k ] * B [ k , j ] Where there is MxNxK tensorization hardware support using the A , B , and C element data types.","title":"tensorize"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#convenience-syntax-kernelize","text":"The kernelize instruction is a convenience syntax that does not provide any unique functionality. Specifically, kernelize is equivalent to a sequence of unroll instructions, followed by an optional vectorize instruction. A typical Accera design pattern is to first break a loop-nest into tiles and then apply an optimized kernel to each tile. For example, imagine that the loop nest multiplies two 256\u00d7256 matrices and the kernel is a highly optimized procedure for multiplying 4\u00d74 matrices. Accera will introduce different ways to write highly optimized kernels in the future. However, currently, it only supports automatic kernelization using the kernelize instruction. As mentioned above, kernelize is shorthand for unrolling and vectorizing. These instructions structure the code in a way that makes it easy for downstream compiler heuristics to automatically generate kernels. Consider, once again, the matrix multiplication example we discussed previously in Section 2 . Assume that we declare the schedule and reorder as follows: schedule = nest . create_schedule () schedule . reorder ( i , k , j ) Notice that i, k, j are the last three dimensions in the iteration space and the resulting implementation becomes equivalent to: for i in range ( M ): for k in range ( S ): for j in range ( N ): C [ i , j ] += A [ i , k ] * B [ k , j ] The instruction: plan . kernelize ( unroll_indices = ( i , k ), vectorize_indices = j ) is just shorthand for plan . unroll ( i ) plan . unroll ( k ) plan . vectorize ( j ) Applying this sequence of instructions allows the compiler to automatically create an optimized kernel from loops i, k, j . For simplicity, assume that the matrix sizes defined by M, N, and S are 3, 4, and 2 respectively. After applying kernelize , the schedule is equivalent to the following Python code: C [ 0 , 0 : 4 ] += A [ 0 , 0 ] * B [ 0 , 0 : 4 ] # vectorized C [ 0 , 0 : 4 ] += A [ 0 , 1 ] * B [ 1 , 0 : 4 ] # vectorized C [ 1 , 0 : 4 ] += A [ 1 , 0 ] * B [ 0 , 0 : 4 ] # vectorized C [ 1 , 0 : 4 ] += A [ 1 , 1 ] * B [ 1 , 0 : 4 ] # vectorized C [ 2 , 0 : 4 ] += A [ 2 , 0 ] * B [ 0 , 0 : 4 ] # vectorized C [ 2 , 0 : 4 ] += A [ 2 , 1 ] * B [ 1 , 0 : 4 ] # vectorized This would result in the following vectorized instructions on an Intel Haswell CPU: 0000000000000200: C4 C1 78 10 00 vmovups xmm0,xmmword ptr [r8] 0000000000000205: C4 E2 79 18 09 vbroadcastss xmm1,dword ptr [rcx] 000000000000020A: C5 F8 10 12 vmovups xmm2,xmmword ptr [rdx] 000000000000020E: C4 E2 69 A8 C8 vfmadd213ps xmm1,xmm2,xmm0 0000000000000213: C5 F8 10 5A 10 vmovups xmm3,xmmword ptr [rdx+10h] 0000000000000218: C4 E2 79 18 61 04 vbroadcastss xmm4,dword ptr [rcx+4] 000000000000021E: C4 E2 61 A8 E1 vfmadd213ps xmm4,xmm3,xmm1 0000000000000223: C4 E2 79 18 49 08 vbroadcastss xmm1,dword ptr [rcx+8] 0000000000000229: C4 E2 69 A8 C8 vfmadd213ps xmm1,xmm2,xmm0 000000000000022E: C4 E2 79 18 69 0C vbroadcastss xmm5,dword ptr [rcx+0Ch] 0000000000000234: C4 E2 61 A8 E9 vfmadd213ps xmm5,xmm3,xmm1 0000000000000239: C4 E2 79 18 49 10 vbroadcastss xmm1,dword ptr [rcx+10h] 000000000000023F: C4 E2 69 A8 C8 vfmadd213ps xmm1,xmm2,xmm0 0000000000000244: C4 E2 79 18 41 14 vbroadcastss xmm0,dword ptr [rcx+14h] 000000000000024A: C4 E2 61 A8 C1 vfmadd213ps xmm0,xmm3,xmm1 000000000000024F: C4 C1 58 58 09 vaddps xmm1,xmm4,xmmword ptr [r9] 0000000000000254: C4 C1 50 58 51 10 vaddps xmm2,xmm5,xmmword ptr [r9+10h] 000000000000025A: C4 C1 78 58 41 20 vaddps xmm0,xmm0,xmmword ptr [r9+20h]","title":"Convenience syntax: kernelize"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#parallelize","text":"The parallelize instruction performs one or more loops in parallel on multiple cores. xeonPlat = acc . Target ( \"Intel 9221\" , num_threads = 16 ) plan = schedule . create_plan ( xeonPlat ) plan . parallelize ( indices = ( i , j , k )) Specifying multiple dimensions is equivalent to the collapse argument in OpenMP. Therefore, the dimensions must be contiguous in the iteration space dimension order.","title":"parallelize"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#static-scheduling-policy","text":"Static scheduling strategy is invoked by setting the argument policy=\"static\" in the call to parallelize . If n iterations are parallelized across c cores, the static scheduling partitions the work into c fixed parts, some of size floor(n/c) , some of size ceil(n/c) , and executes each part on a different core.","title":"Static scheduling policy"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#dynamic-scheduling-policy","text":"Dynamic scheduling strategy is invoked by setting the argument policy=\"dynamic\" in the call to parallelize . Dynamic scheduling creates a single work queue that is shared across different cores.","title":"Dynamic scheduling policy"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#not-yet-implemented-pinning-to-specific-cores","text":"The pin argument allows the parallel work to be pinned to specific cores.","title":"Not yet implemented: Pinning to specific cores"},{"location":"Manual/07%20Plans%20-%20Operations%20and%20Optimizations/#bind","text":"Some target platforms, such as GPUs, are specifically designed to execute nested loops. They can take an entire grid of work and schedule its execution on multiple cores. On a GPU, this grid is broken up into multiple blocks, where each block contains multiple threads. Block iterators and thread iterators are identified by special variables in the Target object. To take advantage of a target platform's ability to execute grids, we must bind dimensions of the iteration space with these special iterator variables. For example, v100 = acc . Target ( \"Tesla V100\" ) plan . bind ( mapping = { i : v100 . GridUnit . BLOCK_X , j : v100 . GridUnit . THREAD_X , k : v100 . GridUnit . THREAD_Y } )","title":"bind"},{"location":"Manual/08%20Deferred%20Layout%20of%20Constant%20Arrays/","text":"Section 8: Deferred layout of constant arrays Let's revisit the memory layout of constant arrays. As explained in Section 1 , the contents of constant arrays are known at compile-time, and these contents are immutable. Accera stores constant arrays in a non-standard memory layout optimized for a particular plan. In some cases, storing multiple copies of each array element may even prove advantageous (e.g., storing a matrix in row-major and column-major layouts). Deferred layout based on a cache Accera's cache strategy creates local copies of an array's active blocks. The constant array can be arranged based on the defined cache. Specifically, the array is stored by serializing the active blocks consecutively. If the caching strategy is thrifty=True , the active blocks are ready to use without copying the data. To define an array layout based on a cache, Accera DSL has to overcome the chicken-and-egg paradox. While on the one hand, arrays need to be defined even before the nest logic. On the other hand, array layout depends on a cache, which is defined only as a part of a plan. In Accera, we overcome this situation by splitting the array definition into two parts. Though we still define the constant array upfront, we avoid committing to a specific layout. import accera as acc import numpy as np matrix = np . random . rand ( 16 , 16 ) A = acc . Array ( role = acc . Array . Role . CONST , data = matrix , layout = acc . Array . Layout . DEFERRED ) Now we define the nest logic, the schedule, and the plan. Consider that we define a plan named plan and use this plan to define a cache A based on dimension i : AA = plan . cache ( A , i , layout = acc . Array . Layout . FIRST_MAJOR , thrifty = True ) We can now use the cache AA to determine the layout of the original array A : A . deferred_layout ( cache = AA )","title":"08 Deferred Layout of Constant Arrays"},{"location":"Manual/08%20Deferred%20Layout%20of%20Constant%20Arrays/#section-8-deferred-layout-of-constant-arrays","text":"Let's revisit the memory layout of constant arrays. As explained in Section 1 , the contents of constant arrays are known at compile-time, and these contents are immutable. Accera stores constant arrays in a non-standard memory layout optimized for a particular plan. In some cases, storing multiple copies of each array element may even prove advantageous (e.g., storing a matrix in row-major and column-major layouts).","title":"Section 8: Deferred layout of constant arrays"},{"location":"Manual/08%20Deferred%20Layout%20of%20Constant%20Arrays/#deferred-layout-based-on-a-cache","text":"Accera's cache strategy creates local copies of an array's active blocks. The constant array can be arranged based on the defined cache. Specifically, the array is stored by serializing the active blocks consecutively. If the caching strategy is thrifty=True , the active blocks are ready to use without copying the data. To define an array layout based on a cache, Accera DSL has to overcome the chicken-and-egg paradox. While on the one hand, arrays need to be defined even before the nest logic. On the other hand, array layout depends on a cache, which is defined only as a part of a plan. In Accera, we overcome this situation by splitting the array definition into two parts. Though we still define the constant array upfront, we avoid committing to a specific layout. import accera as acc import numpy as np matrix = np . random . rand ( 16 , 16 ) A = acc . Array ( role = acc . Array . Role . CONST , data = matrix , layout = acc . Array . Layout . DEFERRED ) Now we define the nest logic, the schedule, and the plan. Consider that we define a plan named plan and use this plan to define a cache A based on dimension i : AA = plan . cache ( A , i , layout = acc . Array . Layout . FIRST_MAJOR , thrifty = True ) We can now use the cache AA to determine the layout of the original array A : A . deferred_layout ( cache = AA )","title":"Deferred layout based on a cache"},{"location":"Manual/09%20Parameters/","text":"Section 9: Parameters Accera's parameters are placeholders that get replaced with concrete values when adding a function to a package. A parameter can be used in a Nest , a Schedule , or a Plan . Parameterized nests Recall that a Nest represents the loop-nest logic. We can parameterize the nest's shape and iteration logic. For example, consider the following parameterized version of matrix multiplication: # Create parameters P0 , P1 , P2 , P3 = acc . create_parameters () A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( P0 , P2 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( P2 , P1 )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( P0 , P1 )) # Define a simple nest nest = acc . Nest ( shape = ( P0 , P1 , P2 )) i , j , k = nest . get_indices () # Define the loop nest logic and add it to the nest @nest . iteration_logic def _ (): C [ i , j ] += P3 * A [ i , k ] * B [ k , j ] # create a package package = acc . Package () # Use the templated nest to add two different functions to the package package . add ( nest , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 }, base_name = \"matmul_16_16_16_1\" ) package . add ( nest , args = ( A , B , C ), parameters = { P0 : 32 , P1 : 32 , P2 : 32 , P3 : 2.0 }, base_name = \"matmul_32_32_32_2\" ) In the above scenario, the shape of the nest is parameterized by ( P0 , P1 , P2 ) and its iteration logic includes the parameter P3 . The nest is used twice with different settings of these parameters to create two separate functions in the package. Parameterized schedules and plans Parameters can also appear in schedules and plans. For example, we can add the following code snippet: P4 , P5 = acc . create_parameters () # Create a parameterized schedule schedule = nest . create_schedule () ii = schedule . split ( i , size = P4 ) # Create a parameterized plan plan = schedule . create_plan () plan . cache ( A , level = P5 ) # Add another function to the package package . add ( plan , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 , P4 : 4 , P5 : 2 }, base_name = \"alternative_matmul_16_16_16\" ) Supported operations Accera's parameters support the basic arithmetic operations and other relational/bitwise/intrinsics operations. For example, we can add the following code snippet instead: fma_unit_count , vector_size , P5 = acc . create_parameters () # Create a parameterized schedule schedule = nest . create_schedule () ii = schedule . split ( i , size = fma_unit_count * vector_size ) iii = schedule . split ( ii , size = vector_size ) # Create a parameterized plan plan = schedule . create_plan () plan . cache ( A , level = P5 ) # Add another function to the package package . add ( plan , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 , fma_unit_count : 4 , vector_size : 16 , P5 : 2 }, base_name = \"alternative_matmul_16_16_16\" ) The supported operations include the following operations: Arithmetic operators Operation Types Description a + b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the sum of parameters (or parameter and scalar) a and b a - b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the difference between parameters (or parameter and scalar) a and b a * b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the product of parameters (or parameter and scalar) a and b a / b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the quotient of parameters (or parameter and scalar) a and b a ** b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the b 'th power of parameter a a // b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the floor of the quotient of parameters (or parameter and scalar) a and b a % b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the signed remainder after dividing parameter a by parameter or scalar b -a acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the additive inverse of parameter a Comparison Operations Operation Types Description a == b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a equals parameter or scalar b , else False a != b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is not equal to parameter or scalar b , else False a < b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is strictly smaller than parameter or scalar b , else False a <= b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is smaller than or equal to parameter or scalar b , else False a > b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is strictly greater than parameter or scalar b , else False a >= b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is greater than or equal to parameter or scalar b , else False Bitwise operators Operation Types Description a & b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise AND of the bits in parameters (or parameter and scalar) a and b a \\| b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise OR of the bits in parameters (or parameter and scalar) a and b a ^ b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise XOR of the bits in parameters (or parameter and scalar) a and b ~a acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise inverse of the bits in parameter a a << b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns parameter a whose bitwise representation is shifted left by b bits a >> b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns parameter a whose bitwise representation is shifted right by b bits Intrinsics Operation Types Description acc.abs(a) acc.ScalarType.float16/32/64 Returns the absolute value of parameter a Tuple parameter values Parameters can be used as placeholders for tuples, specifically for tuples of indices. For example, assume that we want to parameterize the order of the iteration space dimensions. We can then write: P6 = acc . create_parameters () schedule . reorder ( order = P6 ) Later, we can set the value of P6 to the index tuple (j,k,i) . Create parameters from an entire parameter grid Consider the parameterized nest defined above. Rather than setting a specific value for each parameter, imagine that we have a set of different values for each parameter. For example, consider that we want P0 to have a value in set {8, 16} , P1 in {16, 32} , P2 to be always 16 , and P3 in {1,2} . We can define the parameter grid with this data, which lists all the valid parameter combinations. In our case, this grid includes the following parameter settings: { P0 : 8 , P1 : 16 , P2 : 16 , P3 : 1.0 } { P0 : 8 , P1 : 16 , P2 : 16 , P3 : 2.0 } { P0 : 8 , P1 : 32 , P2 : 16 , P3 : 1.0 } { P0 : 8 , P1 : 32 , P2 : 16 , P3 : 2.0 } { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 } { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 2.0 } { P0 : 16 , P1 : 32 , P2 : 16 , P3 : 1.0 } { P0 : 16 , P1 : 32 , P2 : 16 , P3 : 2.0 } Accera provides an easy way to add all the functions that correspond to the parameter grid at once: parameters = create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]) package . add ( nest , args = ( A , B , C ), base_name = \"matmul\" , parameters ) In this case, package.add generates a function eight times, once for each parameter combination in the grid. Other than nest , package.add can alternatively accept a Schedule (if we are performing schedule transformations), or a Plan (if we are setting target-specific options). All eight functions share the same base name. However, Accera automatically adds a unique suffix to each function name to prevent duplication. This pattern allows optional filtering by inspecting the generated parameter values list before calling package.add . You can define a lambda or function to filter out combinations from the parameter grid. The arguments to the filter are the values of a parameter combination, and it should return True if the combination should be included, and False otherwise: parameters = create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, filter_func = lambda p0 , p1 , p2 , p3 : p2 < p1 and 4 * ( p0 * p3 + p1 * p2 + p1 * p3 + p2 * p3 ) / 1024 < 256 ) To limit the size of the parameter grid (and therefore the number of functions generated) to at most 5: parameters = create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, sample = 5 ) If the parameter is a loop order which is a list or tuple of indices, create_parameter_grid can generate all the permutations of loop order. Furthermore, you can pass in a filter function to filter out invalid loop orders: parameters = create_parameter_grid ({ P0 :( i , j , k , ii , jj , kk )}, filter_func = lambda * p : schedule . is_valid_loop_order ( p [ 0 ][ 0 ])) Schedule.is_valid_loop_order() is a pre-defined filter function that determines if a given loop order is valid for that schedule. Note that the order of the list or tuple of indices provided to create_parameter_grid does not matter. To filter parameters with more complicated logic, you can define your own filter function that wraps Schedule.is_valid_loop_order() : def my_filter ( parameters_choice ): P1 , P2 , P3 , P4 , P5 , loop_order = parameters_choice return P1 > P2 \\ and P3 > P4 \\ and P1 * P5 < P3 \\ and P2 * P5 < P4 \\ and schedule . is_valid_loop_order ( loop_order ) parameters = acc . create_parameter_grid ({ P1 : [ 64 , 128 , 256 ], P2 : [ 32 , 128 ], P3 : [ 16 , 32 , 128 ], P4 : [ 8 , 64 ], P5 : [ 4 ], loop_order : ( i , j , k , ii , jj , kk ) }, my_filter )","title":"09 Parameters"},{"location":"Manual/09%20Parameters/#section-9-parameters","text":"Accera's parameters are placeholders that get replaced with concrete values when adding a function to a package. A parameter can be used in a Nest , a Schedule , or a Plan .","title":"Section 9: Parameters"},{"location":"Manual/09%20Parameters/#parameterized-nests","text":"Recall that a Nest represents the loop-nest logic. We can parameterize the nest's shape and iteration logic. For example, consider the following parameterized version of matrix multiplication: # Create parameters P0 , P1 , P2 , P3 = acc . create_parameters () A = acc . Array ( role = acc . Array . Role . INPUT , shape = ( P0 , P2 )) B = acc . Array ( role = acc . Array . Role . INPUT , shape = ( P2 , P1 )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , shape = ( P0 , P1 )) # Define a simple nest nest = acc . Nest ( shape = ( P0 , P1 , P2 )) i , j , k = nest . get_indices () # Define the loop nest logic and add it to the nest @nest . iteration_logic def _ (): C [ i , j ] += P3 * A [ i , k ] * B [ k , j ] # create a package package = acc . Package () # Use the templated nest to add two different functions to the package package . add ( nest , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 }, base_name = \"matmul_16_16_16_1\" ) package . add ( nest , args = ( A , B , C ), parameters = { P0 : 32 , P1 : 32 , P2 : 32 , P3 : 2.0 }, base_name = \"matmul_32_32_32_2\" ) In the above scenario, the shape of the nest is parameterized by ( P0 , P1 , P2 ) and its iteration logic includes the parameter P3 . The nest is used twice with different settings of these parameters to create two separate functions in the package.","title":"Parameterized nests"},{"location":"Manual/09%20Parameters/#parameterized-schedules-and-plans","text":"Parameters can also appear in schedules and plans. For example, we can add the following code snippet: P4 , P5 = acc . create_parameters () # Create a parameterized schedule schedule = nest . create_schedule () ii = schedule . split ( i , size = P4 ) # Create a parameterized plan plan = schedule . create_plan () plan . cache ( A , level = P5 ) # Add another function to the package package . add ( plan , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 , P4 : 4 , P5 : 2 }, base_name = \"alternative_matmul_16_16_16\" )","title":"Parameterized schedules and plans"},{"location":"Manual/09%20Parameters/#supported-operations","text":"Accera's parameters support the basic arithmetic operations and other relational/bitwise/intrinsics operations. For example, we can add the following code snippet instead: fma_unit_count , vector_size , P5 = acc . create_parameters () # Create a parameterized schedule schedule = nest . create_schedule () ii = schedule . split ( i , size = fma_unit_count * vector_size ) iii = schedule . split ( ii , size = vector_size ) # Create a parameterized plan plan = schedule . create_plan () plan . cache ( A , level = P5 ) # Add another function to the package package . add ( plan , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 , fma_unit_count : 4 , vector_size : 16 , P5 : 2 }, base_name = \"alternative_matmul_16_16_16\" ) The supported operations include the following operations:","title":"Supported operations"},{"location":"Manual/09%20Parameters/#arithmetic-operators","text":"Operation Types Description a + b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the sum of parameters (or parameter and scalar) a and b a - b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the difference between parameters (or parameter and scalar) a and b a * b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the product of parameters (or parameter and scalar) a and b a / b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the quotient of parameters (or parameter and scalar) a and b a ** b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the b 'th power of parameter a a // b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the floor of the quotient of parameters (or parameter and scalar) a and b a % b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the signed remainder after dividing parameter a by parameter or scalar b -a acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns the additive inverse of parameter a","title":"Arithmetic operators"},{"location":"Manual/09%20Parameters/#comparison-operations","text":"Operation Types Description a == b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a equals parameter or scalar b , else False a != b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is not equal to parameter or scalar b , else False a < b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is strictly smaller than parameter or scalar b , else False a <= b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is smaller than or equal to parameter or scalar b , else False a > b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is strictly greater than parameter or scalar b , else False a >= b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64, acc.ScalarType.float16/32/64 Returns True if parameter or scalar a is greater than or equal to parameter or scalar b , else False","title":"Comparison Operations"},{"location":"Manual/09%20Parameters/#bitwise-operators","text":"Operation Types Description a & b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise AND of the bits in parameters (or parameter and scalar) a and b a \\| b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise OR of the bits in parameters (or parameter and scalar) a and b a ^ b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise XOR of the bits in parameters (or parameter and scalar) a and b ~a acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns the bitwise inverse of the bits in parameter a a << b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns parameter a whose bitwise representation is shifted left by b bits a >> b acc.DelayedParameter, acc.ScalarType.int8/16/32/64, acc.ScalarType.uint8/16/32/64 Returns parameter a whose bitwise representation is shifted right by b bits","title":"Bitwise operators"},{"location":"Manual/09%20Parameters/#intrinsics","text":"Operation Types Description acc.abs(a) acc.ScalarType.float16/32/64 Returns the absolute value of parameter a","title":"Intrinsics"},{"location":"Manual/09%20Parameters/#tuple-parameter-values","text":"Parameters can be used as placeholders for tuples, specifically for tuples of indices. For example, assume that we want to parameterize the order of the iteration space dimensions. We can then write: P6 = acc . create_parameters () schedule . reorder ( order = P6 ) Later, we can set the value of P6 to the index tuple (j,k,i) .","title":"Tuple parameter values"},{"location":"Manual/09%20Parameters/#create-parameters-from-an-entire-parameter-grid","text":"Consider the parameterized nest defined above. Rather than setting a specific value for each parameter, imagine that we have a set of different values for each parameter. For example, consider that we want P0 to have a value in set {8, 16} , P1 in {16, 32} , P2 to be always 16 , and P3 in {1,2} . We can define the parameter grid with this data, which lists all the valid parameter combinations. In our case, this grid includes the following parameter settings: { P0 : 8 , P1 : 16 , P2 : 16 , P3 : 1.0 } { P0 : 8 , P1 : 16 , P2 : 16 , P3 : 2.0 } { P0 : 8 , P1 : 32 , P2 : 16 , P3 : 1.0 } { P0 : 8 , P1 : 32 , P2 : 16 , P3 : 2.0 } { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1.0 } { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 2.0 } { P0 : 16 , P1 : 32 , P2 : 16 , P3 : 1.0 } { P0 : 16 , P1 : 32 , P2 : 16 , P3 : 2.0 } Accera provides an easy way to add all the functions that correspond to the parameter grid at once: parameters = create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]) package . add ( nest , args = ( A , B , C ), base_name = \"matmul\" , parameters ) In this case, package.add generates a function eight times, once for each parameter combination in the grid. Other than nest , package.add can alternatively accept a Schedule (if we are performing schedule transformations), or a Plan (if we are setting target-specific options). All eight functions share the same base name. However, Accera automatically adds a unique suffix to each function name to prevent duplication. This pattern allows optional filtering by inspecting the generated parameter values list before calling package.add . You can define a lambda or function to filter out combinations from the parameter grid. The arguments to the filter are the values of a parameter combination, and it should return True if the combination should be included, and False otherwise: parameters = create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, filter_func = lambda p0 , p1 , p2 , p3 : p2 < p1 and 4 * ( p0 * p3 + p1 * p2 + p1 * p3 + p2 * p3 ) / 1024 < 256 ) To limit the size of the parameter grid (and therefore the number of functions generated) to at most 5: parameters = create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, sample = 5 ) If the parameter is a loop order which is a list or tuple of indices, create_parameter_grid can generate all the permutations of loop order. Furthermore, you can pass in a filter function to filter out invalid loop orders: parameters = create_parameter_grid ({ P0 :( i , j , k , ii , jj , kk )}, filter_func = lambda * p : schedule . is_valid_loop_order ( p [ 0 ][ 0 ])) Schedule.is_valid_loop_order() is a pre-defined filter function that determines if a given loop order is valid for that schedule. Note that the order of the list or tuple of indices provided to create_parameter_grid does not matter. To filter parameters with more complicated logic, you can define your own filter function that wraps Schedule.is_valid_loop_order() : def my_filter ( parameters_choice ): P1 , P2 , P3 , P4 , P5 , loop_order = parameters_choice return P1 > P2 \\ and P3 > P4 \\ and P1 * P5 < P3 \\ and P2 * P5 < P4 \\ and schedule . is_valid_loop_order ( loop_order ) parameters = acc . create_parameter_grid ({ P1 : [ 64 , 128 , 256 ], P2 : [ 32 , 128 ], P3 : [ 16 , 32 , 128 ], P4 : [ 8 , 64 ], P5 : [ 4 ], loop_order : ( i , j , k , ii , jj , kk ) }, my_filter )","title":"Create parameters from an entire parameter grid"},{"location":"Manual/10%20Packages/","text":"Section 10: Building Packages The Package class represents a collection of Accera-generated functions. Whenever a package is built, it creates a stand-alone function library that other pieces of software can use. Currently, Accera supports two package formats: HAT and MLIR. HAT package format HAT \"Header Annotated with TOML\" is a format for packaging compiled libraries in the C programming language. HAT implies that a standard C header is styled with useful metadata in the TOML markup language. Consider a nest that holds some loop-nest logic. To build a HAT package containing a function with this logic for the Windows operating system, we write the following lines of code: package = acc . Package () package . add ( nest , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , platform = acc . Packag +- e . Platform . WINDOWS ) The result is two files: myPackage.hat and myPackage.dll . The output directory defaults to current working directory. We can change the output directory with output_dir set to a relative or absolute path: package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , platform = acc . Package . Platform . WINDOWS , output_dir = \"hat_packages\" ) MLIR package format MLIR format is used for debugging the multiple stages of MLIR lowering, from the Accera DSL all the way to runnable code. package . build ( format = acc . Package . Format . MLIR , name = \"myPackage\" ) Function names in packages We can specify the base name of a function when it is added to a package. The full function name is the base name followed by an automatically generated unique identifier. For example, if the base name is \"myFunc\" then the function name could be \"myFunc_8f24bef5\". If no base name is defined, the automatically-generated unique identifier becomes the function name. The unique identifier ensures that no two functions share the same name. However, invoking the function from the client code becomes cumbersome because the function name changes each time the Accera package is updated and rebuilt. Therefore, the HAT file includes the client code to call the function without the unique identifier. Concretely, if the function signature in C is: void myFunc_8f24bef5(const float* A, float* B); then the HAT file also contains the line: void (*myFunc)(const float* A, float* B) = myFunc_8f24bef5; The above code makes the abbreviated name myFunc an alias of the full function name myFunc_8f24bef5 . If multiple functions share the same base name, the first function in the HAT file gets the alias. Debug mode A package can be built with mode=acc.Package.Mode.DEBUG . Doing so creates a special version of each function that validates its own correctness every time the function is called. From the outside, a debugging package looks identical to a standard package. However, each of its functions actually contains two different implementations: the Accera implementation (with all of the fancy scheduling and planning) and the trivial default implementation (without any scheduling or planning). When called, the function runs both implementations and asserts that their outputs are within the predefined tolerance. If the outputs don't match, the function prints error messages to stderr . package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , mode = acc . Package . Mode . DEBUG , tolerance = 1.0e-6 ) Not yet implemented: Debug mode is not supported for GPU targets. Adding descriptions Accera allows us to specify some standard descriptive fields in a package: package . add_description ( version = \"1.0\" , license = \"https://mit-license.org/\" , author = \"Microsoft Research\" ) Additionally, we can add arbitrary metadata to the package description as follows: package . add_description ( other = { \"title\" : \"My Package Title\" , \"source\" : \"https://github.com/\" , \"citations\" : [ \"https://arxiv.org/2021.12345/\" , \"https://arxiv.org/2021.56789/\" ]})","title":"10 Packages"},{"location":"Manual/10%20Packages/#section-10-building-packages","text":"The Package class represents a collection of Accera-generated functions. Whenever a package is built, it creates a stand-alone function library that other pieces of software can use. Currently, Accera supports two package formats: HAT and MLIR.","title":"Section 10: Building Packages"},{"location":"Manual/10%20Packages/#hat-package-format","text":"HAT \"Header Annotated with TOML\" is a format for packaging compiled libraries in the C programming language. HAT implies that a standard C header is styled with useful metadata in the TOML markup language. Consider a nest that holds some loop-nest logic. To build a HAT package containing a function with this logic for the Windows operating system, we write the following lines of code: package = acc . Package () package . add ( nest , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , platform = acc . Packag +- e . Platform . WINDOWS ) The result is two files: myPackage.hat and myPackage.dll . The output directory defaults to current working directory. We can change the output directory with output_dir set to a relative or absolute path: package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , platform = acc . Package . Platform . WINDOWS , output_dir = \"hat_packages\" )","title":"HAT package format"},{"location":"Manual/10%20Packages/#mlir-package-format","text":"MLIR format is used for debugging the multiple stages of MLIR lowering, from the Accera DSL all the way to runnable code. package . build ( format = acc . Package . Format . MLIR , name = \"myPackage\" )","title":"MLIR package format"},{"location":"Manual/10%20Packages/#function-names-in-packages","text":"We can specify the base name of a function when it is added to a package. The full function name is the base name followed by an automatically generated unique identifier. For example, if the base name is \"myFunc\" then the function name could be \"myFunc_8f24bef5\". If no base name is defined, the automatically-generated unique identifier becomes the function name. The unique identifier ensures that no two functions share the same name. However, invoking the function from the client code becomes cumbersome because the function name changes each time the Accera package is updated and rebuilt. Therefore, the HAT file includes the client code to call the function without the unique identifier. Concretely, if the function signature in C is: void myFunc_8f24bef5(const float* A, float* B); then the HAT file also contains the line: void (*myFunc)(const float* A, float* B) = myFunc_8f24bef5; The above code makes the abbreviated name myFunc an alias of the full function name myFunc_8f24bef5 . If multiple functions share the same base name, the first function in the HAT file gets the alias.","title":"Function names in packages"},{"location":"Manual/10%20Packages/#debug-mode","text":"A package can be built with mode=acc.Package.Mode.DEBUG . Doing so creates a special version of each function that validates its own correctness every time the function is called. From the outside, a debugging package looks identical to a standard package. However, each of its functions actually contains two different implementations: the Accera implementation (with all of the fancy scheduling and planning) and the trivial default implementation (without any scheduling or planning). When called, the function runs both implementations and asserts that their outputs are within the predefined tolerance. If the outputs don't match, the function prints error messages to stderr . package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , mode = acc . Package . Mode . DEBUG , tolerance = 1.0e-6 ) Not yet implemented: Debug mode is not supported for GPU targets.","title":"Debug mode"},{"location":"Manual/10%20Packages/#adding-descriptions","text":"Accera allows us to specify some standard descriptive fields in a package: package . add_description ( version = \"1.0\" , license = \"https://mit-license.org/\" , author = \"Microsoft Research\" ) Additionally, we can add arbitrary metadata to the package description as follows: package . add_description ( other = { \"title\" : \"My Package Title\" , \"source\" : \"https://github.com/\" , \"citations\" : [ \"https://arxiv.org/2021.12345/\" , \"https://arxiv.org/2021.56789/\" ]})","title":"Adding descriptions"},{"location":"Reference/accera/","text":"Accera v1.2.7 Reference Module functions accera.cast (value, type) accera.create_parameters (number) accera.create_parameter_grid (parameter_choices, filter_func, sample) accera.fuse (schedules[, partial]) Top level enumerations accera.ScalarType accera.MMASchedulingPolicy accera.MMAShape Classes class accera.Plan A scheduled (ordered) loop nest with target-specific implementation details. Methods cache (source[, index, layout, level, max_elements, thrifty, type]) bind (indices, grid) kernelize (unroll_indices, vectorize_indices) parallelize (indices[, pin, policy]) unroll (index) vectorize (index) class accera.Array A multidimensional array of scalar elements. Constructors Array (role[, data, element_type, layout, offset, shape]) Enumerations accera.Array.Layout accera.Array.Role Methods deferred_layout (layout) class accera.Cache A local copy of an Array block. class accera.Index An index representing one of the loops in a Nest or one of the iteration-space dimensions of a Schedule or a Plan . class accera.Nest The logic of a loop nest. Constructors Nest (shape) Methods iteration_logic (logic) create_plan ([target]) create_schedule () get_indices () class accera.Package Represents a collection of functions that can be built and emitted for use in client code. Constructors Package () Enumerations accera.Package.Format accera.Package.Mode accera.Package.Platform Methods add_description ([author, license, other, version]) add (args, source[, base_name, parameters]) build (name[, error_path, format, mode, os, tolerance]) class accera.Parameter A placeholder that can be used instead of concrete values when constructing or calling the methods of a Nest , Schedule , or Plan . class accera.Schedule A scheduled (ordered) loop nest with no target-specific implementation details. Methods create_plan ([target]) pad (index, size) reorder (indices) skew (index, reference_index) split (index, size) tile (indices, sizes) class accera.Target A target platform for the cross-compiler. Constructors Target ([architecture, cache_lines, cache_sizes, category, extensions, family, frequency_GHz, model, name, num_cores, num_threads, turbo_frequency_GHz]) Enumerations accera.Target.Architecture accera.Target.Category accera.Target.Models","title":"Accera"},{"location":"Reference/accera/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/accera/#module-functions","text":"accera.cast (value, type) accera.create_parameters (number) accera.create_parameter_grid (parameter_choices, filter_func, sample) accera.fuse (schedules[, partial])","title":"Module functions"},{"location":"Reference/accera/#top-level-enumerations","text":"accera.ScalarType accera.MMASchedulingPolicy accera.MMAShape","title":"Top level enumerations"},{"location":"Reference/accera/#classes","text":"","title":"Classes"},{"location":"Reference/accera/#class-acceraplan","text":"A scheduled (ordered) loop nest with target-specific implementation details.","title":"class accera.Plan"},{"location":"Reference/accera/#methods","text":"cache (source[, index, layout, level, max_elements, thrifty, type]) bind (indices, grid) kernelize (unroll_indices, vectorize_indices) parallelize (indices[, pin, policy]) unroll (index) vectorize (index)","title":"Methods"},{"location":"Reference/accera/#class-acceraarray","text":"A multidimensional array of scalar elements.","title":"class accera.Array"},{"location":"Reference/accera/#constructors","text":"Array (role[, data, element_type, layout, offset, shape])","title":"Constructors"},{"location":"Reference/accera/#enumerations","text":"accera.Array.Layout accera.Array.Role","title":"Enumerations"},{"location":"Reference/accera/#methods_1","text":"deferred_layout (layout)","title":"Methods"},{"location":"Reference/accera/#class-acceracache","text":"A local copy of an Array block.","title":"class accera.Cache"},{"location":"Reference/accera/#class-acceraindex","text":"An index representing one of the loops in a Nest or one of the iteration-space dimensions of a Schedule or a Plan .","title":"class accera.Index"},{"location":"Reference/accera/#class-acceranest","text":"The logic of a loop nest.","title":"class accera.Nest"},{"location":"Reference/accera/#constructors_1","text":"Nest (shape)","title":"Constructors"},{"location":"Reference/accera/#methods_2","text":"iteration_logic (logic) create_plan ([target]) create_schedule () get_indices ()","title":"Methods"},{"location":"Reference/accera/#class-accerapackage","text":"Represents a collection of functions that can be built and emitted for use in client code.","title":"class accera.Package"},{"location":"Reference/accera/#constructors_2","text":"Package ()","title":"Constructors"},{"location":"Reference/accera/#enumerations_1","text":"accera.Package.Format accera.Package.Mode accera.Package.Platform","title":"Enumerations"},{"location":"Reference/accera/#methods_3","text":"add_description ([author, license, other, version]) add (args, source[, base_name, parameters]) build (name[, error_path, format, mode, os, tolerance])","title":"Methods"},{"location":"Reference/accera/#class-acceraparameter","text":"A placeholder that can be used instead of concrete values when constructing or calling the methods of a Nest , Schedule , or Plan .","title":"class accera.Parameter"},{"location":"Reference/accera/#class-acceraschedule","text":"A scheduled (ordered) loop nest with no target-specific implementation details.","title":"class accera.Schedule"},{"location":"Reference/accera/#methods_4","text":"create_plan ([target]) pad (index, size) reorder (indices) skew (index, reference_index) split (index, size) tile (indices, sizes)","title":"Methods"},{"location":"Reference/accera/#class-acceratarget","text":"A target platform for the cross-compiler.","title":"class accera.Target"},{"location":"Reference/accera/#constructors_3","text":"Target ([architecture, cache_lines, cache_sizes, category, extensions, family, frequency_GHz, model, name, num_cores, num_threads, turbo_frequency_GHz])","title":"Constructors"},{"location":"Reference/accera/#enumerations_2","text":"accera.Target.Architecture accera.Target.Category accera.Target.Models","title":"Enumerations"},{"location":"Reference/safety_analysis/","text":"Accera v1.2.7 Reference Safety Analysis One of the most important features in Accera is to provide safety guarantees to preserve the underlying logic no matter how we transform the schedule. Not all Accera schedules are safe, but those that are safe are much easier to work with. Order-invariant Schedules Order-invariant schedules are always safe because Accera transformations never remove any iterations. They only change the order of the loop-nest iterations, or add empty iterations in the form of padding when necessary. Recall that a Nest represents a simple nest. A simple nest is assumed to be order-invariant, and therefore any schedule created by a call to create_schedule() is safe. Safety and Fusing Fusing is another way to create a schedule (see Section 4 of the Accera manual ). Say that we have a sequence of n schedules: schedule0 , schedule1 , ... and we partially fuse their first m dimensions. Namely: schedule = acc . fuse (( schedule0 , schedule1 , ... ), partial = m ) At this point, schedule is equivalent to sequentially executing the individual schedules. However, is the fused schedule safe? In other words, does schedule guarantee the preservation of underlying logic, regardless of the applied transformation? The dimensions of schedule fall into three categories: Fusing dimensions : at first, this category contains a single dimension, the first dimension of schedule . However, if this dimension is split, its derived dimensions are added to this category. Fused dimensions : at first, this category contains the next m dimensions of schedule . If any of these dimensions are split, the derived dimensions are also added to this category. Unfused dimensions : all the remaining dimensions. Note that the individual schedules being fused may have been created by previous fusing operations. The categories above relate to the role of each dimension in the current fusing operation. Theorem Imagine that we apply a sequence of transformations to schedule , which may derive new dimensions. Derived dimensions belong to the same category as the dimension from which they were derived. Suppose the fusing dimension (and its derived dimensions) precedes all the unfused dimensions. In that case, for any value of the fused dimensions, all the corresponding work from schedule0 is executed before any of the corresponding work from schedule1 . Similarly, all the corresponding work from schedule1 is executed before any of the corresponding work from schedule2 ; and so on. Proof For simplicity, assume that there is only one fusing dimension, f . Also, assume that we've only fused two schedules, schedule0 and schedule1 . Note that these simplifying assumptions can easily be relaxed. Assume that f precedes all of the unfused dimensions. Therefore, dimensions that precede f are necessarily fused dimensions. Let U be a sequence of concrete values for all the fused dimensions, and let V denote only those values that correspond to dimensions that precede f . The work from schedule0 that corresponds to the concrete values in U is contained in the slice (V, 0, *, ..., *). Similarly, the work form schedule1 that corresponds to the values in U is contained in (V, 1, *, ..., *). Finally, note that the former slice lexicographically precedes the latter, concluding the proof. An example To make the theorem less abstract, we demonstrate how it applies to a simple example. Assume that we start with two three-dimensional schedules, schedule0 and schedule1 , and we fuse their first two dimensions: i0 , j0 , k0 = schedule0 . get_indices () # redundant operation, included for clarity i1 , j1 , k1 = schedule1 . get_indices () # redundant operation, included for clarity schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k0 , k1 = schedule . get_indices () Next, say that we transform schedule by tiling dimensions j and k0 to reorder the dimensions as follows: jj , kk0 = schedule . tile ({ j : 4 , k0 : 4 }) schedule . reorder ( j , i , f , k0 , k1 , kk0 , jj ) Dimensions i , j , and jj are fused dimensions, while k0 , kk0 , and k1 are unfused dimensions. Note that the fusing dimension f precedes all of the unfused dimensions, satisfying the theorem's condition. Next, choose concrete values for the fused dimensions, say, i=4 , j=3 , and jj=2 . The work from schedule0 that corresponds to these values is contained in the slice (3, 4, 0, *, *, *, *). Similarly, the work from schedule1 that corresponds to these values is contained in the slice (3, 4, 1, *, *, *, *). The former slice lexicographically precedes the latter and is therefore executed first. Safety The theorem holds for any schedule, but it does not imply that every schedule is safe. Additional effort is required to prove whether a specific schedule is safe. When performing a fuse operation, we must examine the specific circumstances and consider whether the theorem provides a sufficient condition for safety.","title":"Safety analysis"},{"location":"Reference/safety_analysis/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/safety_analysis/#safety-analysis","text":"One of the most important features in Accera is to provide safety guarantees to preserve the underlying logic no matter how we transform the schedule. Not all Accera schedules are safe, but those that are safe are much easier to work with.","title":"Safety Analysis"},{"location":"Reference/safety_analysis/#order-invariant-schedules","text":"Order-invariant schedules are always safe because Accera transformations never remove any iterations. They only change the order of the loop-nest iterations, or add empty iterations in the form of padding when necessary. Recall that a Nest represents a simple nest. A simple nest is assumed to be order-invariant, and therefore any schedule created by a call to create_schedule() is safe.","title":"Order-invariant Schedules"},{"location":"Reference/safety_analysis/#safety-and-fusing","text":"Fusing is another way to create a schedule (see Section 4 of the Accera manual ). Say that we have a sequence of n schedules: schedule0 , schedule1 , ... and we partially fuse their first m dimensions. Namely: schedule = acc . fuse (( schedule0 , schedule1 , ... ), partial = m ) At this point, schedule is equivalent to sequentially executing the individual schedules. However, is the fused schedule safe? In other words, does schedule guarantee the preservation of underlying logic, regardless of the applied transformation? The dimensions of schedule fall into three categories: Fusing dimensions : at first, this category contains a single dimension, the first dimension of schedule . However, if this dimension is split, its derived dimensions are added to this category. Fused dimensions : at first, this category contains the next m dimensions of schedule . If any of these dimensions are split, the derived dimensions are also added to this category. Unfused dimensions : all the remaining dimensions. Note that the individual schedules being fused may have been created by previous fusing operations. The categories above relate to the role of each dimension in the current fusing operation.","title":"Safety and Fusing"},{"location":"Reference/safety_analysis/#theorem","text":"Imagine that we apply a sequence of transformations to schedule , which may derive new dimensions. Derived dimensions belong to the same category as the dimension from which they were derived. Suppose the fusing dimension (and its derived dimensions) precedes all the unfused dimensions. In that case, for any value of the fused dimensions, all the corresponding work from schedule0 is executed before any of the corresponding work from schedule1 . Similarly, all the corresponding work from schedule1 is executed before any of the corresponding work from schedule2 ; and so on.","title":"Theorem"},{"location":"Reference/safety_analysis/#proof","text":"For simplicity, assume that there is only one fusing dimension, f . Also, assume that we've only fused two schedules, schedule0 and schedule1 . Note that these simplifying assumptions can easily be relaxed. Assume that f precedes all of the unfused dimensions. Therefore, dimensions that precede f are necessarily fused dimensions. Let U be a sequence of concrete values for all the fused dimensions, and let V denote only those values that correspond to dimensions that precede f . The work from schedule0 that corresponds to the concrete values in U is contained in the slice (V, 0, *, ..., *). Similarly, the work form schedule1 that corresponds to the values in U is contained in (V, 1, *, ..., *). Finally, note that the former slice lexicographically precedes the latter, concluding the proof.","title":"Proof"},{"location":"Reference/safety_analysis/#an-example","text":"To make the theorem less abstract, we demonstrate how it applies to a simple example. Assume that we start with two three-dimensional schedules, schedule0 and schedule1 , and we fuse their first two dimensions: i0 , j0 , k0 = schedule0 . get_indices () # redundant operation, included for clarity i1 , j1 , k1 = schedule1 . get_indices () # redundant operation, included for clarity schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k0 , k1 = schedule . get_indices () Next, say that we transform schedule by tiling dimensions j and k0 to reorder the dimensions as follows: jj , kk0 = schedule . tile ({ j : 4 , k0 : 4 }) schedule . reorder ( j , i , f , k0 , k1 , kk0 , jj ) Dimensions i , j , and jj are fused dimensions, while k0 , kk0 , and k1 are unfused dimensions. Note that the fusing dimension f precedes all of the unfused dimensions, satisfying the theorem's condition. Next, choose concrete values for the fused dimensions, say, i=4 , j=3 , and jj=2 . The work from schedule0 that corresponds to these values is contained in the slice (3, 4, 0, *, *, *, *). Similarly, the work from schedule1 that corresponds to these values is contained in the slice (3, 4, 1, *, *, *, *). The former slice lexicographically precedes the latter and is therefore executed first.","title":"An example"},{"location":"Reference/safety_analysis/#safety","text":"The theorem holds for any schedule, but it does not imply that every schedule is safe. Additional effort is required to prove whether a specific schedule is safe. When performing a fuse operation, we must examine the specific circumstances and consider whether the theorem provides a sufficient condition for safety.","title":"Safety"},{"location":"Reference/classes/Array/Array/","text":"Accera v1.2.7 Reference accera.Array(role[, data, element_type, layout, offset, shape]) Constructs an array. Arguments argument description type/default role The role of the array determines if the array scope is internal or external and if the array is mutable or immutable. accera.Array.Role data The contents of a constant array. Required for accera.Array,Role.CONST arrays but should not be specified for other roles. Python buffer or numpy.ndarray . element_type The array element type. accera.ScalarType , default: accera.ScalarType.float32 . layout The affine memory map. tuple of integers or accera.Array.Layout , default: accera.Array.Layout.FIRST_MAJOR . offset The offset of the affine memory map integer (positive, zero, or negative), default: 0. shape The array shape. Required for roles other than accera.Array.Role.CONST , should not be specified for accera.Array.Role.CONST . Examples Construct an input array: import accera as acc A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) # the default layout is acc.Array.Layout.FIRST_MAJOR Construct an input array with an explicit standard layout: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 ), layout = acc . Array . Layout . LAST_MAJOR ) Construct an input array with an explicit affine memory map: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 ), layout = ( 1 , 10 )) Construct an input array with an infinite (undefined) major dimension: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , acc . inf ), layout = acc . Array . Layout . LAST_MAJOR ) Construct an input/output array: A = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) Construct a constant array: D = np . random . rand ( 10 , 16 ) A = acc . Array ( role = acc . Array . Role . CONST , data = D ) Construct a constant array with an explicit element type and layout, which does not necessarily match the input data: D = np . random . rand ( 10 , 16 ) A = acc . Array ( role = acc . Array . Role . CONST , element_type = acc . ScalarType . float32 , layout = acc . Array . Layout . LAST_MAJOR , data = D ) Construct a temporary array: A = acc . Array ( role = acc . Array . Role . TEMP , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 ), layout = acc . Array . Layout . LAST_MAJOR )","title":"Array"},{"location":"Reference/classes/Array/Array/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Array/Array/#acceraarrayrole-data-element_type-layout-offset-shape","text":"Constructs an array.","title":"accera.Array(role[, data, element_type, layout, offset, shape])"},{"location":"Reference/classes/Array/Array/#arguments","text":"argument description type/default role The role of the array determines if the array scope is internal or external and if the array is mutable or immutable. accera.Array.Role data The contents of a constant array. Required for accera.Array,Role.CONST arrays but should not be specified for other roles. Python buffer or numpy.ndarray . element_type The array element type. accera.ScalarType , default: accera.ScalarType.float32 . layout The affine memory map. tuple of integers or accera.Array.Layout , default: accera.Array.Layout.FIRST_MAJOR . offset The offset of the affine memory map integer (positive, zero, or negative), default: 0. shape The array shape. Required for roles other than accera.Array.Role.CONST , should not be specified for accera.Array.Role.CONST .","title":"Arguments"},{"location":"Reference/classes/Array/Array/#examples","text":"Construct an input array: import accera as acc A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) # the default layout is acc.Array.Layout.FIRST_MAJOR Construct an input array with an explicit standard layout: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 ), layout = acc . Array . Layout . LAST_MAJOR ) Construct an input array with an explicit affine memory map: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 ), layout = ( 1 , 10 )) Construct an input array with an infinite (undefined) major dimension: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , acc . inf ), layout = acc . Array . Layout . LAST_MAJOR ) Construct an input/output array: A = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) Construct a constant array: D = np . random . rand ( 10 , 16 ) A = acc . Array ( role = acc . Array . Role . CONST , data = D ) Construct a constant array with an explicit element type and layout, which does not necessarily match the input data: D = np . random . rand ( 10 , 16 ) A = acc . Array ( role = acc . Array . Role . CONST , element_type = acc . ScalarType . float32 , layout = acc . Array . Layout . LAST_MAJOR , data = D ) Construct a temporary array: A = acc . Array ( role = acc . Array . Role . TEMP , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 ), layout = acc . Array . Layout . LAST_MAJOR )","title":"Examples"},{"location":"Reference/classes/Array/Layout/","text":"Accera v1.2.7 Reference accera.Array.Layout type description accera.Array.Layout.FIRST_MAJOR Specifies a memory layout where the first major axis is in contiguous memory. For example, in a matrix, this corresponds to \"row-major\". accera.Array.Layout.LAST_MAJOR Specifies a memory layout where the last major axis is in contiguous memory. For example, in a matrix, this corresponds to \"column-major\". accera.Array.Layout.DEFERRED Defer specifying the memory layout for an Array.Role.CONST array until a cache is created.","title":"Layout"},{"location":"Reference/classes/Array/Layout/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Array/Layout/#acceraarraylayout","text":"type description accera.Array.Layout.FIRST_MAJOR Specifies a memory layout where the first major axis is in contiguous memory. For example, in a matrix, this corresponds to \"row-major\". accera.Array.Layout.LAST_MAJOR Specifies a memory layout where the last major axis is in contiguous memory. For example, in a matrix, this corresponds to \"column-major\". accera.Array.Layout.DEFERRED Defer specifying the memory layout for an Array.Role.CONST array until a cache is created.","title":"accera.Array.Layout"},{"location":"Reference/classes/Array/Role/","text":"Accera v1.2.7 Reference accera.Array.Role type description accera.Array.Role.CONST A constant array (immutable internally scoped) whose contents are known at compile-time. accera.Array.Role.INPUT An input array (immutable external-scope). accera.Array.Role.INPUT_OUTPUT An input/output array (mutable external-scope). accera.Array.Role.TEMP A temporary array (mutable internal-scope).","title":"Role"},{"location":"Reference/classes/Array/Role/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Array/Role/#acceraarrayrole","text":"type description accera.Array.Role.CONST A constant array (immutable internally scoped) whose contents are known at compile-time. accera.Array.Role.INPUT An input array (immutable external-scope). accera.Array.Role.INPUT_OUTPUT An input/output array (mutable external-scope). accera.Array.Role.TEMP A temporary array (mutable internal-scope).","title":"accera.Array.Role"},{"location":"Reference/classes/Array/deferred_layout/","text":"Accera v1.2.7 Reference accera.Array.deferred_layout(cache) Specifies the layout for a Array.Role.CONST array based on a Cache . For more details, see Deferred layout of constant arrays Arguments argument description type/default cache The cache that defines the layout to set. accera.Cache Examples Create a constant 16x16 array without specifying a layout. Later on, define its layout based on a cache: import numpy as np import accera as acc matrix = np . random . rand ( 16 , 16 ) # Create a constant array with a deferred layout A = acc . Array ( role = acc . Array . Role . CONST , data = matrix , layout = acc . Array . Layout . DEFERRED ) B = Array ( role = Array . Role . INPUT_OUTPUT , element_type = ScalarType . float32 , shape = matrix . shape ) nest = Nest ( shape = matrix . shape ) i , j = nest . get_indices () @nest . iteration_logic def_ (): B [ i , j ] += A [ i , j ] plan = nest . create_plan () # create a cache for the constant array AA = plan . cache ( A , i , layout = acc . Array . Layout . FIRST_MAJOR , thrifty = True ) # update the constant array's layout based on the cache A . deferred_layout ( cache = AA )","title":"Deferred layout"},{"location":"Reference/classes/Array/deferred_layout/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Array/deferred_layout/#acceraarraydeferred_layoutcache","text":"Specifies the layout for a Array.Role.CONST array based on a Cache . For more details, see Deferred layout of constant arrays","title":"accera.Array.deferred_layout(cache)"},{"location":"Reference/classes/Array/deferred_layout/#arguments","text":"argument description type/default cache The cache that defines the layout to set. accera.Cache","title":"Arguments"},{"location":"Reference/classes/Array/deferred_layout/#examples","text":"Create a constant 16x16 array without specifying a layout. Later on, define its layout based on a cache: import numpy as np import accera as acc matrix = np . random . rand ( 16 , 16 ) # Create a constant array with a deferred layout A = acc . Array ( role = acc . Array . Role . CONST , data = matrix , layout = acc . Array . Layout . DEFERRED ) B = Array ( role = Array . Role . INPUT_OUTPUT , element_type = ScalarType . float32 , shape = matrix . shape ) nest = Nest ( shape = matrix . shape ) i , j = nest . get_indices () @nest . iteration_logic def_ (): B [ i , j ] += A [ i , j ] plan = nest . create_plan () # create a cache for the constant array AA = plan . cache ( A , i , layout = acc . Array . Layout . FIRST_MAJOR , thrifty = True ) # update the constant array's layout based on the cache A . deferred_layout ( cache = AA )","title":"Examples"},{"location":"Reference/classes/Array/sub_array/","text":"Accera v1.2.7 Reference accera.Array.sub_array(offsets, shape, strides) Creates a sub-array of a specific shape from an array. The sub-array is created from elements at specified offsets and strides into the original array. Arguments argument description type/default offsets The offsets into the original array. Tuple[int] shape The size of the sub-array. Tuple[int] strides (Optional) The strides in the original array used to create the sub-array. Tuple[int] Examples Create a sub-array of size 2x3 from an array of size 5x5 at an offset of {1, 1} and a stride of {2, 1}: import numpy as np import accera as acc N = 5 subArrayNumRows = 2 subArrayNumCols = 3 matrix = np . random . rand ( N , N ) Arr = Array ( role = Array . Role . INPUT , data = matrix ) # Zero out a sub array of size [2, 3] such that the resulting array looks like this: # xxxxx # x000x # xxxxx # x000x # xxxxx nest = Nest ( shape = ( subArrayNumRows , subArrayNumCols )) i , j = nest . get_indices () @nest . iteration_logic def _ (): SubArr = Arr . sub_array ([ 1 , 1 ], [ subArrayNumRows , subArrayNumCols ], [ 2 , 1 ]) SubArr [ i , j ] = 0.0 schedule = nest . create_schedule ()","title":"Sub array"},{"location":"Reference/classes/Array/sub_array/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Array/sub_array/#acceraarraysub_arrayoffsets-shape-strides","text":"Creates a sub-array of a specific shape from an array. The sub-array is created from elements at specified offsets and strides into the original array.","title":"accera.Array.sub_array(offsets, shape, strides)"},{"location":"Reference/classes/Array/sub_array/#arguments","text":"argument description type/default offsets The offsets into the original array. Tuple[int] shape The size of the sub-array. Tuple[int] strides (Optional) The strides in the original array used to create the sub-array. Tuple[int]","title":"Arguments"},{"location":"Reference/classes/Array/sub_array/#examples","text":"Create a sub-array of size 2x3 from an array of size 5x5 at an offset of {1, 1} and a stride of {2, 1}: import numpy as np import accera as acc N = 5 subArrayNumRows = 2 subArrayNumCols = 3 matrix = np . random . rand ( N , N ) Arr = Array ( role = Array . Role . INPUT , data = matrix ) # Zero out a sub array of size [2, 3] such that the resulting array looks like this: # xxxxx # x000x # xxxxx # x000x # xxxxx nest = Nest ( shape = ( subArrayNumRows , subArrayNumCols )) i , j = nest . get_indices () @nest . iteration_logic def _ (): SubArr = Arr . sub_array ([ 1 , 1 ], [ subArrayNumRows , subArrayNumCols ], [ 2 , 1 ]) SubArr [ i , j ] = 0.0 schedule = nest . create_schedule ()","title":"Examples"},{"location":"Reference/classes/Nest/Nest/","text":"Accera v1.2.7 Reference accera.Nest(shape) Creates an affine loop nest. Arguments argument description type/default shape The shape of the iteration space tuple of positive integers Examples Create a nest with 3 nested for-loops of sizes 16, 10, and 11: nest = acc . Nest ( shape = ( 16 , 10 , 11 ))","title":"Nest"},{"location":"Reference/classes/Nest/Nest/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Nest/Nest/#acceranestshape","text":"Creates an affine loop nest.","title":"accera.Nest(shape)"},{"location":"Reference/classes/Nest/Nest/#arguments","text":"argument description type/default shape The shape of the iteration space tuple of positive integers","title":"Arguments"},{"location":"Reference/classes/Nest/Nest/#examples","text":"Create a nest with 3 nested for-loops of sizes 16, 10, and 11: nest = acc . Nest ( shape = ( 16 , 10 , 11 ))","title":"Examples"},{"location":"Reference/classes/Nest/create_plan/","text":"Accera v1.2.7 Reference accera.Nest.create_plan([target]) Creates a plan using the default schedule for the nest. Arguments argument description type/default target The target platform. Defaults to acc.Target.HOST Target Returns Plan Examples Create a plan for the host computer, using the default schedule for a nest: plan = nest . create_plan () Create a plan for an Intel Core 7th Generation, using the default schedule for a nest: corei9 = acc . Target ( \"Intel 7900X\" , num_threads = 44 ) plan = nest . create_plan ( corei9 )","title":"Create plan"},{"location":"Reference/classes/Nest/create_plan/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Nest/create_plan/#acceranestcreate_plantarget","text":"Creates a plan using the default schedule for the nest.","title":"accera.Nest.create_plan([target])"},{"location":"Reference/classes/Nest/create_plan/#arguments","text":"argument description type/default target The target platform. Defaults to acc.Target.HOST Target","title":"Arguments"},{"location":"Reference/classes/Nest/create_plan/#returns","text":"Plan","title":"Returns"},{"location":"Reference/classes/Nest/create_plan/#examples","text":"Create a plan for the host computer, using the default schedule for a nest: plan = nest . create_plan () Create a plan for an Intel Core 7th Generation, using the default schedule for a nest: corei9 = acc . Target ( \"Intel 7900X\" , num_threads = 44 ) plan = nest . create_plan ( corei9 )","title":"Examples"},{"location":"Reference/classes/Nest/create_schedule/","text":"Accera v1.2.7 Reference accera.Nest.create_schedule() Create a default schedule for a nest. Returns Schedule Examples schedule = nest . create_schedule ()","title":"Create schedule"},{"location":"Reference/classes/Nest/create_schedule/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Nest/create_schedule/#acceranestcreate_schedule","text":"Create a default schedule for a nest.","title":"accera.Nest.create_schedule()"},{"location":"Reference/classes/Nest/create_schedule/#returns","text":"Schedule","title":"Returns"},{"location":"Reference/classes/Nest/create_schedule/#examples","text":"schedule = nest . create_schedule ()","title":"Examples"},{"location":"Reference/classes/Nest/get_indices/","text":"Accera v1.2.7 Reference accera.Nest.get_indices() Gets the iteration space dimensions for a nest. Returns Tuple of Index Examples Get the iteration space dimensions for a 3-dimensional nest: i , j , k = nest . get_indices ()","title":"Get indices"},{"location":"Reference/classes/Nest/get_indices/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Nest/get_indices/#acceranestget_indices","text":"Gets the iteration space dimensions for a nest.","title":"accera.Nest.get_indices()"},{"location":"Reference/classes/Nest/get_indices/#returns","text":"Tuple of Index","title":"Returns"},{"location":"Reference/classes/Nest/get_indices/#examples","text":"Get the iteration space dimensions for a 3-dimensional nest: i , j , k = nest . get_indices ()","title":"Examples"},{"location":"Reference/classes/Nest/iteration_logic/","text":"Accera v1.2.7 Reference accera.Nest.iteration_logic(logic) Adds an iteration logic function to a Nest . Arguments argument description type/default logic Python function that represents the logic to run in the innermost loop of the nest. Examples The preferred syntax uses Python decorators, as follows: import accera as acc A = acc . Array ( role = acc . role . INPUT , shape = ( 16 , 64 )) B = acc . Array ( role = acc . role . INPUT , shape = ( 64 , 32 )) C = acc . Array ( role = acc . role . INPUT_OUTPUT , shape = ( 16 , 32 )) nest = acc . Nest ( shape = ( 16 , 32 , 64 )) i , j , k = nest . get_indices () @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] The alternative syntax avoids decorators and instead defines the logic in a function: import accera as acc A = acc . Array ( role = acc . role . INPUT , shape = ( 16 , 64 )) B = acc . Array ( role = acc . role . INPUT , shape = ( 64 , 32 )) C = acc . Array ( role = acc . role . INPUT_OUTPUT , shape = ( 16 , 32 )) nest = acc . Nest ( shape = ( 16 , 32 , 64 )) i , j , k = nest . get_indices () def logic_fn (): C [ i , j ] += A [ i , k ] * B [ k , j ] nest . iteration_logic ( logic_fn )","title":"Iteration logic"},{"location":"Reference/classes/Nest/iteration_logic/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Nest/iteration_logic/#acceranestiteration_logiclogic","text":"Adds an iteration logic function to a Nest .","title":"accera.Nest.iteration_logic(logic)"},{"location":"Reference/classes/Nest/iteration_logic/#arguments","text":"argument description type/default logic Python function that represents the logic to run in the innermost loop of the nest.","title":"Arguments"},{"location":"Reference/classes/Nest/iteration_logic/#examples","text":"The preferred syntax uses Python decorators, as follows: import accera as acc A = acc . Array ( role = acc . role . INPUT , shape = ( 16 , 64 )) B = acc . Array ( role = acc . role . INPUT , shape = ( 64 , 32 )) C = acc . Array ( role = acc . role . INPUT_OUTPUT , shape = ( 16 , 32 )) nest = acc . Nest ( shape = ( 16 , 32 , 64 )) i , j , k = nest . get_indices () @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] The alternative syntax avoids decorators and instead defines the logic in a function: import accera as acc A = acc . Array ( role = acc . role . INPUT , shape = ( 16 , 64 )) B = acc . Array ( role = acc . role . INPUT , shape = ( 64 , 32 )) C = acc . Array ( role = acc . role . INPUT_OUTPUT , shape = ( 16 , 32 )) nest = acc . Nest ( shape = ( 16 , 32 , 64 )) i , j , k = nest . get_indices () def logic_fn (): C [ i , j ] += A [ i , k ] * B [ k , j ] nest . iteration_logic ( logic_fn )","title":"Examples"},{"location":"Reference/classes/Package/Format/","text":"Accera v1.2.7 Reference accera.Package.Format type description accera.Package.Format.HAT_DYNAMIC HAT package format, dynamically linked. accera.Package.Format.HAT_STATIC HAT package format, statically linked. accera.Package.Format.MLIR_DYNAMIC MLIR (debugging) package format, dynamically linked. accera.Package.Format.MLIR_STATIC MLIR (debugging) package format, statically linked. When cross-compiling, use either accera.Package.Format.HAT_STATIC or accera.Package.Format.MLIR_STATIC .","title":"Format"},{"location":"Reference/classes/Package/Format/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Package/Format/#accerapackageformat","text":"type description accera.Package.Format.HAT_DYNAMIC HAT package format, dynamically linked. accera.Package.Format.HAT_STATIC HAT package format, statically linked. accera.Package.Format.MLIR_DYNAMIC MLIR (debugging) package format, dynamically linked. accera.Package.Format.MLIR_STATIC MLIR (debugging) package format, statically linked. When cross-compiling, use either accera.Package.Format.HAT_STATIC or accera.Package.Format.MLIR_STATIC .","title":"accera.Package.Format"},{"location":"Reference/classes/Package/Mode/","text":"Accera v1.2.7 Reference accera.Package.Mode type description accera.Package.Mode.DEBUG Debug mode (automatically tests logical equivalence). accera.Package.Mode.RELEASE Release (maximally optimized).","title":"Mode"},{"location":"Reference/classes/Package/Mode/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Package/Mode/#accerapackagemode","text":"type description accera.Package.Mode.DEBUG Debug mode (automatically tests logical equivalence). accera.Package.Mode.RELEASE Release (maximally optimized).","title":"accera.Package.Mode"},{"location":"Reference/classes/Package/Package/","text":"Accera v1.2.7 Reference accera.Package.Package() A package of functions that can be built and linked with client code. Examples Create a package: package = acc . Package ()","title":"Package"},{"location":"Reference/classes/Package/Package/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Package/Package/#accerapackagepackage","text":"A package of functions that can be built and linked with client code.","title":"accera.Package.Package()"},{"location":"Reference/classes/Package/Package/#examples","text":"Create a package: package = acc . Package ()","title":"Examples"},{"location":"Reference/classes/Package/Platform/","text":"Accera v1.2.7 Reference accera.Package.Platform type description accera.Package.Platform.HOST The host computer's platform accera.Package.Platform.WINDOWS The Windows platform accera.Package.Platform.LINUX The Linux platform accera.Package.Platform.MACOS The MacOS platform accera.Package.Platform.ANDRIOD The Android platform accera.Package.Platform.IOS The iOS platform accera.Package.Platform.RASPBIAN The Raspbian platform","title":"Platform"},{"location":"Reference/classes/Package/Platform/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Package/Platform/#accerapackageplatform","text":"type description accera.Package.Platform.HOST The host computer's platform accera.Package.Platform.WINDOWS The Windows platform accera.Package.Platform.LINUX The Linux platform accera.Package.Platform.MACOS The MacOS platform accera.Package.Platform.ANDRIOD The Android platform accera.Package.Platform.IOS The iOS platform accera.Package.Platform.RASPBIAN The Raspbian platform","title":"accera.Package.Platform"},{"location":"Reference/classes/Package/add/","text":"Accera v1.2.7 Reference accera.Package.add(source, args[, base_name, parameters]) Adds one or more functions to the package. Arguments argument description type source The source which defines the function's implementation. Nest or Schedule or Plan args The order of external-scope arrays used in the function signature. tuple of Array base_name A base name for the function. The full name for the function will be the base name followed by an automatically-generated unique identifier. string parameters A value for each parameter if the function's implementation is parameterized. See Parameters . A list of dictionaries can also be provided, in which case, multiple functions are generated. Parameter to value dictionary or a list of Parameter to value dictionaries. Examples Adding a function defined by an Plan : package . add ( plan , args = ( A , B , C ), base_name = \"simple_matmul\" ) Convenience syntax to add a function defined by a Schedule . A default Plan will be created automatically: package . add ( schedule , args = ( A , B , C ), base_name = \"simple_matmul\" ) Convenience syntax to add a function defined by a Nest . A default Schedule and Plan will be created internally: package . add ( nest , args = ( A , B , C ), base_name = \"simple_matmul\" ) Adding a function with concrete values specified for its parameters ( P0 , P1 , P2 , P3 ). package . add ( nest , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1 }, base_name = \"matmul_16_16_16_1\" )","title":"Add"},{"location":"Reference/classes/Package/add/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Package/add/#accerapackageaddsource-args-base_name-parameters","text":"Adds one or more functions to the package.","title":"accera.Package.add(source, args[, base_name, parameters])"},{"location":"Reference/classes/Package/add/#arguments","text":"argument description type source The source which defines the function's implementation. Nest or Schedule or Plan args The order of external-scope arrays used in the function signature. tuple of Array base_name A base name for the function. The full name for the function will be the base name followed by an automatically-generated unique identifier. string parameters A value for each parameter if the function's implementation is parameterized. See Parameters . A list of dictionaries can also be provided, in which case, multiple functions are generated. Parameter to value dictionary or a list of Parameter to value dictionaries.","title":"Arguments"},{"location":"Reference/classes/Package/add/#examples","text":"Adding a function defined by an Plan : package . add ( plan , args = ( A , B , C ), base_name = \"simple_matmul\" ) Convenience syntax to add a function defined by a Schedule . A default Plan will be created automatically: package . add ( schedule , args = ( A , B , C ), base_name = \"simple_matmul\" ) Convenience syntax to add a function defined by a Nest . A default Schedule and Plan will be created internally: package . add ( nest , args = ( A , B , C ), base_name = \"simple_matmul\" ) Adding a function with concrete values specified for its parameters ( P0 , P1 , P2 , P3 ). package . add ( nest , args = ( A , B , C ), parameters = { P0 : 16 , P1 : 16 , P2 : 16 , P3 : 1 }, base_name = \"matmul_16_16_16_1\" )","title":"Examples"},{"location":"Reference/classes/Package/add_description/","text":"Accera v1.2.7 Reference accera.Package.add_description([author, license, other, version]) Adds descriptive metadata to the HAT package. Arguments argument description type/default author Name of the individual or group that authored the package. string license The internet URL of the license used to release the package. string other User-specific descriptive metadata dictionary version The package version. string Examples Adds the standard version, license, and author description fields to the package: package . add_description ( version \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b = \"1.0\" , license = \"https://mit-license.org/\" , author = \"Microsoft Research\" ) \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b Adds arbitrary user-defined metadata to describe the package: package . add_description ( other = { \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b \"title\" : \"My Package Title\" , \"source\" : \"https://github.com/\" , \"citations\" : [ \"https://arxiv.org/2021.12345/\" , \"https://arxiv.org/2021.56789/\" ]} \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b )","title":"Add description"},{"location":"Reference/classes/Package/add_description/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Package/add_description/#accerapackageadd_descriptionauthor-license-other-version","text":"Adds descriptive metadata to the HAT package.","title":"accera.Package.add_description([author, license, other, version])"},{"location":"Reference/classes/Package/add_description/#arguments","text":"argument description type/default author Name of the individual or group that authored the package. string license The internet URL of the license used to release the package. string other User-specific descriptive metadata dictionary version The package version. string","title":"Arguments"},{"location":"Reference/classes/Package/add_description/#examples","text":"Adds the standard version, license, and author description fields to the package: package . add_description ( version \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b = \"1.0\" , license = \"https://mit-license.org/\" , author = \"Microsoft Research\" ) \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b Adds arbitrary user-defined metadata to describe the package: package . add_description ( other = { \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b \"title\" : \"My Package Title\" , \"source\" : \"https://github.com/\" , \"citations\" : [ \"https://arxiv.org/2021.12345/\" , \"https://arxiv.org/2021.56789/\" ]} \u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b )","title":"Examples"},{"location":"Reference/classes/Package/build/","text":"Accera v1.2.7 Reference accera.Package.build(name[, format, mode, platform, tolerance, output_dir]) Builds a HAT package. Arguments argument description type/default name The package name. string format The format of the package. accera.Package.Format , defaults to Package.Format.HAT_STATIC mode The package mode, such as whether it is optimized or used for debugging. robopy.Package.Mode , defaults to Package.Mode.Release platform The platform where the package runs. accera.Package.Platform tolerance The tolerance for correctness checking when mode = Package.Mode.Debug . float, defaults to 1e-5 output_dir The path to an output directory. Defaults to the current directory if unspecified. string Examples Build a Dynamically-linked HAT package called myPackage containing func1 for the host platform in the current directory: package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" ) Build a statically-linked HAT package called myPackage containing func1 for the host platform in the hat_packages subdirectory: package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_STATIC , name = \"myPackage\" , output_dir = \"hat_packages\" ) Build a statically-linked myPackage with additional intermediate MLIR files for debugging purposes. To build a dynamically-linked package, use acc.Package.Format.MLIR_DYNAMIC : package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . MLIR_STATIC , name = \"myPackage\" ) Build a package with error checking for func1 , outputing error messages to stderr if the default implementation and the Accera implementation do not match within a tolerance of 1.0e-6 : package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , mode = acc . Package . Mode . DEBUG , tolerance = 1.0e-6 ) Cross-compile a statically-linked HAT package called myPackage containing func1 for the Raspberry Pi 3. Note that dynamically-linked HAT packages are not supported for cross-compilation: pi3 = Target ( \"Raspberry Pi 3B\" , category = Target . Category . CPU ) plan = schedule . create_plan ( target = pi3 ) package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_STATIC , name = \"myPackagePi3\" , platform = acc . Package . Platform . RASPBIAN )","title":"Build"},{"location":"Reference/classes/Package/build/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Package/build/#accerapackagebuildname-format-mode-platform-tolerance-output_dir","text":"Builds a HAT package.","title":"accera.Package.build(name[, format, mode, platform, tolerance, output_dir])"},{"location":"Reference/classes/Package/build/#arguments","text":"argument description type/default name The package name. string format The format of the package. accera.Package.Format , defaults to Package.Format.HAT_STATIC mode The package mode, such as whether it is optimized or used for debugging. robopy.Package.Mode , defaults to Package.Mode.Release platform The platform where the package runs. accera.Package.Platform tolerance The tolerance for correctness checking when mode = Package.Mode.Debug . float, defaults to 1e-5 output_dir The path to an output directory. Defaults to the current directory if unspecified. string","title":"Arguments"},{"location":"Reference/classes/Package/build/#examples","text":"Build a Dynamically-linked HAT package called myPackage containing func1 for the host platform in the current directory: package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" ) Build a statically-linked HAT package called myPackage containing func1 for the host platform in the hat_packages subdirectory: package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_STATIC , name = \"myPackage\" , output_dir = \"hat_packages\" ) Build a statically-linked myPackage with additional intermediate MLIR files for debugging purposes. To build a dynamically-linked package, use acc.Package.Format.MLIR_DYNAMIC : package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . MLIR_STATIC , name = \"myPackage\" ) Build a package with error checking for func1 , outputing error messages to stderr if the default implementation and the Accera implementation do not match within a tolerance of 1.0e-6 : package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_DYNAMIC , name = \"myPackage\" , mode = acc . Package . Mode . DEBUG , tolerance = 1.0e-6 ) Cross-compile a statically-linked HAT package called myPackage containing func1 for the Raspberry Pi 3. Note that dynamically-linked HAT packages are not supported for cross-compilation: pi3 = Target ( \"Raspberry Pi 3B\" , category = Target . Category . CPU ) plan = schedule . create_plan ( target = pi3 ) package = acc . Package () package . add ( plan , base_name = \"func1\" ) package . build ( format = acc . Package . Format . HAT_STATIC , name = \"myPackagePi3\" , platform = acc . Package . Platform . RASPBIAN )","title":"Examples"},{"location":"Reference/classes/Plan/bind/","text":"Accera v1.2.7 Reference accera.Plan.bind(mapping) Only available for targets that can execute a grid of work (such as GPUs). The bind function binds dimensions of the iteration space to axes of the target-specific grid (such as v100.GridUnit.BLOCK_X , v100.GridUnit.THREAD_X on an Nvidia GPU). Arguments argument description type/default mapping Mapping of indices to GPU thread or block identifiers. dict of Index to target-specific identifiers Examples Mark the i , j , and k indices to execute on NVidia V100's BLOCK_X , THREAD_X , and THREAD_Y grid axes, respectively. v100 = acc . Target ( Target . Model . NVIDIA_V100 ) plan . bind ({ i : v100 . GridUnit . BLOCK_X , j : v100 . GridUnit . THREAD_X , k : v100 . GridUnit . THREAD_Y })","title":"Bind"},{"location":"Reference/classes/Plan/bind/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Plan/bind/#acceraplanbindmapping","text":"Only available for targets that can execute a grid of work (such as GPUs). The bind function binds dimensions of the iteration space to axes of the target-specific grid (such as v100.GridUnit.BLOCK_X , v100.GridUnit.THREAD_X on an Nvidia GPU).","title":"accera.Plan.bind(mapping)"},{"location":"Reference/classes/Plan/bind/#arguments","text":"argument description type/default mapping Mapping of indices to GPU thread or block identifiers. dict of Index to target-specific identifiers","title":"Arguments"},{"location":"Reference/classes/Plan/bind/#examples","text":"Mark the i , j , and k indices to execute on NVidia V100's BLOCK_X , THREAD_X , and THREAD_Y grid axes, respectively. v100 = acc . Target ( Target . Model . NVIDIA_V100 ) plan . bind ({ i : v100 . GridUnit . BLOCK_X , j : v100 . GridUnit . THREAD_X , k : v100 . GridUnit . THREAD_Y })","title":"Examples"},{"location":"Reference/classes/Plan/cache/","text":"Accera v1.2.7 Reference accera.Plan.cache(source[, index, trigger_index, layout, level, trigger_level, max_elements, thrifty, location, double_buffer]) Adds a caching strategy to a plan. Arguments argument description type source The array or cache from which this cache is copied. Array or Cache . index The index used to determine the cache level. Specify one and only one of index , level , max_elements . Index . trigger_index The index used to determine what level to fill the cache at. trigger_index can't come after index in the schedule order and will default to index if not specified. Specify at most one of trigger_index or trigger_level . Index . layout The affine memory map, if different from the source. accera.Layout . level The key-slice level to cache (the number of wildcard dimensions in a key-slice). Specify one and only one of index , level , max_elements . positive integer. trigger_level The key-slice level to fill the cache at. trigger_level can't be smaller than level , and will default to level if not specified. Specify at most one of trigger_index or trigger_level . positive integer max_elements The maximum elements to include in the cached region. Specify one and only one of index , level , max_elements . positive integer thrifty Use thrifty caching (copy data into a cache only if the cached data differs from the original active block). bool location The type of memory used to store the cache. MemorySpace double_buffer Whether to make this cache a double-buffering cache. Only valid on INPUT and CONST arrays. bool double_buffer_location Which memory space to put the double buffer temp array in. Requires that double_buffer is set to True. Defaults to AUTO . MemorySpace or AUTO vectorize Whether to vectorize the cache operations. Defaults to AUTO , which will behave like vectorize=True if the loop-nest has any vectorized loop via plan.vectorize(index) or vectorize=False if the loop-nest has no vectorized loops. bool AUTO will configure the double buffering location based on the following: location | double_buffer | double_buffer_location = AUTO --- | --- | --- MemorySpace.SHARED | True | MemorySpace.PRIVATE !MemorySpace.SHARED | True | Same value as location Returns A Cache handle that represents the created cache. Examples Create a cache of array A at level 2. AA = plan . cache ( A , level = 2 ) Create a cache of array A with the Array.Layout.FIRST_MAJOR layout: AA = plan . cache ( A , level = 2 , layout = acc . Array . Layout . FIRST_MAJOR ) Create a cache of array A for dimension j : AA = plan . cache ( A , index = j ) Create a cache of array A for the largest active block that does not exceed 1024 elements: AA = plan . cache ( A , max_elements = 1024 ) Create a level 2 cache of array A from its level 4 cache: AA = plan . cache ( A , level = 4 ) AAA = plan . cache ( AA , level = 2 ) Not yet implemented: Create a cache of array A at index i in GPU shared memory: v100 = Target ( Target . Model . NVIDIA_V100 ) AA = plan . cache ( A , i , location = v100 . MemorySpace . SHARED )","title":"Cache"},{"location":"Reference/classes/Plan/cache/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Plan/cache/#acceraplancachesource-index-trigger_index-layout-level-trigger_level-max_elements-thrifty-location-double_buffer","text":"Adds a caching strategy to a plan.","title":"accera.Plan.cache(source[, index, trigger_index, layout, level, trigger_level, max_elements, thrifty, location, double_buffer])"},{"location":"Reference/classes/Plan/cache/#arguments","text":"argument description type source The array or cache from which this cache is copied. Array or Cache . index The index used to determine the cache level. Specify one and only one of index , level , max_elements . Index . trigger_index The index used to determine what level to fill the cache at. trigger_index can't come after index in the schedule order and will default to index if not specified. Specify at most one of trigger_index or trigger_level . Index . layout The affine memory map, if different from the source. accera.Layout . level The key-slice level to cache (the number of wildcard dimensions in a key-slice). Specify one and only one of index , level , max_elements . positive integer. trigger_level The key-slice level to fill the cache at. trigger_level can't be smaller than level , and will default to level if not specified. Specify at most one of trigger_index or trigger_level . positive integer max_elements The maximum elements to include in the cached region. Specify one and only one of index , level , max_elements . positive integer thrifty Use thrifty caching (copy data into a cache only if the cached data differs from the original active block). bool location The type of memory used to store the cache. MemorySpace double_buffer Whether to make this cache a double-buffering cache. Only valid on INPUT and CONST arrays. bool double_buffer_location Which memory space to put the double buffer temp array in. Requires that double_buffer is set to True. Defaults to AUTO . MemorySpace or AUTO vectorize Whether to vectorize the cache operations. Defaults to AUTO , which will behave like vectorize=True if the loop-nest has any vectorized loop via plan.vectorize(index) or vectorize=False if the loop-nest has no vectorized loops. bool AUTO will configure the double buffering location based on the following: location | double_buffer | double_buffer_location = AUTO --- | --- | --- MemorySpace.SHARED | True | MemorySpace.PRIVATE !MemorySpace.SHARED | True | Same value as location","title":"Arguments"},{"location":"Reference/classes/Plan/cache/#returns","text":"A Cache handle that represents the created cache.","title":"Returns"},{"location":"Reference/classes/Plan/cache/#examples","text":"Create a cache of array A at level 2. AA = plan . cache ( A , level = 2 ) Create a cache of array A with the Array.Layout.FIRST_MAJOR layout: AA = plan . cache ( A , level = 2 , layout = acc . Array . Layout . FIRST_MAJOR ) Create a cache of array A for dimension j : AA = plan . cache ( A , index = j ) Create a cache of array A for the largest active block that does not exceed 1024 elements: AA = plan . cache ( A , max_elements = 1024 ) Create a level 2 cache of array A from its level 4 cache: AA = plan . cache ( A , level = 4 ) AAA = plan . cache ( AA , level = 2 ) Not yet implemented: Create a cache of array A at index i in GPU shared memory: v100 = Target ( Target . Model . NVIDIA_V100 ) AA = plan . cache ( A , i , location = v100 . MemorySpace . SHARED )","title":"Examples"},{"location":"Reference/classes/Plan/kernelize/","text":"Accera v1.2.7 Reference accera.Plan.kernelize(unroll_indices[, vectorize_indices]) A convenience method for a sequence of unroll instructions followed by a possible sequence of vectorize instructions. Arguments argument description type/default unroll_indices The iteration-space dimensions to unroll tuple of accera.Index . vectorize_indices The optional iteration-space dimensions to vectorize accera.Index or tuple of accera.Index . Examples Unroll i and k , and then vectorize j : schedule . reorder ( i , k , j ) plan = schedule . create_plan () plan . kernelize ( unroll_indices = ( i , k ), vectorize_indices = j ) Another example is to Unroll i and then vectorize j and k : schedule . reorder ( i , j , k ) plan = schedule . create_plan () plan . kernelize ( unroll_indices = ( i ,), vectorize_indices = ( j , k ))","title":"Kernelize"},{"location":"Reference/classes/Plan/kernelize/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Plan/kernelize/#acceraplankernelizeunroll_indices-vectorize_indices","text":"A convenience method for a sequence of unroll instructions followed by a possible sequence of vectorize instructions.","title":"accera.Plan.kernelize(unroll_indices[, vectorize_indices])"},{"location":"Reference/classes/Plan/kernelize/#arguments","text":"argument description type/default unroll_indices The iteration-space dimensions to unroll tuple of accera.Index . vectorize_indices The optional iteration-space dimensions to vectorize accera.Index or tuple of accera.Index .","title":"Arguments"},{"location":"Reference/classes/Plan/kernelize/#examples","text":"Unroll i and k , and then vectorize j : schedule . reorder ( i , k , j ) plan = schedule . create_plan () plan . kernelize ( unroll_indices = ( i , k ), vectorize_indices = j ) Another example is to Unroll i and then vectorize j and k : schedule . reorder ( i , j , k ) plan = schedule . create_plan () plan . kernelize ( unroll_indices = ( i ,), vectorize_indices = ( j , k ))","title":"Examples"},{"location":"Reference/classes/Plan/parallelize/","text":"Accera v1.2.7 Reference accera.Plan.parallelize(indices[, pin, policy]) Executes one or more loops in parallel on multiple cores or processors. Only available for targets with multiple cores or processors. Arguments argument description type/default indices The iteration-space dimensions to run in parallel. To assign multiple threads to an index, first split that index, then parallelize its split indices. Unsplit indices will be assigned one thread each, split indices will be assigned threads based on the number of split blocks. This is limited by the number of threads supported by the target. tuple of accera.Index pin Pin the computation to a subset of cores or processors. tuple of target-specific identifiers policy The scheduling policy to apply (\"dynamic\" or \"static\"). string. Defaults to \"static\". Examples Parallelize the i , j , and k dimensions using 3 threads: plan . parallelize ( indices = ( i , j , k )) Parallelize the i dimension using 4 threads: N = 1024 # shape of the i dimension num_threads = 4 # divide the shape by num_threads to get the block size per thread block_size = N // num_threads ii = schedule . split ( i , size = block_size ) plan . parallelize ( indices = i ) Not yet implemented: Parallelize the i , j , and k dimensions by pinning them to specific cores on an Intel Xeon E5: plan . parallelize ( indices = ( i , j , k ), pin = ( xeonE5 . cores [ 0 ], xeonE5 . cores [ 1 ], xeonE5 . cores [ 2 ])) Apply a dynamic scheduling policy, which uses a queue to partition the work across multiple cores: plan . parallelize ( indices = ( i , j , k ), policy = \"dynamic\" )","title":"Parallelize"},{"location":"Reference/classes/Plan/parallelize/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Plan/parallelize/#acceraplanparallelizeindices-pin-policy","text":"Executes one or more loops in parallel on multiple cores or processors. Only available for targets with multiple cores or processors.","title":"accera.Plan.parallelize(indices[, pin, policy])"},{"location":"Reference/classes/Plan/parallelize/#arguments","text":"argument description type/default indices The iteration-space dimensions to run in parallel. To assign multiple threads to an index, first split that index, then parallelize its split indices. Unsplit indices will be assigned one thread each, split indices will be assigned threads based on the number of split blocks. This is limited by the number of threads supported by the target. tuple of accera.Index pin Pin the computation to a subset of cores or processors. tuple of target-specific identifiers policy The scheduling policy to apply (\"dynamic\" or \"static\"). string. Defaults to \"static\".","title":"Arguments"},{"location":"Reference/classes/Plan/parallelize/#examples","text":"Parallelize the i , j , and k dimensions using 3 threads: plan . parallelize ( indices = ( i , j , k )) Parallelize the i dimension using 4 threads: N = 1024 # shape of the i dimension num_threads = 4 # divide the shape by num_threads to get the block size per thread block_size = N // num_threads ii = schedule . split ( i , size = block_size ) plan . parallelize ( indices = i ) Not yet implemented: Parallelize the i , j , and k dimensions by pinning them to specific cores on an Intel Xeon E5: plan . parallelize ( indices = ( i , j , k ), pin = ( xeonE5 . cores [ 0 ], xeonE5 . cores [ 1 ], xeonE5 . cores [ 2 ])) Apply a dynamic scheduling policy, which uses a queue to partition the work across multiple cores: plan . parallelize ( indices = ( i , j , k ), policy = \"dynamic\" )","title":"Examples"},{"location":"Reference/classes/Plan/tensorize/","text":"Accera v1.2.7 Reference accera.Plan.tensorize(indices, mma_shape [, use_static_offsets, num_total_passes, num_fused_passes, scheduling_policy]) Only available for targets with native matrix multiplication instruction (tensor core) support. Marks the dimensions of the iteration-space for tensorization. Only perfectly nested loops of the following form can be tensorized: for i in range ( M ): for k in range ( N ): for j in range ( K ): C [ i , j ] += A [ i , k ] * B [ k , j ] Arguments argument description type/default indices The 3-dimensional iteration space to tensorize. 3-D tuple of accera.Index mma_shape The type of MMA operation to use. accera.MMAShape use_static_offsets This is an optimization flag, which when enabled will use precomputed offset maps stored in device constant memory. Defaults to False . bool num_total_passes This controls the total number of passes to run. Defaults to 1. positive integer num_fused_passes This controls the number of passes for which register allocation is done, higher the value more the number of registers that are allocated. Defaults to None which will fuse all the passes as specified by num_total_passes . positive integer scheduling_policy For multi-block MMA operations, this controls whether matrix multiplication is done block-by-block or pass-by-pass (affects register usage). Default value is accera.MMASchedulingPolicy.PASS_ORDER accera.MMASchedulingPolicy The different values of the enum MMASchedulingPolicy (applicable only for AMD targets supporting MFMA ops, such as accera.Target.Model.AMD_MI100 ) are mentioned here: accera.MMASchedulingPolicy The different values of the enum MMAShape are explained here: accera.MMAShape Examples Mark the dimensions ii , jj , and kk for tensorization execution: plan . tensorize ( indices = ( ii , jj , kk ))","title":"Tensorize"},{"location":"Reference/classes/Plan/tensorize/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Plan/tensorize/#acceraplantensorizeindices-mma_shape-use_static_offsets-num_total_passes-num_fused_passes-scheduling_policy","text":"Only available for targets with native matrix multiplication instruction (tensor core) support. Marks the dimensions of the iteration-space for tensorization. Only perfectly nested loops of the following form can be tensorized: for i in range ( M ): for k in range ( N ): for j in range ( K ): C [ i , j ] += A [ i , k ] * B [ k , j ]","title":"accera.Plan.tensorize(indices, mma_shape [, use_static_offsets, num_total_passes, num_fused_passes, scheduling_policy])"},{"location":"Reference/classes/Plan/tensorize/#arguments","text":"argument description type/default indices The 3-dimensional iteration space to tensorize. 3-D tuple of accera.Index mma_shape The type of MMA operation to use. accera.MMAShape use_static_offsets This is an optimization flag, which when enabled will use precomputed offset maps stored in device constant memory. Defaults to False . bool num_total_passes This controls the total number of passes to run. Defaults to 1. positive integer num_fused_passes This controls the number of passes for which register allocation is done, higher the value more the number of registers that are allocated. Defaults to None which will fuse all the passes as specified by num_total_passes . positive integer scheduling_policy For multi-block MMA operations, this controls whether matrix multiplication is done block-by-block or pass-by-pass (affects register usage). Default value is accera.MMASchedulingPolicy.PASS_ORDER accera.MMASchedulingPolicy The different values of the enum MMASchedulingPolicy (applicable only for AMD targets supporting MFMA ops, such as accera.Target.Model.AMD_MI100 ) are mentioned here: accera.MMASchedulingPolicy The different values of the enum MMAShape are explained here: accera.MMAShape","title":"Arguments"},{"location":"Reference/classes/Plan/tensorize/#examples","text":"Mark the dimensions ii , jj , and kk for tensorization execution: plan . tensorize ( indices = ( ii , jj , kk ))","title":"Examples"},{"location":"Reference/classes/Plan/unroll/","text":"Accera v1.2.7 Reference accera.Plan.unroll(index) Marks a dimension of the iteration-space for unrolling. Arguments argument description type/default index The index to unroll. Index Examples Mark the i dimension for unrolling: plan . unroll ( index = i )","title":"Unroll"},{"location":"Reference/classes/Plan/unroll/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Plan/unroll/#acceraplanunrollindex","text":"Marks a dimension of the iteration-space for unrolling.","title":"accera.Plan.unroll(index)"},{"location":"Reference/classes/Plan/unroll/#arguments","text":"argument description type/default index The index to unroll. Index","title":"Arguments"},{"location":"Reference/classes/Plan/unroll/#examples","text":"Mark the i dimension for unrolling: plan . unroll ( index = i )","title":"Examples"},{"location":"Reference/classes/Plan/vectorize/","text":"Accera v1.2.7 Reference accera.Plan.vectorize(index) Only available for targets that have SIMD registers and support vector instructions. Marks a dimension of the iteration-space for vectorization. Arguments argument description type/default index The index to vectorize. Index Examples Mark the dimension ii for vectorized execution: plan . vectorize ( index = ii )","title":"Vectorize"},{"location":"Reference/classes/Plan/vectorize/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Plan/vectorize/#acceraplanvectorizeindex","text":"Only available for targets that have SIMD registers and support vector instructions. Marks a dimension of the iteration-space for vectorization.","title":"accera.Plan.vectorize(index)"},{"location":"Reference/classes/Plan/vectorize/#arguments","text":"argument description type/default index The index to vectorize. Index","title":"Arguments"},{"location":"Reference/classes/Plan/vectorize/#examples","text":"Mark the dimension ii for vectorized execution: plan . vectorize ( index = ii )","title":"Examples"},{"location":"Reference/classes/Schedule/create_plan/","text":"Accera v1.2.7 Reference accera.Schedule.create_plan([target]) Creates a plan for running this schedule. Arguments argument description type/default target The target platform. Defaults to acc.Target.HOST Target Returns Plan Examples TODO","title":"Create plan"},{"location":"Reference/classes/Schedule/create_plan/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Schedule/create_plan/#acceraschedulecreate_plantarget","text":"Creates a plan for running this schedule.","title":"accera.Schedule.create_plan([target])"},{"location":"Reference/classes/Schedule/create_plan/#arguments","text":"argument description type/default target The target platform. Defaults to acc.Target.HOST Target","title":"Arguments"},{"location":"Reference/classes/Schedule/create_plan/#returns","text":"Plan","title":"Returns"},{"location":"Reference/classes/Schedule/create_plan/#examples","text":"TODO","title":"Examples"},{"location":"Reference/classes/Schedule/is_valid_loop_order/","text":"Accera v1.2.7 Reference accera.Schedule.is_valid_loop_order(*order) The is_valid_loop_order function determines if an order of indices is valid. For a description of valid schedule orders, refer to reorder . Arguments argument description type/default *order The order of indices to check for validity variable Index arguments Examples Checks if an order is valid: print ( schedule . is_valid_loop_order ( k , i , j )) Uses this function as part of a parameter filter to determine which permutations of loop order parameters are valid: P1 , P2 , P2 , P4 , P5 , loop_order = acc . create_parameters () schedule . reorder ( order = loop_order ) def my_filter ( parameters_choice ): P1 , P2 , P3 , P4 , P5 , loop_order = parameters_choice return P1 > P2 \\ and P3 > P4 \\ and P1 * P5 < P3 \\ and P2 * P5 < P4 \\ and schedule . is_valid_loop_order ( loop_order ) parameters = acc . create_parameter_grid ({ P1 : [ 64 , 128 , 256 ], P2 : [ 32 , 128 ], P3 : [ 16 , 32 , 128 ], P4 : [ 8 , 64 ], P5 : [ 4 ], loop_order : ( i , j , k , ii , jj , kk ) }, my_filter )","title":"Is valid loop order"},{"location":"Reference/classes/Schedule/is_valid_loop_order/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Schedule/is_valid_loop_order/#accerascheduleis_valid_loop_orderorder","text":"The is_valid_loop_order function determines if an order of indices is valid. For a description of valid schedule orders, refer to reorder .","title":"accera.Schedule.is_valid_loop_order(*order)"},{"location":"Reference/classes/Schedule/is_valid_loop_order/#arguments","text":"argument description type/default *order The order of indices to check for validity variable Index arguments","title":"Arguments"},{"location":"Reference/classes/Schedule/is_valid_loop_order/#examples","text":"Checks if an order is valid: print ( schedule . is_valid_loop_order ( k , i , j )) Uses this function as part of a parameter filter to determine which permutations of loop order parameters are valid: P1 , P2 , P2 , P4 , P5 , loop_order = acc . create_parameters () schedule . reorder ( order = loop_order ) def my_filter ( parameters_choice ): P1 , P2 , P3 , P4 , P5 , loop_order = parameters_choice return P1 > P2 \\ and P3 > P4 \\ and P1 * P5 < P3 \\ and P2 * P5 < P4 \\ and schedule . is_valid_loop_order ( loop_order ) parameters = acc . create_parameter_grid ({ P1 : [ 64 , 128 , 256 ], P2 : [ 32 , 128 ], P3 : [ 16 , 32 , 128 ], P4 : [ 8 , 64 ], P5 : [ 4 ], loop_order : ( i , j , k , ii , jj , kk ) }, my_filter )","title":"Examples"},{"location":"Reference/classes/Schedule/pad/","text":"Accera v1.2.7 Reference accera.Schedule.pad(index, size) Pads the beginning of a specified dimension of the iteration-space with empty (no-op) elements. Arguments argument description type/default index The dimension to pad Index size The number of elements to pad non-negative integer Examples Pads the beginning of dimension i with 10 empty elements schedule . pad ( i , 10 )","title":"Pad"},{"location":"Reference/classes/Schedule/pad/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Schedule/pad/#acceraschedulepadindex-size","text":"Pads the beginning of a specified dimension of the iteration-space with empty (no-op) elements.","title":"accera.Schedule.pad(index, size)"},{"location":"Reference/classes/Schedule/pad/#arguments","text":"argument description type/default index The dimension to pad Index size The number of elements to pad non-negative integer","title":"Arguments"},{"location":"Reference/classes/Schedule/pad/#examples","text":"Pads the beginning of dimension i with 10 empty elements schedule . pad ( i , 10 )","title":"Examples"},{"location":"Reference/classes/Schedule/reorder/","text":"Accera v1.2.7 Reference accera.Schedule.reorder(order, *args) The reorder transformation sets the order of the indices in the schedule. These orders are not allowed: 1. The outer dimension created by a split transformation must always precede the corresponding inner dimension . 2. The fusing dimension created by a fuse operation must always precede any unfused dimensions . Arguments argument description type/default order Either the order of indices to set or the outermost index if using variable arguments tuple of Index or Index . *args Optional variable arguments containing subsequent indices to set variable Index arguments Examples Reorder a schedule by moving the k dimension to the outermost loop: schedule . reorder ( k , i , j ) Using a tuple to reorder a schedule. This overloaded form is better suited for parameters: schedule . reorder ( order = ( k , i , j ))","title":"Reorder"},{"location":"Reference/classes/Schedule/reorder/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Schedule/reorder/#acceraschedulereorderorder-args","text":"The reorder transformation sets the order of the indices in the schedule. These orders are not allowed: 1. The outer dimension created by a split transformation must always precede the corresponding inner dimension . 2. The fusing dimension created by a fuse operation must always precede any unfused dimensions .","title":"accera.Schedule.reorder(order, *args)"},{"location":"Reference/classes/Schedule/reorder/#arguments","text":"argument description type/default order Either the order of indices to set or the outermost index if using variable arguments tuple of Index or Index . *args Optional variable arguments containing subsequent indices to set variable Index arguments","title":"Arguments"},{"location":"Reference/classes/Schedule/reorder/#examples","text":"Reorder a schedule by moving the k dimension to the outermost loop: schedule . reorder ( k , i , j ) Using a tuple to reorder a schedule. This overloaded form is better suited for parameters: schedule . reorder ( order = ( k , i , j ))","title":"Examples"},{"location":"Reference/classes/Schedule/skew/","text":"Accera v1.2.7 Reference accera.Schedule.skew(index, reference_index [, unroll_loops_smaller_than]) Transforms a dimension with respect to a reference dimension into a parallelogram by padding with empty elements. Arguments argument description type/default index The dimension to skew Index reference_index The reference dimension Index unroll_loops_smaller_than Unroll loops that are smaller than this range (non-inclusive) non-negative integer Examples Skew dimension i with respect to dimension j : schedule . skew ( i , j ) Skew dimension j with respect to dimension i , and unroll if the resulting loops are smaller than 3: schedule . skew ( j , i , unroll_loops_smaller_than = 3 )","title":"Skew"},{"location":"Reference/classes/Schedule/skew/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Schedule/skew/#accerascheduleskewindex-reference_index-unroll_loops_smaller_than","text":"Transforms a dimension with respect to a reference dimension into a parallelogram by padding with empty elements.","title":"accera.Schedule.skew(index, reference_index [, unroll_loops_smaller_than])"},{"location":"Reference/classes/Schedule/skew/#arguments","text":"argument description type/default index The dimension to skew Index reference_index The reference dimension Index unroll_loops_smaller_than Unroll loops that are smaller than this range (non-inclusive) non-negative integer","title":"Arguments"},{"location":"Reference/classes/Schedule/skew/#examples","text":"Skew dimension i with respect to dimension j : schedule . skew ( i , j ) Skew dimension j with respect to dimension i , and unroll if the resulting loops are smaller than 3: schedule . skew ( j , i , unroll_loops_smaller_than = 3 )","title":"Examples"},{"location":"Reference/classes/Schedule/split/","text":"Accera v1.2.7 Reference accera.Schedule.split(index, size) The split transformation takes a dimension i and a size , modifies i , and creates a new dimension ii . Assume that the original size of dimension i was n : The split transformation splits dimension i into ceil(n/size) parts of size size , arranges each of those parts along dimension ii , and stacks the ceil(n/size) parts along dimension i . If the split size does not divide the dimension size, empty elements are added such that the split size does divide the dimension size. Arguments argument description type/default index The dimension to split Index size The split size non-negative integer Returns Index for the new inner dimension Examples Split the i dimension by 5, creating a new dimension ii : ii = schedule . split ( j , 5 )","title":"Split"},{"location":"Reference/classes/Schedule/split/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Schedule/split/#acceraschedulesplitindex-size","text":"The split transformation takes a dimension i and a size , modifies i , and creates a new dimension ii . Assume that the original size of dimension i was n : The split transformation splits dimension i into ceil(n/size) parts of size size , arranges each of those parts along dimension ii , and stacks the ceil(n/size) parts along dimension i . If the split size does not divide the dimension size, empty elements are added such that the split size does divide the dimension size.","title":"accera.Schedule.split(index, size)"},{"location":"Reference/classes/Schedule/split/#arguments","text":"argument description type/default index The dimension to split Index size The split size non-negative integer","title":"Arguments"},{"location":"Reference/classes/Schedule/split/#returns","text":"Index for the new inner dimension","title":"Returns"},{"location":"Reference/classes/Schedule/split/#examples","text":"Split the i dimension by 5, creating a new dimension ii : ii = schedule . split ( j , 5 )","title":"Examples"},{"location":"Reference/classes/Schedule/tile/","text":"Accera v1.2.7 Reference accera.Schedule.tile(shape) The tile transformation is a convenience syntax that takes a tuple of indices and a tuple of sizes, and splits each index by the corresponding size. The indices involved in the split are then ordered such that all the outer indices precede all of their respective inner indices. Arguments argument description type/default shape Mapping of indices to tile sizes dict of Index and non-negative integers Returns Tuple of Index representing the new inner dimensions. Examples Tile the i , j , and k dimensions by 8, 2, and 3, respectively. ii , jj , kk = schedule . tile ({ i : 8 , j : 2 , k : 3 })","title":"Tile"},{"location":"Reference/classes/Schedule/tile/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Schedule/tile/#accerascheduletileshape","text":"The tile transformation is a convenience syntax that takes a tuple of indices and a tuple of sizes, and splits each index by the corresponding size. The indices involved in the split are then ordered such that all the outer indices precede all of their respective inner indices.","title":"accera.Schedule.tile(shape)"},{"location":"Reference/classes/Schedule/tile/#arguments","text":"argument description type/default shape Mapping of indices to tile sizes dict of Index and non-negative integers","title":"Arguments"},{"location":"Reference/classes/Schedule/tile/#returns","text":"Tuple of Index representing the new inner dimensions.","title":"Returns"},{"location":"Reference/classes/Schedule/tile/#examples","text":"Tile the i , j , and k dimensions by 8, 2, and 3, respectively. ii , jj , kk = schedule . tile ({ i : 8 , j : 2 , k : 3 })","title":"Examples"},{"location":"Reference/classes/Target/Architecture/","text":"Accera v1.2.7 Reference accera.Target.Architecture Defines the supported target architectures. type description accera.Target.Architecture.HOST The host computer's architecture accera.Target.Architecture.ARM The ARM architecture accera.Target.Architecture.AARCH64 The 64-bit ARM architecture accera.Target.Architecture.X86 The 32-bit x86 architecture accera.Target.Architecture.X86_64 The 64-bit x86 architecture TODO: AARCH64?","title":"Architecture"},{"location":"Reference/classes/Target/Architecture/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Target/Architecture/#acceratargetarchitecture","text":"Defines the supported target architectures. type description accera.Target.Architecture.HOST The host computer's architecture accera.Target.Architecture.ARM The ARM architecture accera.Target.Architecture.AARCH64 The 64-bit ARM architecture accera.Target.Architecture.X86 The 32-bit x86 architecture accera.Target.Architecture.X86_64 The 64-bit x86 architecture TODO: AARCH64?","title":"accera.Target.Architecture"},{"location":"Reference/classes/Target/Category/","text":"Accera v1.2.7 Reference accera.Target.Category Defines the target processor category. type description accera.Target.Category.CPU accera.Target.Category.GPU","title":"Category"},{"location":"Reference/classes/Target/Category/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Target/Category/#acceratargetcategory","text":"Defines the target processor category. type description accera.Target.Category.CPU accera.Target.Category.GPU","title":"accera.Target.Category"},{"location":"Reference/classes/Target/Model/","text":"Accera v1.2.7 Reference accera.Target.Model Defines constants for some well-known CPU models. type description accera.Target.Model.AMD_1200 AMD 1200 accera.Target.Model.AMD_1300X AMD 1300X accera.Target.Model.AMD_1400 AMD 1400 accera.Target.Model.AMD_1500X AMD 1500X accera.Target.Model.AMD_1600 AMD 1600 accera.Target.Model.AMD_1600X AMD 1600X accera.Target.Model.AMD_1700 AMD 1700 accera.Target.Model.AMD_1700X AMD 1700X accera.Target.Model.AMD_1800X AMD 1800X accera.Target.Model.AMD_1900X AMD 1900X accera.Target.Model.AMD_1920X AMD 1920X accera.Target.Model.AMD_1950X AMD 1950X accera.Target.Model.AMD_200GE AMD 200GE accera.Target.Model.AMD_2200G AMD 2200G accera.Target.Model.AMD_2200GE AMD 2200GE accera.Target.Model.AMD_2200U AMD 2200U accera.Target.Model.AMD_220GE AMD 220GE accera.Target.Model.AMD_2300U AMD 2300U accera.Target.Model.AMD_2300X AMD 2300X accera.Target.Model.AMD_2400G AMD 2400G accera.Target.Model.AMD_2400GE AMD 2400GE accera.Target.Model.AMD_240GE AMD 240GE accera.Target.Model.AMD_2500U AMD 2500U accera.Target.Model.AMD_2500X AMD 2500X accera.Target.Model.AMD_2600 AMD 2600 accera.Target.Model.AMD_2600E AMD 2600E accera.Target.Model.AMD_2600H AMD 2600H accera.Target.Model.AMD_2600X AMD 2600X accera.Target.Model.AMD_2700 AMD 2700 accera.Target.Model.AMD_2700E AMD 2700E accera.Target.Model.AMD_2700U AMD 2700U accera.Target.Model.AMD_2700X AMD 2700X accera.Target.Model.AMD_2700X_GOLD_EDITION AMD 2700X Gold Edition accera.Target.Model.AMD_2800H AMD 2800H accera.Target.Model.AMD_2920X AMD 2920X accera.Target.Model.AMD_2950X AMD 2950X accera.Target.Model.AMD_2970WX AMD 2970WX accera.Target.Model.AMD_2990WX AMD 2990WX accera.Target.Model.AMD_3000G AMD 3000G accera.Target.Model.AMD_300U AMD 300U accera.Target.Model.AMD_3050U AMD 3050U accera.Target.Model.AMD_3101 AMD 3101 accera.Target.Model.AMD_3150U AMD 3150U accera.Target.Model.AMD_3151 AMD 3151 accera.Target.Model.AMD_3200G AMD 3200G accera.Target.Model.AMD_3200U AMD 3200U accera.Target.Model.AMD_3201 AMD 3201 accera.Target.Model.AMD_3250U AMD 3250U accera.Target.Model.AMD_3251 AMD 3251 accera.Target.Model.AMD_3255 AMD 3255 accera.Target.Model.AMD_3300U AMD 3300U accera.Target.Model.AMD_3301 AMD 3301 accera.Target.Model.AMD_3351 AMD 3351 accera.Target.Model.AMD_3400G AMD 3400G accera.Target.Model.AMD_3401 AMD 3401 accera.Target.Model.AMD_3451 AMD 3451 accera.Target.Model.AMD_3500 AMD 3500 accera.Target.Model.AMD_3500U AMD 3500U accera.Target.Model.AMD_3500X AMD 3500X accera.Target.Model.AMD_3550H AMD 3550H accera.Target.Model.AMD_3580U AMD 3580U accera.Target.Model.AMD_3600 AMD 3600 accera.Target.Model.AMD_3600X AMD 3600X accera.Target.Model.AMD_3600XT AMD 3600XT accera.Target.Model.AMD_3700U AMD 3700U accera.Target.Model.AMD_3700X AMD 3700X accera.Target.Model.AMD_3750H AMD 3750H accera.Target.Model.AMD_3780U AMD 3780U accera.Target.Model.AMD_3800X AMD 3800X accera.Target.Model.AMD_3800XT AMD 3800XT accera.Target.Model.AMD_3900 AMD 3900 accera.Target.Model.AMD_3900X AMD 3900X accera.Target.Model.AMD_3900XT AMD 3900XT accera.Target.Model.AMD_3950X AMD 3950X accera.Target.Model.AMD_3960X AMD 3960X accera.Target.Model.AMD_3970X AMD 3970X accera.Target.Model.AMD_3980X AMD 3980X accera.Target.Model.AMD_3990X AMD 3990X accera.Target.Model.AMD_4300G AMD 4300G accera.Target.Model.AMD_4300GE AMD 4300GE accera.Target.Model.AMD_4300U AMD 4300U accera.Target.Model.AMD_4500U AMD 4500U accera.Target.Model.AMD_4600G AMD 4600G accera.Target.Model.AMD_4600GE AMD 4600GE accera.Target.Model.AMD_4600H AMD 4600H accera.Target.Model.AMD_4600HS AMD 4600HS accera.Target.Model.AMD_4600U AMD 4600U accera.Target.Model.AMD_4680U AMD 4680U accera.Target.Model.AMD_4700G AMD 4700G accera.Target.Model.AMD_4700GE AMD 4700GE accera.Target.Model.AMD_4700U AMD 4700U accera.Target.Model.AMD_4800H AMD 4800H accera.Target.Model.AMD_4800HS AMD 4800HS accera.Target.Model.AMD_4800U AMD 4800U accera.Target.Model.AMD_4900H AMD 4900H accera.Target.Model.AMD_4900HS AMD 4900HS accera.Target.Model.AMD_4980U AMD 4980U accera.Target.Model.AMD_5300G AMD 5300G accera.Target.Model.AMD_5300GE AMD 5300GE accera.Target.Model.AMD_5300U AMD 5300U accera.Target.Model.AMD_5400U AMD 5400U accera.Target.Model.AMD_5500U AMD 5500U accera.Target.Model.AMD_5600G AMD 5600G accera.Target.Model.AMD_5600GE AMD 5600GE accera.Target.Model.AMD_5600H AMD 5600H accera.Target.Model.AMD_5600HS AMD 5600HS accera.Target.Model.AMD_5600U AMD 5600U accera.Target.Model.AMD_5600X AMD 5600X accera.Target.Model.AMD_5700G AMD 5700G accera.Target.Model.AMD_5700GE AMD 5700GE accera.Target.Model.AMD_5700U AMD 5700U accera.Target.Model.AMD_5800 AMD 5800 accera.Target.Model.AMD_5800H AMD 5800H accera.Target.Model.AMD_5800HS AMD 5800HS accera.Target.Model.AMD_5800U AMD 5800U accera.Target.Model.AMD_5800X AMD 5800X accera.Target.Model.AMD_5900 AMD 5900 accera.Target.Model.AMD_5900HS AMD 5900HS accera.Target.Model.AMD_5900HX AMD 5900HX accera.Target.Model.AMD_5900X AMD 5900X accera.Target.Model.AMD_5950X AMD 5950X accera.Target.Model.AMD_5980HS AMD 5980HS accera.Target.Model.AMD_5980HX AMD 5980HX accera.Target.Model.AMD_7232P AMD 7232P accera.Target.Model.AMD_7251 AMD 7251 accera.Target.Model.AMD_7252 AMD 7252 accera.Target.Model.AMD_7261 AMD 7261 accera.Target.Model.AMD_7262 AMD 7262 accera.Target.Model.AMD_7272 AMD 7272 accera.Target.Model.AMD_7281 AMD 7281 accera.Target.Model.AMD_7282 AMD 7282 accera.Target.Model.AMD_72F3 AMD 72F3 accera.Target.Model.AMD_7301 AMD 7301 accera.Target.Model.AMD_7302 AMD 7302 accera.Target.Model.AMD_7302P AMD 7302P accera.Target.Model.AMD_7313 AMD 7313 accera.Target.Model.AMD_7313P AMD 7313P accera.Target.Model.AMD_7343 AMD 7343 accera.Target.Model.AMD_7351 AMD 7351 accera.Target.Model.AMD_7351P AMD 7351P accera.Target.Model.AMD_7352 AMD 7352 accera.Target.Model.AMD_7371 AMD 7371 accera.Target.Model.AMD_73F3 AMD 73F3 accera.Target.Model.AMD_7401 AMD 7401 accera.Target.Model.AMD_7401P AMD 7401P accera.Target.Model.AMD_7402 AMD 7402 accera.Target.Model.AMD_7402P AMD 7402P accera.Target.Model.AMD_7413 AMD 7413 accera.Target.Model.AMD_7443 AMD 7443 accera.Target.Model.AMD_7443P AMD 7443P accera.Target.Model.AMD_7451 AMD 7451 accera.Target.Model.AMD_7452 AMD 7452 accera.Target.Model.AMD_7453 AMD 7453 accera.Target.Model.AMD_74F3 AMD 74F3 accera.Target.Model.AMD_7501 AMD 7501 accera.Target.Model.AMD_7502 AMD 7502 accera.Target.Model.AMD_7502P AMD 7502P accera.Target.Model.AMD_7513 AMD 7513 accera.Target.Model.AMD_7532 AMD 7532 accera.Target.Model.AMD_7542 AMD 7542 accera.Target.Model.AMD_7543 AMD 7543 accera.Target.Model.AMD_7543P AMD 7543P accera.Target.Model.AMD_7551 AMD 7551 accera.Target.Model.AMD_7551P AMD 7551P accera.Target.Model.AMD_7552 AMD 7552 accera.Target.Model.AMD_75F3 AMD 75F3 accera.Target.Model.AMD_7601 AMD 7601 accera.Target.Model.AMD_7642 AMD 7642 accera.Target.Model.AMD_7643 AMD 7643 accera.Target.Model.AMD_7662 AMD 7662 accera.Target.Model.AMD_7663 AMD 7663 accera.Target.Model.AMD_7702 AMD 7702 accera.Target.Model.AMD_7702P AMD 7702P accera.Target.Model.AMD_7713 AMD 7713 accera.Target.Model.AMD_7713P AMD 7713P accera.Target.Model.AMD_7742 AMD 7742 accera.Target.Model.AMD_7763 AMD 7763 accera.Target.Model.AMD_7F32 AMD 7F32 accera.Target.Model.AMD_7F52 AMD 7F52 accera.Target.Model.AMD_7F72 AMD 7F72 accera.Target.Model.AMD_7H12 AMD 7H12 accera.Target.Model.AMD_7V12 AMD 7V12 accera.Target.Model.AMD_FIREFLIGHT AMD FireFlight accera.Target.Model.AMD_PRO_1200 AMD PRO 1200 accera.Target.Model.AMD_PRO_1300 AMD PRO 1300 accera.Target.Model.AMD_PRO_1500 AMD PRO 1500 accera.Target.Model.AMD_PRO_1600 AMD PRO 1600 accera.Target.Model.AMD_PRO_1700 AMD PRO 1700 accera.Target.Model.AMD_PRO_1700X AMD PRO 1700X accera.Target.Model.AMD_PRO_200GE AMD PRO 200GE accera.Target.Model.AMD_PRO_2200G AMD PRO 2200G accera.Target.Model.AMD_PRO_2200GE AMD PRO 2200GE accera.Target.Model.AMD_PRO_2300U AMD PRO 2300U accera.Target.Model.AMD_PRO_2400G AMD PRO 2400G accera.Target.Model.AMD_PRO_2400GE AMD PRO 2400GE accera.Target.Model.AMD_PRO_2500U AMD PRO 2500U accera.Target.Model.AMD_PRO_2600 AMD PRO 2600 accera.Target.Model.AMD_PRO_2700 AMD PRO 2700 accera.Target.Model.AMD_PRO_2700U AMD PRO 2700U accera.Target.Model.AMD_PRO_2700X AMD PRO 2700X accera.Target.Model.AMD_PRO_300GE AMD PRO 300GE accera.Target.Model.AMD_PRO_300U AMD PRO 300U accera.Target.Model.AMD_PRO_3200G AMD PRO 3200G accera.Target.Model.AMD_PRO_3200GE AMD PRO 3200GE accera.Target.Model.AMD_PRO_3300U AMD PRO 3300U accera.Target.Model.AMD_PRO_3400G AMD PRO 3400G accera.Target.Model.AMD_PRO_3400GE AMD PRO 3400GE accera.Target.Model.AMD_PRO_3500U AMD PRO 3500U accera.Target.Model.AMD_PRO_3600 AMD PRO 3600 accera.Target.Model.AMD_PRO_3700 AMD PRO 3700 accera.Target.Model.AMD_PRO_3700U AMD PRO 3700U accera.Target.Model.AMD_PRO_3900 AMD PRO 3900 accera.Target.Model.AMD_PRO_4350G AMD PRO 4350G accera.Target.Model.AMD_PRO_4350GE AMD PRO 4350GE accera.Target.Model.AMD_PRO_4450U AMD PRO 4450U accera.Target.Model.AMD_PRO_4650G AMD PRO 4650G accera.Target.Model.AMD_PRO_4650GE AMD PRO 4650GE accera.Target.Model.AMD_PRO_4650U AMD PRO 4650U accera.Target.Model.AMD_PRO_4750G AMD PRO 4750G accera.Target.Model.AMD_PRO_4750GE AMD PRO 4750GE accera.Target.Model.AMD_PRO_4750U AMD PRO 4750U accera.Target.Model.AMD_PRO_5350G AMD PRO 5350G accera.Target.Model.AMD_PRO_5350GE AMD PRO 5350GE accera.Target.Model.AMD_PRO_5450U AMD PRO 5450U accera.Target.Model.AMD_PRO_5650G AMD PRO 5650G accera.Target.Model.AMD_PRO_5650GE AMD PRO 5650GE accera.Target.Model.AMD_PRO_5650U AMD PRO 5650U accera.Target.Model.AMD_PRO_5750G AMD PRO 5750G accera.Target.Model.AMD_PRO_5750GE AMD PRO 5750GE accera.Target.Model.AMD_PRO_5850U AMD PRO 5850U accera.Target.Model.AMD_R1102G AMD R1102G accera.Target.Model.AMD_R1305G AMD R1305G accera.Target.Model.AMD_R1505G AMD R1505G accera.Target.Model.AMD_R1606G AMD R1606G accera.Target.Model.AMD_V1202B AMD V1202B accera.Target.Model.AMD_V1404I AMD V1404I accera.Target.Model.AMD_V1500B AMD V1500B accera.Target.Model.AMD_V1605B AMD V1605B accera.Target.Model.AMD_V1756B AMD V1756B accera.Target.Model.AMD_V1780B AMD V1780B accera.Target.Model.AMD_V1807B AMD V1807B accera.Target.Model.AMD_V2516 AMD V2516 accera.Target.Model.AMD_V2546 AMD V2546 accera.Target.Model.AMD_V2718 AMD V2718 accera.Target.Model.AMD_V2748 AMD V2748 accera.Target.Model.ARM_CORTEX_M4 ARM Cortex-M4 accera.Target.Model.ARM_CORTEX_M4F ARM Cortex-M4F accera.Target.Model.APPLE_M1_MAX Apple M1 Max accera.Target.Model.INTEL_1000G1 Intel 1000G1 accera.Target.Model.INTEL_1000G4 Intel 1000G4 accera.Target.Model.INTEL_1005G1 Intel 1005G1 accera.Target.Model.INTEL_10100 Intel 10100 accera.Target.Model.INTEL_10100F Intel 10100F accera.Target.Model.INTEL_10100T Intel 10100T accera.Target.Model.INTEL_10300 Intel 10300 accera.Target.Model.INTEL_10300T Intel 10300T accera.Target.Model.INTEL_1030G4 Intel 1030G4 accera.Target.Model.INTEL_1030G7 Intel 1030G7 accera.Target.Model.INTEL_10320 Intel 10320 accera.Target.Model.INTEL_1035G1 Intel 1035G1 accera.Target.Model.INTEL_1035G4 Intel 1035G4 accera.Target.Model.INTEL_1035G7 Intel 1035G7 accera.Target.Model.INTEL_10400 Intel 10400 accera.Target.Model.INTEL_10400F Intel 10400F accera.Target.Model.INTEL_10400T Intel 10400T accera.Target.Model.INTEL_10500 Intel 10500 accera.Target.Model.INTEL_10500T Intel 10500T accera.Target.Model.INTEL_10600 Intel 10600 accera.Target.Model.INTEL_10600K Intel 10600K accera.Target.Model.INTEL_10600KF Intel 10600KF accera.Target.Model.INTEL_10600T Intel 10600T accera.Target.Model.INTEL_1060G7 Intel 1060G7 accera.Target.Model.INTEL_1065G7 Intel 1065G7 accera.Target.Model.INTEL_1068G7 Intel 1068G7 accera.Target.Model.INTEL_10700 Intel 10700 accera.Target.Model.INTEL_10700F Intel 10700F accera.Target.Model.INTEL_10700K Intel 10700K accera.Target.Model.INTEL_10700KF Intel 10700KF accera.Target.Model.INTEL_10700T Intel 10700T accera.Target.Model.INTEL_10850K Intel 10850K accera.Target.Model.INTEL_10900 Intel 10900 accera.Target.Model.INTEL_10900F Intel 10900F accera.Target.Model.INTEL_10900K Intel 10900K accera.Target.Model.INTEL_10900KF Intel 10900KF accera.Target.Model.INTEL_10900T Intel 10900T accera.Target.Model.INTEL_10910 Intel 10910 accera.Target.Model.INTEL_11100B Intel 11100B accera.Target.Model.INTEL_1115G7 Intel 1115G7 accera.Target.Model.INTEL_1125G7 Intel 1125G7 accera.Target.Model.INTEL_1135G7 Intel 1135G7 accera.Target.Model.INTEL_11400 Intel 11400 accera.Target.Model.INTEL_11400F Intel 11400F accera.Target.Model.INTEL_11400T Intel 11400T accera.Target.Model.INTEL_1145G7 Intel 1145G7 accera.Target.Model.INTEL_11500 Intel 11500 accera.Target.Model.INTEL_11500B Intel 11500B accera.Target.Model.INTEL_11500T Intel 11500T accera.Target.Model.INTEL_1155G7 Intel 1155G7 accera.Target.Model.INTEL_11600 Intel 11600 accera.Target.Model.INTEL_11600K Intel 11600K accera.Target.Model.INTEL_11600KF Intel 11600KF accera.Target.Model.INTEL_11600T Intel 11600T accera.Target.Model.INTEL_1165G7 Intel 1165G7 accera.Target.Model.INTEL_11700 Intel 11700 accera.Target.Model.INTEL_11700B Intel 11700B accera.Target.Model.INTEL_11700F Intel 11700F accera.Target.Model.INTEL_11700K Intel 11700K accera.Target.Model.INTEL_11700KF Intel 11700KF accera.Target.Model.INTEL_11700T Intel 11700T accera.Target.Model.INTEL_1185G7 Intel 1185G7 accera.Target.Model.INTEL_11900 Intel 11900 accera.Target.Model.INTEL_11900F Intel 11900F accera.Target.Model.INTEL_11900K Intel 11900K accera.Target.Model.INTEL_11900KB Intel 11900KB accera.Target.Model.INTEL_11900KF Intel 11900KF accera.Target.Model.INTEL_11900T Intel 11900T accera.Target.Model.INTEL_1195G7 Intel 1195G7 accera.Target.Model.INTEL_2104G Intel 2104G accera.Target.Model.INTEL_2124 Intel 2124 accera.Target.Model.INTEL_2124G Intel 2124G accera.Target.Model.INTEL_2126G Intel 2126G accera.Target.Model.INTEL_2134 Intel 2134 accera.Target.Model.INTEL_2136 Intel 2136 accera.Target.Model.INTEL_2144G Intel 2144G accera.Target.Model.INTEL_2146G Intel 2146G accera.Target.Model.INTEL_2174G Intel 2174G accera.Target.Model.INTEL_2176G Intel 2176G accera.Target.Model.INTEL_2186G Intel 2186G accera.Target.Model.INTEL_2314 Intel 2314 accera.Target.Model.INTEL_2324G Intel 2324G accera.Target.Model.INTEL_2334 Intel 2334 accera.Target.Model.INTEL_2336 Intel 2336 accera.Target.Model.INTEL_2356G Intel 2356G accera.Target.Model.INTEL_2374G Intel 2374G accera.Target.Model.INTEL_2378 Intel 2378 accera.Target.Model.INTEL_2378G Intel 2378G accera.Target.Model.INTEL_2386G Intel 2386G accera.Target.Model.INTEL_2388G Intel 2388G accera.Target.Model.INTEL_3204 Intel 3204 accera.Target.Model.INTEL_4108 Intel 4108 accera.Target.Model.INTEL_4109T Intel 4109T accera.Target.Model.INTEL_4110 Intel 4110 accera.Target.Model.INTEL_4112 Intel 4112 accera.Target.Model.INTEL_4114 Intel 4114 accera.Target.Model.INTEL_4208 Intel 4208 accera.Target.Model.INTEL_4209T Intel 4209T accera.Target.Model.INTEL_4210 Intel 4210 accera.Target.Model.INTEL_4210R Intel 4210R accera.Target.Model.INTEL_4214 Intel 4214 accera.Target.Model.INTEL_4214R Intel 4214R accera.Target.Model.INTEL_4214Y Intel 4214Y accera.Target.Model.INTEL_4215 Intel 4215 accera.Target.Model.INTEL_4215R Intel 4215R accera.Target.Model.INTEL_4216 Intel 4216 accera.Target.Model.INTEL_5215 Intel 5215 accera.Target.Model.INTEL_5215L Intel 5215L accera.Target.Model.INTEL_5215M Intel 5215M accera.Target.Model.INTEL_5217 Intel 5217 accera.Target.Model.INTEL_5218 Intel 5218 accera.Target.Model.INTEL_5218B Intel 5218B accera.Target.Model.INTEL_5218N Intel 5218N accera.Target.Model.INTEL_5218R Intel 5218R accera.Target.Model.INTEL_5218T Intel 5218T accera.Target.Model.INTEL_5220 Intel 5220 accera.Target.Model.INTEL_5220R Intel 5220R accera.Target.Model.INTEL_5220S Intel 5220S accera.Target.Model.INTEL_5220T Intel 5220T accera.Target.Model.INTEL_5222 Intel 5222 accera.Target.Model.INTEL_6035 Intel 6035 accera.Target.Model.INTEL_6098P Intel 6098P accera.Target.Model.INTEL_6100 Intel 6100 accera.Target.Model.INTEL_6100T Intel 6100T accera.Target.Model.INTEL_6209U Intel 6209U accera.Target.Model.INTEL_6210U Intel 6210U accera.Target.Model.INTEL_6212U Intel 6212U accera.Target.Model.INTEL_6222V Intel 6222V accera.Target.Model.INTEL_6226 Intel 6226 accera.Target.Model.INTEL_6226R Intel 6226R accera.Target.Model.INTEL_6230 Intel 6230 accera.Target.Model.INTEL_6230N Intel 6230N accera.Target.Model.INTEL_6230R Intel 6230R accera.Target.Model.INTEL_6230T Intel 6230T accera.Target.Model.INTEL_6234 Intel 6234 accera.Target.Model.INTEL_6238 Intel 6238 accera.Target.Model.INTEL_6238L Intel 6238L accera.Target.Model.INTEL_6238M Intel 6238M accera.Target.Model.INTEL_6238R Intel 6238R accera.Target.Model.INTEL_6238T Intel 6238T accera.Target.Model.INTEL_6240 Intel 6240 accera.Target.Model.INTEL_6240L Intel 6240L accera.Target.Model.INTEL_6240M Intel 6240M accera.Target.Model.INTEL_6240R Intel 6240R accera.Target.Model.INTEL_6240Y Intel 6240Y accera.Target.Model.INTEL_6242 Intel 6242 accera.Target.Model.INTEL_6242R Intel 6242R accera.Target.Model.INTEL_6244 Intel 6244 accera.Target.Model.INTEL_6246 Intel 6246 accera.Target.Model.INTEL_6246R Intel 6246R accera.Target.Model.INTEL_6248 Intel 6248 accera.Target.Model.INTEL_6248R Intel 6248R accera.Target.Model.INTEL_6252 Intel 6252 accera.Target.Model.INTEL_6252N Intel 6252N accera.Target.Model.INTEL_6254 Intel 6254 accera.Target.Model.INTEL_6258R Intel 6258R accera.Target.Model.INTEL_6262V Intel 6262V accera.Target.Model.INTEL_6300 Intel 6300 accera.Target.Model.INTEL_6300T Intel 6300T accera.Target.Model.INTEL_6320 Intel 6320 accera.Target.Model.INTEL_6400 Intel 6400 accera.Target.Model.INTEL_6400T Intel 6400T accera.Target.Model.INTEL_6402P Intel 6402P accera.Target.Model.INTEL_6500 Intel 6500 accera.Target.Model.INTEL_6500T Intel 6500T accera.Target.Model.INTEL_6585R Intel 6585R accera.Target.Model.INTEL_6600 Intel 6600 accera.Target.Model.INTEL_6600K Intel 6600K accera.Target.Model.INTEL_6600T Intel 6600T accera.Target.Model.INTEL_6685R Intel 6685R accera.Target.Model.INTEL_6700 Intel 6700 accera.Target.Model.INTEL_6700K Intel 6700K accera.Target.Model.INTEL_6700T Intel 6700T accera.Target.Model.INTEL_6785R Intel 6785R accera.Target.Model.INTEL_6820HQ Intel 6820HQ accera.Target.Model.INTEL_7100 Intel 7100 accera.Target.Model.INTEL_7100T Intel 7100T accera.Target.Model.INTEL_7101E Intel 7101E accera.Target.Model.INTEL_7101TE Intel 7101TE accera.Target.Model.INTEL_7300 Intel 7300 accera.Target.Model.INTEL_7300T Intel 7300T accera.Target.Model.INTEL_7320 Intel 7320 accera.Target.Model.INTEL_7350K Intel 7350K accera.Target.Model.INTEL_7400 Intel 7400 accera.Target.Model.INTEL_7400T Intel 7400T accera.Target.Model.INTEL_7500 Intel 7500 accera.Target.Model.INTEL_7500T Intel 7500T accera.Target.Model.INTEL_7505 Intel 7505 accera.Target.Model.INTEL_7600 Intel 7600 accera.Target.Model.INTEL_7600K Intel 7600K accera.Target.Model.INTEL_7600T Intel 7600T accera.Target.Model.INTEL_7640X Intel 7640X accera.Target.Model.INTEL_7700 Intel 7700 accera.Target.Model.INTEL_7700K Intel 7700K accera.Target.Model.INTEL_7700T Intel 7700T accera.Target.Model.INTEL_7740X Intel 7740X accera.Target.Model.INTEL_7800X Intel 7800X accera.Target.Model.INTEL_7820X Intel 7820X accera.Target.Model.INTEL_7900X Intel 7900X accera.Target.Model.INTEL_7920X Intel 7920X accera.Target.Model.INTEL_7940X Intel 7940X accera.Target.Model.INTEL_7960X Intel 7960X accera.Target.Model.INTEL_7980XE Intel 7980XE accera.Target.Model.INTEL_8086K Intel 8086K accera.Target.Model.INTEL_8100 Intel 8100 accera.Target.Model.INTEL_8100F Intel 8100F accera.Target.Model.INTEL_8100T Intel 8100T accera.Target.Model.INTEL_8253 Intel 8253 accera.Target.Model.INTEL_8256 Intel 8256 accera.Target.Model.INTEL_8260 Intel 8260 accera.Target.Model.INTEL_8260L Intel 8260L accera.Target.Model.INTEL_8260M Intel 8260M accera.Target.Model.INTEL_8260Y Intel 8260Y accera.Target.Model.INTEL_8268 Intel 8268 accera.Target.Model.INTEL_8270 Intel 8270 accera.Target.Model.INTEL_8272CL Intel 8272CL accera.Target.Model.INTEL_8273CL Intel 8273CL accera.Target.Model.INTEL_8276 Intel 8276 accera.Target.Model.INTEL_8276L Intel 8276L accera.Target.Model.INTEL_8276M Intel 8276M accera.Target.Model.INTEL_8280 Intel 8280 accera.Target.Model.INTEL_8280L Intel 8280L accera.Target.Model.INTEL_8280M Intel 8280M accera.Target.Model.INTEL_8284 Intel 8284 accera.Target.Model.INTEL_8300 Intel 8300 accera.Target.Model.INTEL_8300T Intel 8300T accera.Target.Model.INTEL_8350K Intel 8350K accera.Target.Model.INTEL_8351N Intel 8351N accera.Target.Model.INTEL_8352S Intel 8352S accera.Target.Model.INTEL_8352V Intel 8352V accera.Target.Model.INTEL_8352Y Intel 8352Y accera.Target.Model.INTEL_8358 Intel 8358 accera.Target.Model.INTEL_8358P Intel 8358P accera.Target.Model.INTEL_8360Y Intel 8360Y accera.Target.Model.INTEL_8362 Intel 8362 accera.Target.Model.INTEL_8368 Intel 8368 accera.Target.Model.INTEL_8368Q Intel 8368Q accera.Target.Model.INTEL_8380 Intel 8380 accera.Target.Model.INTEL_8400 Intel 8400 accera.Target.Model.INTEL_8400T Intel 8400T accera.Target.Model.INTEL_8500 Intel 8500 accera.Target.Model.INTEL_8500T Intel 8500T accera.Target.Model.INTEL_8550U Intel 8550U accera.Target.Model.INTEL_8600 Intel 8600 accera.Target.Model.INTEL_8600K Intel 8600K accera.Target.Model.INTEL_8600T Intel 8600T accera.Target.Model.INTEL_8650U Intel 8650U accera.Target.Model.INTEL_8700 Intel 8700 accera.Target.Model.INTEL_8700K Intel 8700K accera.Target.Model.INTEL_8700T Intel 8700T accera.Target.Model.INTEL_9221 Intel 9221 accera.Target.Model.INTEL_9222 Intel 9222 accera.Target.Model.INTEL_9242 Intel 9242 accera.Target.Model.INTEL_9282 Intel 9282 accera.Target.Model.INTEL_9800X Intel 9800X accera.Target.Model.INTEL_9820X Intel 9820X accera.Target.Model.INTEL_9900X Intel 9900X accera.Target.Model.INTEL_9920X Intel 9920X accera.Target.Model.INTEL_9940X Intel 9940X accera.Target.Model.INTEL_9960X Intel 9960X accera.Target.Model.INTEL_9980XE Intel 9980XE accera.Target.Model.INTEL_9990XE Intel 9990XE accera.Target.Model.INTEL_E3_1220_V6 Intel E3-1220 v6 accera.Target.Model.INTEL_E3_1225_V6 Intel E3-1225 v6 accera.Target.Model.INTEL_E3_1230_V6 Intel E3-1230 v6 accera.Target.Model.INTEL_E3_1240_V6 Intel E3-1240 v6 accera.Target.Model.INTEL_E3_1245_V6 Intel E3-1245 v6 accera.Target.Model.INTEL_E3_1270_V6 Intel E3-1270 v6 accera.Target.Model.INTEL_E3_1275_V6 Intel E3-1275 v6 accera.Target.Model.INTEL_E3_1280_V6 Intel E3-1280 v6 accera.Target.Model.INTEL_E3_1285_V6 Intel E3-1285 v6 accera.Target.Model.INTEL_E5_1607_V2 Intel E5-1607 v2 accera.Target.Model.INTEL_E5_1620_V2 Intel E5-1620 v2 accera.Target.Model.INTEL_E5_1650_V2 Intel E5-1650 v2 accera.Target.Model.INTEL_E5_1650_V3 Intel E5-1650 v3 accera.Target.Model.INTEL_E5_1660_V2 Intel E5-1660 v2 accera.Target.Model.INTEL_E5_1660_V3 Intel E5-1660 v3 accera.Target.Model.INTEL_E5_1680_V2 Intel E5-1680 v2 accera.Target.Model.INTEL_E5_1680_V3 Intel E5-1680 v3 accera.Target.Model.INTEL_G3900 Intel G3900 accera.Target.Model.INTEL_G3900T Intel G3900T accera.Target.Model.INTEL_G3900TE Intel G3900TE accera.Target.Model.INTEL_G3920 Intel G3920 accera.Target.Model.INTEL_G4400 Intel G4400 accera.Target.Model.INTEL_G4400T Intel G4400T accera.Target.Model.INTEL_G4400TE Intel G4400TE accera.Target.Model.INTEL_G4500 Intel G4500 accera.Target.Model.INTEL_G4500T Intel G4500T accera.Target.Model.INTEL_G4520 Intel G4520 accera.Target.Model.INTEL_W_1250 Intel W-1250 accera.Target.Model.INTEL_W_1250P Intel W-1250P accera.Target.Model.INTEL_W_1270 Intel W-1270 accera.Target.Model.INTEL_W_1270P Intel W-1270P accera.Target.Model.INTEL_W_1290 Intel W-1290 accera.Target.Model.INTEL_W_1290P Intel W-1290P accera.Target.Model.INTEL_W_1290T Intel W-1290T accera.Target.Model.INTEL_W_1350 Intel W-1350 accera.Target.Model.INTEL_W_1350P Intel W-1350P accera.Target.Model.INTEL_W_1370 Intel W-1370 accera.Target.Model.INTEL_W_1370P Intel W-1370P accera.Target.Model.INTEL_W_1390 Intel W-1390 accera.Target.Model.INTEL_W_1390P Intel W-1390P accera.Target.Model.INTEL_W_1390T Intel W-1390T accera.Target.Model.INTEL_W_2102 Intel W-2102 accera.Target.Model.INTEL_W_2104 Intel W-2104 accera.Target.Model.INTEL_W_2123 Intel W-2123 accera.Target.Model.INTEL_W_2125 Intel W-2125 accera.Target.Model.INTEL_W_2133 Intel W-2133 accera.Target.Model.INTEL_W_2135 Intel W-2135 accera.Target.Model.INTEL_W_2140B Intel W-2140B accera.Target.Model.INTEL_W_2150B Intel W-2150B accera.Target.Model.INTEL_W_3175X Intel W-3175X accera.Target.Model.INTEL_W_3223 Intel W-3223 accera.Target.Model.INTEL_W_3225 Intel W-3225 accera.Target.Model.INTEL_W_3235 Intel W-3235 accera.Target.Model.INTEL_W_3245 Intel W-3245 accera.Target.Model.INTEL_W_3245M Intel W-3245M accera.Target.Model.INTEL_W_3265 Intel W-3265 accera.Target.Model.INTEL_W_3265M Intel W-3265M accera.Target.Model.INTEL_W_3275 Intel W-3275 accera.Target.Model.INTEL_W_3275M Intel W-3275M accera.Target.Model.RASPBERRY_PI_3B Raspberry Pi 3B accera.Target.Model.RASPBERRY_PI_4B Raspberry Pi 4B accera.Target.Model.RASPBERRY_PI_ZERO Raspberry Pi Zero The enum also defines constants for some well-known GPU models. type description accera.Target.Model.AMD_MI100 AMD MI100 accera.Target.Model.AMD_MI200 AMD MI200 accera.Target.Model.AMD_MI50 AMD MI50 accera.Target.Model.AMD_RADEON7 AMD Radeon7 accera.Target.Model.NVIDIA_A100 NVidia A100 accera.Target.Model.NVIDIA_P100 NVidia P100 accera.Target.Model.NVIDIA_RTX_A6000 NVidia RTX A6000 accera.Target.Model.NVIDIA_V100 NVidia V100","title":"Model"},{"location":"Reference/classes/Target/Model/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Target/Model/#acceratargetmodel","text":"Defines constants for some well-known CPU models. type description accera.Target.Model.AMD_1200 AMD 1200 accera.Target.Model.AMD_1300X AMD 1300X accera.Target.Model.AMD_1400 AMD 1400 accera.Target.Model.AMD_1500X AMD 1500X accera.Target.Model.AMD_1600 AMD 1600 accera.Target.Model.AMD_1600X AMD 1600X accera.Target.Model.AMD_1700 AMD 1700 accera.Target.Model.AMD_1700X AMD 1700X accera.Target.Model.AMD_1800X AMD 1800X accera.Target.Model.AMD_1900X AMD 1900X accera.Target.Model.AMD_1920X AMD 1920X accera.Target.Model.AMD_1950X AMD 1950X accera.Target.Model.AMD_200GE AMD 200GE accera.Target.Model.AMD_2200G AMD 2200G accera.Target.Model.AMD_2200GE AMD 2200GE accera.Target.Model.AMD_2200U AMD 2200U accera.Target.Model.AMD_220GE AMD 220GE accera.Target.Model.AMD_2300U AMD 2300U accera.Target.Model.AMD_2300X AMD 2300X accera.Target.Model.AMD_2400G AMD 2400G accera.Target.Model.AMD_2400GE AMD 2400GE accera.Target.Model.AMD_240GE AMD 240GE accera.Target.Model.AMD_2500U AMD 2500U accera.Target.Model.AMD_2500X AMD 2500X accera.Target.Model.AMD_2600 AMD 2600 accera.Target.Model.AMD_2600E AMD 2600E accera.Target.Model.AMD_2600H AMD 2600H accera.Target.Model.AMD_2600X AMD 2600X accera.Target.Model.AMD_2700 AMD 2700 accera.Target.Model.AMD_2700E AMD 2700E accera.Target.Model.AMD_2700U AMD 2700U accera.Target.Model.AMD_2700X AMD 2700X accera.Target.Model.AMD_2700X_GOLD_EDITION AMD 2700X Gold Edition accera.Target.Model.AMD_2800H AMD 2800H accera.Target.Model.AMD_2920X AMD 2920X accera.Target.Model.AMD_2950X AMD 2950X accera.Target.Model.AMD_2970WX AMD 2970WX accera.Target.Model.AMD_2990WX AMD 2990WX accera.Target.Model.AMD_3000G AMD 3000G accera.Target.Model.AMD_300U AMD 300U accera.Target.Model.AMD_3050U AMD 3050U accera.Target.Model.AMD_3101 AMD 3101 accera.Target.Model.AMD_3150U AMD 3150U accera.Target.Model.AMD_3151 AMD 3151 accera.Target.Model.AMD_3200G AMD 3200G accera.Target.Model.AMD_3200U AMD 3200U accera.Target.Model.AMD_3201 AMD 3201 accera.Target.Model.AMD_3250U AMD 3250U accera.Target.Model.AMD_3251 AMD 3251 accera.Target.Model.AMD_3255 AMD 3255 accera.Target.Model.AMD_3300U AMD 3300U accera.Target.Model.AMD_3301 AMD 3301 accera.Target.Model.AMD_3351 AMD 3351 accera.Target.Model.AMD_3400G AMD 3400G accera.Target.Model.AMD_3401 AMD 3401 accera.Target.Model.AMD_3451 AMD 3451 accera.Target.Model.AMD_3500 AMD 3500 accera.Target.Model.AMD_3500U AMD 3500U accera.Target.Model.AMD_3500X AMD 3500X accera.Target.Model.AMD_3550H AMD 3550H accera.Target.Model.AMD_3580U AMD 3580U accera.Target.Model.AMD_3600 AMD 3600 accera.Target.Model.AMD_3600X AMD 3600X accera.Target.Model.AMD_3600XT AMD 3600XT accera.Target.Model.AMD_3700U AMD 3700U accera.Target.Model.AMD_3700X AMD 3700X accera.Target.Model.AMD_3750H AMD 3750H accera.Target.Model.AMD_3780U AMD 3780U accera.Target.Model.AMD_3800X AMD 3800X accera.Target.Model.AMD_3800XT AMD 3800XT accera.Target.Model.AMD_3900 AMD 3900 accera.Target.Model.AMD_3900X AMD 3900X accera.Target.Model.AMD_3900XT AMD 3900XT accera.Target.Model.AMD_3950X AMD 3950X accera.Target.Model.AMD_3960X AMD 3960X accera.Target.Model.AMD_3970X AMD 3970X accera.Target.Model.AMD_3980X AMD 3980X accera.Target.Model.AMD_3990X AMD 3990X accera.Target.Model.AMD_4300G AMD 4300G accera.Target.Model.AMD_4300GE AMD 4300GE accera.Target.Model.AMD_4300U AMD 4300U accera.Target.Model.AMD_4500U AMD 4500U accera.Target.Model.AMD_4600G AMD 4600G accera.Target.Model.AMD_4600GE AMD 4600GE accera.Target.Model.AMD_4600H AMD 4600H accera.Target.Model.AMD_4600HS AMD 4600HS accera.Target.Model.AMD_4600U AMD 4600U accera.Target.Model.AMD_4680U AMD 4680U accera.Target.Model.AMD_4700G AMD 4700G accera.Target.Model.AMD_4700GE AMD 4700GE accera.Target.Model.AMD_4700U AMD 4700U accera.Target.Model.AMD_4800H AMD 4800H accera.Target.Model.AMD_4800HS AMD 4800HS accera.Target.Model.AMD_4800U AMD 4800U accera.Target.Model.AMD_4900H AMD 4900H accera.Target.Model.AMD_4900HS AMD 4900HS accera.Target.Model.AMD_4980U AMD 4980U accera.Target.Model.AMD_5300G AMD 5300G accera.Target.Model.AMD_5300GE AMD 5300GE accera.Target.Model.AMD_5300U AMD 5300U accera.Target.Model.AMD_5400U AMD 5400U accera.Target.Model.AMD_5500U AMD 5500U accera.Target.Model.AMD_5600G AMD 5600G accera.Target.Model.AMD_5600GE AMD 5600GE accera.Target.Model.AMD_5600H AMD 5600H accera.Target.Model.AMD_5600HS AMD 5600HS accera.Target.Model.AMD_5600U AMD 5600U accera.Target.Model.AMD_5600X AMD 5600X accera.Target.Model.AMD_5700G AMD 5700G accera.Target.Model.AMD_5700GE AMD 5700GE accera.Target.Model.AMD_5700U AMD 5700U accera.Target.Model.AMD_5800 AMD 5800 accera.Target.Model.AMD_5800H AMD 5800H accera.Target.Model.AMD_5800HS AMD 5800HS accera.Target.Model.AMD_5800U AMD 5800U accera.Target.Model.AMD_5800X AMD 5800X accera.Target.Model.AMD_5900 AMD 5900 accera.Target.Model.AMD_5900HS AMD 5900HS accera.Target.Model.AMD_5900HX AMD 5900HX accera.Target.Model.AMD_5900X AMD 5900X accera.Target.Model.AMD_5950X AMD 5950X accera.Target.Model.AMD_5980HS AMD 5980HS accera.Target.Model.AMD_5980HX AMD 5980HX accera.Target.Model.AMD_7232P AMD 7232P accera.Target.Model.AMD_7251 AMD 7251 accera.Target.Model.AMD_7252 AMD 7252 accera.Target.Model.AMD_7261 AMD 7261 accera.Target.Model.AMD_7262 AMD 7262 accera.Target.Model.AMD_7272 AMD 7272 accera.Target.Model.AMD_7281 AMD 7281 accera.Target.Model.AMD_7282 AMD 7282 accera.Target.Model.AMD_72F3 AMD 72F3 accera.Target.Model.AMD_7301 AMD 7301 accera.Target.Model.AMD_7302 AMD 7302 accera.Target.Model.AMD_7302P AMD 7302P accera.Target.Model.AMD_7313 AMD 7313 accera.Target.Model.AMD_7313P AMD 7313P accera.Target.Model.AMD_7343 AMD 7343 accera.Target.Model.AMD_7351 AMD 7351 accera.Target.Model.AMD_7351P AMD 7351P accera.Target.Model.AMD_7352 AMD 7352 accera.Target.Model.AMD_7371 AMD 7371 accera.Target.Model.AMD_73F3 AMD 73F3 accera.Target.Model.AMD_7401 AMD 7401 accera.Target.Model.AMD_7401P AMD 7401P accera.Target.Model.AMD_7402 AMD 7402 accera.Target.Model.AMD_7402P AMD 7402P accera.Target.Model.AMD_7413 AMD 7413 accera.Target.Model.AMD_7443 AMD 7443 accera.Target.Model.AMD_7443P AMD 7443P accera.Target.Model.AMD_7451 AMD 7451 accera.Target.Model.AMD_7452 AMD 7452 accera.Target.Model.AMD_7453 AMD 7453 accera.Target.Model.AMD_74F3 AMD 74F3 accera.Target.Model.AMD_7501 AMD 7501 accera.Target.Model.AMD_7502 AMD 7502 accera.Target.Model.AMD_7502P AMD 7502P accera.Target.Model.AMD_7513 AMD 7513 accera.Target.Model.AMD_7532 AMD 7532 accera.Target.Model.AMD_7542 AMD 7542 accera.Target.Model.AMD_7543 AMD 7543 accera.Target.Model.AMD_7543P AMD 7543P accera.Target.Model.AMD_7551 AMD 7551 accera.Target.Model.AMD_7551P AMD 7551P accera.Target.Model.AMD_7552 AMD 7552 accera.Target.Model.AMD_75F3 AMD 75F3 accera.Target.Model.AMD_7601 AMD 7601 accera.Target.Model.AMD_7642 AMD 7642 accera.Target.Model.AMD_7643 AMD 7643 accera.Target.Model.AMD_7662 AMD 7662 accera.Target.Model.AMD_7663 AMD 7663 accera.Target.Model.AMD_7702 AMD 7702 accera.Target.Model.AMD_7702P AMD 7702P accera.Target.Model.AMD_7713 AMD 7713 accera.Target.Model.AMD_7713P AMD 7713P accera.Target.Model.AMD_7742 AMD 7742 accera.Target.Model.AMD_7763 AMD 7763 accera.Target.Model.AMD_7F32 AMD 7F32 accera.Target.Model.AMD_7F52 AMD 7F52 accera.Target.Model.AMD_7F72 AMD 7F72 accera.Target.Model.AMD_7H12 AMD 7H12 accera.Target.Model.AMD_7V12 AMD 7V12 accera.Target.Model.AMD_FIREFLIGHT AMD FireFlight accera.Target.Model.AMD_PRO_1200 AMD PRO 1200 accera.Target.Model.AMD_PRO_1300 AMD PRO 1300 accera.Target.Model.AMD_PRO_1500 AMD PRO 1500 accera.Target.Model.AMD_PRO_1600 AMD PRO 1600 accera.Target.Model.AMD_PRO_1700 AMD PRO 1700 accera.Target.Model.AMD_PRO_1700X AMD PRO 1700X accera.Target.Model.AMD_PRO_200GE AMD PRO 200GE accera.Target.Model.AMD_PRO_2200G AMD PRO 2200G accera.Target.Model.AMD_PRO_2200GE AMD PRO 2200GE accera.Target.Model.AMD_PRO_2300U AMD PRO 2300U accera.Target.Model.AMD_PRO_2400G AMD PRO 2400G accera.Target.Model.AMD_PRO_2400GE AMD PRO 2400GE accera.Target.Model.AMD_PRO_2500U AMD PRO 2500U accera.Target.Model.AMD_PRO_2600 AMD PRO 2600 accera.Target.Model.AMD_PRO_2700 AMD PRO 2700 accera.Target.Model.AMD_PRO_2700U AMD PRO 2700U accera.Target.Model.AMD_PRO_2700X AMD PRO 2700X accera.Target.Model.AMD_PRO_300GE AMD PRO 300GE accera.Target.Model.AMD_PRO_300U AMD PRO 300U accera.Target.Model.AMD_PRO_3200G AMD PRO 3200G accera.Target.Model.AMD_PRO_3200GE AMD PRO 3200GE accera.Target.Model.AMD_PRO_3300U AMD PRO 3300U accera.Target.Model.AMD_PRO_3400G AMD PRO 3400G accera.Target.Model.AMD_PRO_3400GE AMD PRO 3400GE accera.Target.Model.AMD_PRO_3500U AMD PRO 3500U accera.Target.Model.AMD_PRO_3600 AMD PRO 3600 accera.Target.Model.AMD_PRO_3700 AMD PRO 3700 accera.Target.Model.AMD_PRO_3700U AMD PRO 3700U accera.Target.Model.AMD_PRO_3900 AMD PRO 3900 accera.Target.Model.AMD_PRO_4350G AMD PRO 4350G accera.Target.Model.AMD_PRO_4350GE AMD PRO 4350GE accera.Target.Model.AMD_PRO_4450U AMD PRO 4450U accera.Target.Model.AMD_PRO_4650G AMD PRO 4650G accera.Target.Model.AMD_PRO_4650GE AMD PRO 4650GE accera.Target.Model.AMD_PRO_4650U AMD PRO 4650U accera.Target.Model.AMD_PRO_4750G AMD PRO 4750G accera.Target.Model.AMD_PRO_4750GE AMD PRO 4750GE accera.Target.Model.AMD_PRO_4750U AMD PRO 4750U accera.Target.Model.AMD_PRO_5350G AMD PRO 5350G accera.Target.Model.AMD_PRO_5350GE AMD PRO 5350GE accera.Target.Model.AMD_PRO_5450U AMD PRO 5450U accera.Target.Model.AMD_PRO_5650G AMD PRO 5650G accera.Target.Model.AMD_PRO_5650GE AMD PRO 5650GE accera.Target.Model.AMD_PRO_5650U AMD PRO 5650U accera.Target.Model.AMD_PRO_5750G AMD PRO 5750G accera.Target.Model.AMD_PRO_5750GE AMD PRO 5750GE accera.Target.Model.AMD_PRO_5850U AMD PRO 5850U accera.Target.Model.AMD_R1102G AMD R1102G accera.Target.Model.AMD_R1305G AMD R1305G accera.Target.Model.AMD_R1505G AMD R1505G accera.Target.Model.AMD_R1606G AMD R1606G accera.Target.Model.AMD_V1202B AMD V1202B accera.Target.Model.AMD_V1404I AMD V1404I accera.Target.Model.AMD_V1500B AMD V1500B accera.Target.Model.AMD_V1605B AMD V1605B accera.Target.Model.AMD_V1756B AMD V1756B accera.Target.Model.AMD_V1780B AMD V1780B accera.Target.Model.AMD_V1807B AMD V1807B accera.Target.Model.AMD_V2516 AMD V2516 accera.Target.Model.AMD_V2546 AMD V2546 accera.Target.Model.AMD_V2718 AMD V2718 accera.Target.Model.AMD_V2748 AMD V2748 accera.Target.Model.ARM_CORTEX_M4 ARM Cortex-M4 accera.Target.Model.ARM_CORTEX_M4F ARM Cortex-M4F accera.Target.Model.APPLE_M1_MAX Apple M1 Max accera.Target.Model.INTEL_1000G1 Intel 1000G1 accera.Target.Model.INTEL_1000G4 Intel 1000G4 accera.Target.Model.INTEL_1005G1 Intel 1005G1 accera.Target.Model.INTEL_10100 Intel 10100 accera.Target.Model.INTEL_10100F Intel 10100F accera.Target.Model.INTEL_10100T Intel 10100T accera.Target.Model.INTEL_10300 Intel 10300 accera.Target.Model.INTEL_10300T Intel 10300T accera.Target.Model.INTEL_1030G4 Intel 1030G4 accera.Target.Model.INTEL_1030G7 Intel 1030G7 accera.Target.Model.INTEL_10320 Intel 10320 accera.Target.Model.INTEL_1035G1 Intel 1035G1 accera.Target.Model.INTEL_1035G4 Intel 1035G4 accera.Target.Model.INTEL_1035G7 Intel 1035G7 accera.Target.Model.INTEL_10400 Intel 10400 accera.Target.Model.INTEL_10400F Intel 10400F accera.Target.Model.INTEL_10400T Intel 10400T accera.Target.Model.INTEL_10500 Intel 10500 accera.Target.Model.INTEL_10500T Intel 10500T accera.Target.Model.INTEL_10600 Intel 10600 accera.Target.Model.INTEL_10600K Intel 10600K accera.Target.Model.INTEL_10600KF Intel 10600KF accera.Target.Model.INTEL_10600T Intel 10600T accera.Target.Model.INTEL_1060G7 Intel 1060G7 accera.Target.Model.INTEL_1065G7 Intel 1065G7 accera.Target.Model.INTEL_1068G7 Intel 1068G7 accera.Target.Model.INTEL_10700 Intel 10700 accera.Target.Model.INTEL_10700F Intel 10700F accera.Target.Model.INTEL_10700K Intel 10700K accera.Target.Model.INTEL_10700KF Intel 10700KF accera.Target.Model.INTEL_10700T Intel 10700T accera.Target.Model.INTEL_10850K Intel 10850K accera.Target.Model.INTEL_10900 Intel 10900 accera.Target.Model.INTEL_10900F Intel 10900F accera.Target.Model.INTEL_10900K Intel 10900K accera.Target.Model.INTEL_10900KF Intel 10900KF accera.Target.Model.INTEL_10900T Intel 10900T accera.Target.Model.INTEL_10910 Intel 10910 accera.Target.Model.INTEL_11100B Intel 11100B accera.Target.Model.INTEL_1115G7 Intel 1115G7 accera.Target.Model.INTEL_1125G7 Intel 1125G7 accera.Target.Model.INTEL_1135G7 Intel 1135G7 accera.Target.Model.INTEL_11400 Intel 11400 accera.Target.Model.INTEL_11400F Intel 11400F accera.Target.Model.INTEL_11400T Intel 11400T accera.Target.Model.INTEL_1145G7 Intel 1145G7 accera.Target.Model.INTEL_11500 Intel 11500 accera.Target.Model.INTEL_11500B Intel 11500B accera.Target.Model.INTEL_11500T Intel 11500T accera.Target.Model.INTEL_1155G7 Intel 1155G7 accera.Target.Model.INTEL_11600 Intel 11600 accera.Target.Model.INTEL_11600K Intel 11600K accera.Target.Model.INTEL_11600KF Intel 11600KF accera.Target.Model.INTEL_11600T Intel 11600T accera.Target.Model.INTEL_1165G7 Intel 1165G7 accera.Target.Model.INTEL_11700 Intel 11700 accera.Target.Model.INTEL_11700B Intel 11700B accera.Target.Model.INTEL_11700F Intel 11700F accera.Target.Model.INTEL_11700K Intel 11700K accera.Target.Model.INTEL_11700KF Intel 11700KF accera.Target.Model.INTEL_11700T Intel 11700T accera.Target.Model.INTEL_1185G7 Intel 1185G7 accera.Target.Model.INTEL_11900 Intel 11900 accera.Target.Model.INTEL_11900F Intel 11900F accera.Target.Model.INTEL_11900K Intel 11900K accera.Target.Model.INTEL_11900KB Intel 11900KB accera.Target.Model.INTEL_11900KF Intel 11900KF accera.Target.Model.INTEL_11900T Intel 11900T accera.Target.Model.INTEL_1195G7 Intel 1195G7 accera.Target.Model.INTEL_2104G Intel 2104G accera.Target.Model.INTEL_2124 Intel 2124 accera.Target.Model.INTEL_2124G Intel 2124G accera.Target.Model.INTEL_2126G Intel 2126G accera.Target.Model.INTEL_2134 Intel 2134 accera.Target.Model.INTEL_2136 Intel 2136 accera.Target.Model.INTEL_2144G Intel 2144G accera.Target.Model.INTEL_2146G Intel 2146G accera.Target.Model.INTEL_2174G Intel 2174G accera.Target.Model.INTEL_2176G Intel 2176G accera.Target.Model.INTEL_2186G Intel 2186G accera.Target.Model.INTEL_2314 Intel 2314 accera.Target.Model.INTEL_2324G Intel 2324G accera.Target.Model.INTEL_2334 Intel 2334 accera.Target.Model.INTEL_2336 Intel 2336 accera.Target.Model.INTEL_2356G Intel 2356G accera.Target.Model.INTEL_2374G Intel 2374G accera.Target.Model.INTEL_2378 Intel 2378 accera.Target.Model.INTEL_2378G Intel 2378G accera.Target.Model.INTEL_2386G Intel 2386G accera.Target.Model.INTEL_2388G Intel 2388G accera.Target.Model.INTEL_3204 Intel 3204 accera.Target.Model.INTEL_4108 Intel 4108 accera.Target.Model.INTEL_4109T Intel 4109T accera.Target.Model.INTEL_4110 Intel 4110 accera.Target.Model.INTEL_4112 Intel 4112 accera.Target.Model.INTEL_4114 Intel 4114 accera.Target.Model.INTEL_4208 Intel 4208 accera.Target.Model.INTEL_4209T Intel 4209T accera.Target.Model.INTEL_4210 Intel 4210 accera.Target.Model.INTEL_4210R Intel 4210R accera.Target.Model.INTEL_4214 Intel 4214 accera.Target.Model.INTEL_4214R Intel 4214R accera.Target.Model.INTEL_4214Y Intel 4214Y accera.Target.Model.INTEL_4215 Intel 4215 accera.Target.Model.INTEL_4215R Intel 4215R accera.Target.Model.INTEL_4216 Intel 4216 accera.Target.Model.INTEL_5215 Intel 5215 accera.Target.Model.INTEL_5215L Intel 5215L accera.Target.Model.INTEL_5215M Intel 5215M accera.Target.Model.INTEL_5217 Intel 5217 accera.Target.Model.INTEL_5218 Intel 5218 accera.Target.Model.INTEL_5218B Intel 5218B accera.Target.Model.INTEL_5218N Intel 5218N accera.Target.Model.INTEL_5218R Intel 5218R accera.Target.Model.INTEL_5218T Intel 5218T accera.Target.Model.INTEL_5220 Intel 5220 accera.Target.Model.INTEL_5220R Intel 5220R accera.Target.Model.INTEL_5220S Intel 5220S accera.Target.Model.INTEL_5220T Intel 5220T accera.Target.Model.INTEL_5222 Intel 5222 accera.Target.Model.INTEL_6035 Intel 6035 accera.Target.Model.INTEL_6098P Intel 6098P accera.Target.Model.INTEL_6100 Intel 6100 accera.Target.Model.INTEL_6100T Intel 6100T accera.Target.Model.INTEL_6209U Intel 6209U accera.Target.Model.INTEL_6210U Intel 6210U accera.Target.Model.INTEL_6212U Intel 6212U accera.Target.Model.INTEL_6222V Intel 6222V accera.Target.Model.INTEL_6226 Intel 6226 accera.Target.Model.INTEL_6226R Intel 6226R accera.Target.Model.INTEL_6230 Intel 6230 accera.Target.Model.INTEL_6230N Intel 6230N accera.Target.Model.INTEL_6230R Intel 6230R accera.Target.Model.INTEL_6230T Intel 6230T accera.Target.Model.INTEL_6234 Intel 6234 accera.Target.Model.INTEL_6238 Intel 6238 accera.Target.Model.INTEL_6238L Intel 6238L accera.Target.Model.INTEL_6238M Intel 6238M accera.Target.Model.INTEL_6238R Intel 6238R accera.Target.Model.INTEL_6238T Intel 6238T accera.Target.Model.INTEL_6240 Intel 6240 accera.Target.Model.INTEL_6240L Intel 6240L accera.Target.Model.INTEL_6240M Intel 6240M accera.Target.Model.INTEL_6240R Intel 6240R accera.Target.Model.INTEL_6240Y Intel 6240Y accera.Target.Model.INTEL_6242 Intel 6242 accera.Target.Model.INTEL_6242R Intel 6242R accera.Target.Model.INTEL_6244 Intel 6244 accera.Target.Model.INTEL_6246 Intel 6246 accera.Target.Model.INTEL_6246R Intel 6246R accera.Target.Model.INTEL_6248 Intel 6248 accera.Target.Model.INTEL_6248R Intel 6248R accera.Target.Model.INTEL_6252 Intel 6252 accera.Target.Model.INTEL_6252N Intel 6252N accera.Target.Model.INTEL_6254 Intel 6254 accera.Target.Model.INTEL_6258R Intel 6258R accera.Target.Model.INTEL_6262V Intel 6262V accera.Target.Model.INTEL_6300 Intel 6300 accera.Target.Model.INTEL_6300T Intel 6300T accera.Target.Model.INTEL_6320 Intel 6320 accera.Target.Model.INTEL_6400 Intel 6400 accera.Target.Model.INTEL_6400T Intel 6400T accera.Target.Model.INTEL_6402P Intel 6402P accera.Target.Model.INTEL_6500 Intel 6500 accera.Target.Model.INTEL_6500T Intel 6500T accera.Target.Model.INTEL_6585R Intel 6585R accera.Target.Model.INTEL_6600 Intel 6600 accera.Target.Model.INTEL_6600K Intel 6600K accera.Target.Model.INTEL_6600T Intel 6600T accera.Target.Model.INTEL_6685R Intel 6685R accera.Target.Model.INTEL_6700 Intel 6700 accera.Target.Model.INTEL_6700K Intel 6700K accera.Target.Model.INTEL_6700T Intel 6700T accera.Target.Model.INTEL_6785R Intel 6785R accera.Target.Model.INTEL_6820HQ Intel 6820HQ accera.Target.Model.INTEL_7100 Intel 7100 accera.Target.Model.INTEL_7100T Intel 7100T accera.Target.Model.INTEL_7101E Intel 7101E accera.Target.Model.INTEL_7101TE Intel 7101TE accera.Target.Model.INTEL_7300 Intel 7300 accera.Target.Model.INTEL_7300T Intel 7300T accera.Target.Model.INTEL_7320 Intel 7320 accera.Target.Model.INTEL_7350K Intel 7350K accera.Target.Model.INTEL_7400 Intel 7400 accera.Target.Model.INTEL_7400T Intel 7400T accera.Target.Model.INTEL_7500 Intel 7500 accera.Target.Model.INTEL_7500T Intel 7500T accera.Target.Model.INTEL_7505 Intel 7505 accera.Target.Model.INTEL_7600 Intel 7600 accera.Target.Model.INTEL_7600K Intel 7600K accera.Target.Model.INTEL_7600T Intel 7600T accera.Target.Model.INTEL_7640X Intel 7640X accera.Target.Model.INTEL_7700 Intel 7700 accera.Target.Model.INTEL_7700K Intel 7700K accera.Target.Model.INTEL_7700T Intel 7700T accera.Target.Model.INTEL_7740X Intel 7740X accera.Target.Model.INTEL_7800X Intel 7800X accera.Target.Model.INTEL_7820X Intel 7820X accera.Target.Model.INTEL_7900X Intel 7900X accera.Target.Model.INTEL_7920X Intel 7920X accera.Target.Model.INTEL_7940X Intel 7940X accera.Target.Model.INTEL_7960X Intel 7960X accera.Target.Model.INTEL_7980XE Intel 7980XE accera.Target.Model.INTEL_8086K Intel 8086K accera.Target.Model.INTEL_8100 Intel 8100 accera.Target.Model.INTEL_8100F Intel 8100F accera.Target.Model.INTEL_8100T Intel 8100T accera.Target.Model.INTEL_8253 Intel 8253 accera.Target.Model.INTEL_8256 Intel 8256 accera.Target.Model.INTEL_8260 Intel 8260 accera.Target.Model.INTEL_8260L Intel 8260L accera.Target.Model.INTEL_8260M Intel 8260M accera.Target.Model.INTEL_8260Y Intel 8260Y accera.Target.Model.INTEL_8268 Intel 8268 accera.Target.Model.INTEL_8270 Intel 8270 accera.Target.Model.INTEL_8272CL Intel 8272CL accera.Target.Model.INTEL_8273CL Intel 8273CL accera.Target.Model.INTEL_8276 Intel 8276 accera.Target.Model.INTEL_8276L Intel 8276L accera.Target.Model.INTEL_8276M Intel 8276M accera.Target.Model.INTEL_8280 Intel 8280 accera.Target.Model.INTEL_8280L Intel 8280L accera.Target.Model.INTEL_8280M Intel 8280M accera.Target.Model.INTEL_8284 Intel 8284 accera.Target.Model.INTEL_8300 Intel 8300 accera.Target.Model.INTEL_8300T Intel 8300T accera.Target.Model.INTEL_8350K Intel 8350K accera.Target.Model.INTEL_8351N Intel 8351N accera.Target.Model.INTEL_8352S Intel 8352S accera.Target.Model.INTEL_8352V Intel 8352V accera.Target.Model.INTEL_8352Y Intel 8352Y accera.Target.Model.INTEL_8358 Intel 8358 accera.Target.Model.INTEL_8358P Intel 8358P accera.Target.Model.INTEL_8360Y Intel 8360Y accera.Target.Model.INTEL_8362 Intel 8362 accera.Target.Model.INTEL_8368 Intel 8368 accera.Target.Model.INTEL_8368Q Intel 8368Q accera.Target.Model.INTEL_8380 Intel 8380 accera.Target.Model.INTEL_8400 Intel 8400 accera.Target.Model.INTEL_8400T Intel 8400T accera.Target.Model.INTEL_8500 Intel 8500 accera.Target.Model.INTEL_8500T Intel 8500T accera.Target.Model.INTEL_8550U Intel 8550U accera.Target.Model.INTEL_8600 Intel 8600 accera.Target.Model.INTEL_8600K Intel 8600K accera.Target.Model.INTEL_8600T Intel 8600T accera.Target.Model.INTEL_8650U Intel 8650U accera.Target.Model.INTEL_8700 Intel 8700 accera.Target.Model.INTEL_8700K Intel 8700K accera.Target.Model.INTEL_8700T Intel 8700T accera.Target.Model.INTEL_9221 Intel 9221 accera.Target.Model.INTEL_9222 Intel 9222 accera.Target.Model.INTEL_9242 Intel 9242 accera.Target.Model.INTEL_9282 Intel 9282 accera.Target.Model.INTEL_9800X Intel 9800X accera.Target.Model.INTEL_9820X Intel 9820X accera.Target.Model.INTEL_9900X Intel 9900X accera.Target.Model.INTEL_9920X Intel 9920X accera.Target.Model.INTEL_9940X Intel 9940X accera.Target.Model.INTEL_9960X Intel 9960X accera.Target.Model.INTEL_9980XE Intel 9980XE accera.Target.Model.INTEL_9990XE Intel 9990XE accera.Target.Model.INTEL_E3_1220_V6 Intel E3-1220 v6 accera.Target.Model.INTEL_E3_1225_V6 Intel E3-1225 v6 accera.Target.Model.INTEL_E3_1230_V6 Intel E3-1230 v6 accera.Target.Model.INTEL_E3_1240_V6 Intel E3-1240 v6 accera.Target.Model.INTEL_E3_1245_V6 Intel E3-1245 v6 accera.Target.Model.INTEL_E3_1270_V6 Intel E3-1270 v6 accera.Target.Model.INTEL_E3_1275_V6 Intel E3-1275 v6 accera.Target.Model.INTEL_E3_1280_V6 Intel E3-1280 v6 accera.Target.Model.INTEL_E3_1285_V6 Intel E3-1285 v6 accera.Target.Model.INTEL_E5_1607_V2 Intel E5-1607 v2 accera.Target.Model.INTEL_E5_1620_V2 Intel E5-1620 v2 accera.Target.Model.INTEL_E5_1650_V2 Intel E5-1650 v2 accera.Target.Model.INTEL_E5_1650_V3 Intel E5-1650 v3 accera.Target.Model.INTEL_E5_1660_V2 Intel E5-1660 v2 accera.Target.Model.INTEL_E5_1660_V3 Intel E5-1660 v3 accera.Target.Model.INTEL_E5_1680_V2 Intel E5-1680 v2 accera.Target.Model.INTEL_E5_1680_V3 Intel E5-1680 v3 accera.Target.Model.INTEL_G3900 Intel G3900 accera.Target.Model.INTEL_G3900T Intel G3900T accera.Target.Model.INTEL_G3900TE Intel G3900TE accera.Target.Model.INTEL_G3920 Intel G3920 accera.Target.Model.INTEL_G4400 Intel G4400 accera.Target.Model.INTEL_G4400T Intel G4400T accera.Target.Model.INTEL_G4400TE Intel G4400TE accera.Target.Model.INTEL_G4500 Intel G4500 accera.Target.Model.INTEL_G4500T Intel G4500T accera.Target.Model.INTEL_G4520 Intel G4520 accera.Target.Model.INTEL_W_1250 Intel W-1250 accera.Target.Model.INTEL_W_1250P Intel W-1250P accera.Target.Model.INTEL_W_1270 Intel W-1270 accera.Target.Model.INTEL_W_1270P Intel W-1270P accera.Target.Model.INTEL_W_1290 Intel W-1290 accera.Target.Model.INTEL_W_1290P Intel W-1290P accera.Target.Model.INTEL_W_1290T Intel W-1290T accera.Target.Model.INTEL_W_1350 Intel W-1350 accera.Target.Model.INTEL_W_1350P Intel W-1350P accera.Target.Model.INTEL_W_1370 Intel W-1370 accera.Target.Model.INTEL_W_1370P Intel W-1370P accera.Target.Model.INTEL_W_1390 Intel W-1390 accera.Target.Model.INTEL_W_1390P Intel W-1390P accera.Target.Model.INTEL_W_1390T Intel W-1390T accera.Target.Model.INTEL_W_2102 Intel W-2102 accera.Target.Model.INTEL_W_2104 Intel W-2104 accera.Target.Model.INTEL_W_2123 Intel W-2123 accera.Target.Model.INTEL_W_2125 Intel W-2125 accera.Target.Model.INTEL_W_2133 Intel W-2133 accera.Target.Model.INTEL_W_2135 Intel W-2135 accera.Target.Model.INTEL_W_2140B Intel W-2140B accera.Target.Model.INTEL_W_2150B Intel W-2150B accera.Target.Model.INTEL_W_3175X Intel W-3175X accera.Target.Model.INTEL_W_3223 Intel W-3223 accera.Target.Model.INTEL_W_3225 Intel W-3225 accera.Target.Model.INTEL_W_3235 Intel W-3235 accera.Target.Model.INTEL_W_3245 Intel W-3245 accera.Target.Model.INTEL_W_3245M Intel W-3245M accera.Target.Model.INTEL_W_3265 Intel W-3265 accera.Target.Model.INTEL_W_3265M Intel W-3265M accera.Target.Model.INTEL_W_3275 Intel W-3275 accera.Target.Model.INTEL_W_3275M Intel W-3275M accera.Target.Model.RASPBERRY_PI_3B Raspberry Pi 3B accera.Target.Model.RASPBERRY_PI_4B Raspberry Pi 4B accera.Target.Model.RASPBERRY_PI_ZERO Raspberry Pi Zero The enum also defines constants for some well-known GPU models. type description accera.Target.Model.AMD_MI100 AMD MI100 accera.Target.Model.AMD_MI200 AMD MI200 accera.Target.Model.AMD_MI50 AMD MI50 accera.Target.Model.AMD_RADEON7 AMD Radeon7 accera.Target.Model.NVIDIA_A100 NVidia A100 accera.Target.Model.NVIDIA_P100 NVidia P100 accera.Target.Model.NVIDIA_RTX_A6000 NVidia RTX A6000 accera.Target.Model.NVIDIA_V100 NVidia V100","title":"accera.Target.Model"},{"location":"Reference/classes/Target/Runtime/","text":"Accera v1.2.7 Reference accera.Target.Runtime The runtime for code generation and/or compilation. type description accera.Target.Runtime.CUDA The NVidia CUDA runtime. accera.Target.Runtime.ROCM The AMD ROCm runtime. accera.Target.Runtime.VULKAN The Vulkan runtime. accera.Target.Runtime.OPENMP The OpenMP runtime.","title":"Runtime"},{"location":"Reference/classes/Target/Runtime/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Target/Runtime/#acceratargetruntime","text":"The runtime for code generation and/or compilation. type description accera.Target.Runtime.CUDA The NVidia CUDA runtime. accera.Target.Runtime.ROCM The AMD ROCm runtime. accera.Target.Runtime.VULKAN The Vulkan runtime. accera.Target.Runtime.OPENMP The OpenMP runtime.","title":"accera.Target.Runtime"},{"location":"Reference/classes/Target/Target/","text":"Accera v1.2.7 Reference accera.Target([architecture, cache_lines, cache_sizes, category, extensions, family, frequency_GHz, known_name, model, name, num_cores, num_threads, runtime, tensor_core_info, turbo_frequency_GHz, vector_bytes, vector_registers) Defines the capabilities of a target processor. Arguments argument description type/default architecture The processor architecture accera.Target.Architecture cache_lines Cache lines (kilobytes) list of positive integers cache_sizes Cache sizes (bytes) list of positive integers category The processor category accera.Target.Category extensions Supported processor extensions list of extension codes family The processor family string frequency_GHz The processor frequency (GHz) positive number known_name A name of a device known to Accera string | accera.Target.Model / \"HOST\" model The processor model accera.Target.Model name The processor name string num_cores Number of cores positive integer num_threads Number of threads positive integer runtime The runtime accera.Target.Runtime tensor_core_info The tensor core capabilities, such as the supported input type, output type, and shapes accera.Targets.TensorCoreInformation turbo_frequency_GHz Turbo frequency (GHz) positive number vector_bytes Bytes per vector register positive number vector_registers total number of SIMD registers positive number Known device names Accera provides a pre-defined list of known targets through the accera.Target.Models enumeration. These known targets provide typical hardware settings and may not fit your specific hardware characteristics exactly. If your target matches closely with (but not exactly to) one of these targets, you can always start with a known target and update the properties accordingly. If your target is your host machine, Accera will first try to find your host machine's CPU in the list of known devices then use its corresponding capabilities. If none is found, we recommend that you inspect the closest matching device in accera.Target.Models enumeration in order to generate optimal code. If there is no closely matching device for you host machine, we suggest you to look at the following section to define a cpu target in Accera. Examples Let's have a look at some examples to understand how to define a CPU target in Accera. Create a custom CPU target: cpu_target = acc . Target ( name = \"Custom processor\" , category = acc . Target . Category . CPU , architecture = acc . Target . Architecture . X86_64 , num_cores = 10 ) We further create a known CPU target and can selectively override fields. gen10 = acc . Target ( known_name = \"Intel 7940X\" , category = acc . Target . Category . CPU , extensions = [ \"SSE4.1\" , \"SSE4.2\" , \"AVX2\" ]) In this example, we created a target device of a known CPU but overrode the extensions to remove AVX512 support. You can use this example as a starting point to define any other Intel Core Processor. Their specifications are listed in the table above. Craete a pre-defined GPU target representing an NVidia Tesla v100 processor: v100 = acc . Target ( model = acc . Target . Model . NVIDIA_TESLA_V100 ) Here is another example to create a custom GPU target: gpu_target = acc . Target ( name = \"Custom GPU processor\" , category = acc . Target . Category . GPU , default_block_size = 16 ) Additional Notes on Instruction Set Extensions It is important to identify the number of vector registers and vector bytes of each SIMD register. These values may help you determine if you are leveraging the vector units of the underlying hardware to its best capabilities. AVX Advanced Vector Extensions (AVX) promotes legacy 128-bit SIMD instructions that operate on XMM registers to use a vector-extension (VEX) prefix and operate on 256-bit YMM registers. Intel AVX introduced support for 256-bit wide SIMD registers (YMM0-YMM7 in operating modes that are 32-bit or less, YMM0-YMM15 in 64-bit mode). For Accera, 64-bit mode is the default. a target. The lower 128-bits of the YMM registers are aliased to the respective 128-bit XMM registers. In Intel AVX, there are 256-bit wide vector registers, 16 XMM registers, and 16 YMM registers to support an extension of 128-bits. AVX512 AVX-512 is a further extension offering 32 ZMM registers, and each SIMD register is 512 bits (64 bytes) wide. SSE4 Extension There are 16 XMM registers (XMM0 to XMM15), each 128-bit wide. In 64-bit mode, eight additional XMM registers are accessible. Registers XMM8-XMM15 are accessed by using REX prefixes.","title":"Target"},{"location":"Reference/classes/Target/Target/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/classes/Target/Target/#acceratargetarchitecture-cache_lines-cache_sizes-category-extensions-family-frequency_ghz-known_name-model-name-num_cores-num_threads-runtime-tensor_core_info-turbo_frequency_ghz-vector_bytes-vector_registers","text":"Defines the capabilities of a target processor.","title":"accera.Target([architecture, cache_lines, cache_sizes, category, extensions, family, frequency_GHz, known_name, model, name, num_cores, num_threads, runtime, tensor_core_info, turbo_frequency_GHz, vector_bytes, vector_registers)"},{"location":"Reference/classes/Target/Target/#arguments","text":"argument description type/default architecture The processor architecture accera.Target.Architecture cache_lines Cache lines (kilobytes) list of positive integers cache_sizes Cache sizes (bytes) list of positive integers category The processor category accera.Target.Category extensions Supported processor extensions list of extension codes family The processor family string frequency_GHz The processor frequency (GHz) positive number known_name A name of a device known to Accera string | accera.Target.Model / \"HOST\" model The processor model accera.Target.Model name The processor name string num_cores Number of cores positive integer num_threads Number of threads positive integer runtime The runtime accera.Target.Runtime tensor_core_info The tensor core capabilities, such as the supported input type, output type, and shapes accera.Targets.TensorCoreInformation turbo_frequency_GHz Turbo frequency (GHz) positive number vector_bytes Bytes per vector register positive number vector_registers total number of SIMD registers positive number","title":"Arguments"},{"location":"Reference/classes/Target/Target/#known-device-names","text":"Accera provides a pre-defined list of known targets through the accera.Target.Models enumeration. These known targets provide typical hardware settings and may not fit your specific hardware characteristics exactly. If your target matches closely with (but not exactly to) one of these targets, you can always start with a known target and update the properties accordingly. If your target is your host machine, Accera will first try to find your host machine's CPU in the list of known devices then use its corresponding capabilities. If none is found, we recommend that you inspect the closest matching device in accera.Target.Models enumeration in order to generate optimal code. If there is no closely matching device for you host machine, we suggest you to look at the following section to define a cpu target in Accera.","title":"Known device names"},{"location":"Reference/classes/Target/Target/#examples","text":"Let's have a look at some examples to understand how to define a CPU target in Accera. Create a custom CPU target: cpu_target = acc . Target ( name = \"Custom processor\" , category = acc . Target . Category . CPU , architecture = acc . Target . Architecture . X86_64 , num_cores = 10 ) We further create a known CPU target and can selectively override fields. gen10 = acc . Target ( known_name = \"Intel 7940X\" , category = acc . Target . Category . CPU , extensions = [ \"SSE4.1\" , \"SSE4.2\" , \"AVX2\" ]) In this example, we created a target device of a known CPU but overrode the extensions to remove AVX512 support. You can use this example as a starting point to define any other Intel Core Processor. Their specifications are listed in the table above. Craete a pre-defined GPU target representing an NVidia Tesla v100 processor: v100 = acc . Target ( model = acc . Target . Model . NVIDIA_TESLA_V100 ) Here is another example to create a custom GPU target: gpu_target = acc . Target ( name = \"Custom GPU processor\" , category = acc . Target . Category . GPU , default_block_size = 16 )","title":"Examples"},{"location":"Reference/classes/Target/Target/#additional-notes-on-instruction-set-extensions","text":"It is important to identify the number of vector registers and vector bytes of each SIMD register. These values may help you determine if you are leveraging the vector units of the underlying hardware to its best capabilities.","title":"Additional Notes on Instruction Set Extensions"},{"location":"Reference/classes/Target/Target/#avx","text":"Advanced Vector Extensions (AVX) promotes legacy 128-bit SIMD instructions that operate on XMM registers to use a vector-extension (VEX) prefix and operate on 256-bit YMM registers. Intel AVX introduced support for 256-bit wide SIMD registers (YMM0-YMM7 in operating modes that are 32-bit or less, YMM0-YMM15 in 64-bit mode). For Accera, 64-bit mode is the default. a target. The lower 128-bits of the YMM registers are aliased to the respective 128-bit XMM registers. In Intel AVX, there are 256-bit wide vector registers, 16 XMM registers, and 16 YMM registers to support an extension of 128-bits.","title":"AVX"},{"location":"Reference/classes/Target/Target/#avx512","text":"AVX-512 is a further extension offering 32 ZMM registers, and each SIMD register is 512 bits (64 bytes) wide.","title":"AVX512"},{"location":"Reference/classes/Target/Target/#sse4-extension","text":"There are 16 XMM registers (XMM0 to XMM15), each 128-bit wide. In 64-bit mode, eight additional XMM registers are accessible. Registers XMM8-XMM15 are accessed by using REX prefixes.","title":"SSE4 Extension"},{"location":"Reference/enumerations/MMASchedulingPolicy/","text":"Accera v1.2.7 Reference accera.MMASchedulingPolicy type description accera.MMASchedulingPolicy.PASS_ORDER Process pass groups (fused passed) sequentially, within each pass group compute all the MFMA blocks. This allocates Accmulator registers required for all the blocks, however it only allocates input (A, B) registers which are only required for the current pass group. accera.MMASchedulingPolicy.BLOCK_ORDER Process MFMA blocks sequentially, for each block iterate over all the passes. This allocates Accumulator registers required for only 1 block and input (A, B) registers required for the entire pass group currently being processed. In this mode, input data for the same pass group is loaded into registers multiple times, once per block.","title":"MMASchedulingPolicy"},{"location":"Reference/enumerations/MMASchedulingPolicy/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/enumerations/MMASchedulingPolicy/#accerammaschedulingpolicy","text":"type description accera.MMASchedulingPolicy.PASS_ORDER Process pass groups (fused passed) sequentially, within each pass group compute all the MFMA blocks. This allocates Accmulator registers required for all the blocks, however it only allocates input (A, B) registers which are only required for the current pass group. accera.MMASchedulingPolicy.BLOCK_ORDER Process MFMA blocks sequentially, for each block iterate over all the passes. This allocates Accumulator registers required for only 1 block and input (A, B) registers required for the entire pass group currently being processed. In this mode, input data for the same pass group is loaded into registers multiple times, once per block.","title":"accera.MMASchedulingPolicy"},{"location":"Reference/enumerations/MMAShape/","text":"Accera v1.2.7 Reference accera.MMAShape The following table shows the matrix multiplication parameters associated with the different enum values, for different data types for a single pass. So for example a single pass of the M32xN32xK2_B1 operation would take input matrices of dimensions [32x2] (A) and [2x32] (B) to produce a matrix multiplication result of dimensions [32x32] (C). These operations can then be composed together to perform matrix multiplication of larger matrices. More information about the corresponding Matrix Arithmetic Instructions (MAI) can be found here . table, td { border: 1px solid black; } th { border: 2px solid black; background-color:grey; } Supported MMA shapes and their compatible types for AMD targets accera.MMAShape MFMA Instruction M, N, K Input Type (ScalarType) Output Type (ScalarType) Compute Type (C++) M64xN64xK1_B4 V_MFMA_F32_16x16x1F32 64, 64, 1 float32 float32 float M64xN64xK1_B2 V_MFMA_F32_32x32x1F32 M32xN32xK2_B1 V_MFMA_F32_32x32x2F32 32, 32, 2 M16xN16xK4_B1 V_MFMA_F32_16x16x4F32 16, 16, 4 M64xN64xK2_B4 V_MFMA_F32_16X16X2BF16 64, 64, 2 bfloat16 bfloat16/float32 M64xN64xK2_B2 V_MFMA_F32_32X32X2BF16 bfloat16/float32 M32xN32xK4_B1 V_MFMA_F32_32X32X4BF16 32, 32, 4 bfloat16/float32 M16xN16xK8_B1 V_MFMA_F32_16X16X8BF16 16, 16, 8 bfloat16/float32 M64xN64xK4_B4 V_MFMA_F32_16x16x4F16 64, 64, 4 float16 float16/32 V_MFMA_I32_16X16X4I8 int8 int8/16/32 int M64xN64xK4_B2 V_MFMA_F32_32x32x4F16 float16 float16/32 float V_MFMA_I32_32X32X4I8 int8 int8/16/32 int M32xN32xK8_B1 V_MFMA_F32_32x32x8F16 32, 32, 8 float16 float16/32 float V_MFMA_I32_32X32X8I8 int8 int8/16/32 int M16xN16xK16_B1 V_MFMA_F32_16x16x16F16 16, 16, 16 float16 float16/32 float V_MFMA_I32_16X16X16I8 int8 int8/16/32 int Supported MMA shapes and their compatible types for Nvidia targets accera.MMAShape M, N, K Input Type (ScalarType) Output Type (ScalarType) Compute Type (C++) M16xN16xK16_B1 16, 16, 16 float16 float16/32 float M32xN8xK16_B1 32, 8, 16 float16/32 M8xN32xK16_B1 8, 32, 16 float16/32","title":"MMAShape"},{"location":"Reference/enumerations/MMAShape/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/enumerations/MMAShape/#accerammashape","text":"The following table shows the matrix multiplication parameters associated with the different enum values, for different data types for a single pass. So for example a single pass of the M32xN32xK2_B1 operation would take input matrices of dimensions [32x2] (A) and [2x32] (B) to produce a matrix multiplication result of dimensions [32x32] (C). These operations can then be composed together to perform matrix multiplication of larger matrices. More information about the corresponding Matrix Arithmetic Instructions (MAI) can be found here . table, td { border: 1px solid black; } th { border: 2px solid black; background-color:grey; } Supported MMA shapes and their compatible types for AMD targets accera.MMAShape MFMA Instruction M, N, K Input Type (ScalarType) Output Type (ScalarType) Compute Type (C++) M64xN64xK1_B4 V_MFMA_F32_16x16x1F32 64, 64, 1 float32 float32 float M64xN64xK1_B2 V_MFMA_F32_32x32x1F32 M32xN32xK2_B1 V_MFMA_F32_32x32x2F32 32, 32, 2 M16xN16xK4_B1 V_MFMA_F32_16x16x4F32 16, 16, 4 M64xN64xK2_B4 V_MFMA_F32_16X16X2BF16 64, 64, 2 bfloat16 bfloat16/float32 M64xN64xK2_B2 V_MFMA_F32_32X32X2BF16 bfloat16/float32 M32xN32xK4_B1 V_MFMA_F32_32X32X4BF16 32, 32, 4 bfloat16/float32 M16xN16xK8_B1 V_MFMA_F32_16X16X8BF16 16, 16, 8 bfloat16/float32 M64xN64xK4_B4 V_MFMA_F32_16x16x4F16 64, 64, 4 float16 float16/32 V_MFMA_I32_16X16X4I8 int8 int8/16/32 int M64xN64xK4_B2 V_MFMA_F32_32x32x4F16 float16 float16/32 float V_MFMA_I32_32X32X4I8 int8 int8/16/32 int M32xN32xK8_B1 V_MFMA_F32_32x32x8F16 32, 32, 8 float16 float16/32 float V_MFMA_I32_32X32X8I8 int8 int8/16/32 int M16xN16xK16_B1 V_MFMA_F32_16x16x16F16 16, 16, 16 float16 float16/32 float V_MFMA_I32_16X16X16I8 int8 int8/16/32 int Supported MMA shapes and their compatible types for Nvidia targets accera.MMAShape M, N, K Input Type (ScalarType) Output Type (ScalarType) Compute Type (C++) M16xN16xK16_B1 16, 16, 16 float16 float16/32 float M32xN8xK16_B1 32, 8, 16 float16/32 M8xN32xK16_B1 8, 32, 16 float16/32","title":"accera.MMAShape"},{"location":"Reference/enumerations/ScalarType/","text":"Accera v1.2.7 Reference accera.ScalarType type description accera.ScalarType.bool boolean accera.ScalarType.float16 16-bit floating point number accera.ScalarType.float32 32-bit floating point number accera.ScalarType.float64 64-bit floating point number accera.ScalarType.bfloat16 16-bit Brain floating point number accera.ScalarType.int8 8-bit signed integer accera.ScalarType.int16 16-bit signed integer accera.ScalarType.int32 32-bit signed integer accera.ScalarType.int64 64-bit signed integer accera.ScalarType.uint8 8-bit unsigned integer accera.ScalarType.uint16 16-bit unsigned integer accera.ScalarType.uint32 32-bit unsigned integer accera.ScalarType.uint64 64-bit unsigned integer","title":"ScalarType"},{"location":"Reference/enumerations/ScalarType/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/enumerations/ScalarType/#accerascalartype","text":"type description accera.ScalarType.bool boolean accera.ScalarType.float16 16-bit floating point number accera.ScalarType.float32 32-bit floating point number accera.ScalarType.float64 64-bit floating point number accera.ScalarType.bfloat16 16-bit Brain floating point number accera.ScalarType.int8 8-bit signed integer accera.ScalarType.int16 16-bit signed integer accera.ScalarType.int32 32-bit signed integer accera.ScalarType.int64 64-bit signed integer accera.ScalarType.uint8 8-bit unsigned integer accera.ScalarType.uint16 16-bit unsigned integer accera.ScalarType.uint32 32-bit unsigned integer accera.ScalarType.uint64 64-bit unsigned integer","title":"accera.ScalarType"},{"location":"Reference/functions/cast/","text":"Accera v1.2.7 Reference accera.cast(value, type) The cast operation converts a value from one acc.ScalarType to another. Accera performs implicit casting between most types. Therefore, this operation should only be used to override the implicit casting behavior documented in Section 2 . Limitation: casting constants may result in truncation. Arguments argument description type/default value The value to cast type The destination type acc.ScalarType Returns The result after casting Examples Casting from float32 to int16: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) B = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . int16 , shape = ( 10 , 20 )) nest = acc . Nest ( 10 , 20 ) i , j = nest . get_indices () @nest . iteration_logic : def _ (): B [ i , j ] = acc . cast ( A [ i , j ], acc . ScalarType . int16 ) # explicit cast to int16 ... In comparison, casting from int16 to float32 is implicit, which means the cast operation can be omitted: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . int16 , shape = ( 10 , 20 )) B = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) nest = acc . Nest ( 10 , 20 ) i , j = nest . get_indices () @nest . iteration_logic : def _ (): B [ i , j ] = A [ i , j ] # implicit cast to float32 ... Casting a constant to int8: A = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . int8 , shape = ( 10 , 20 )) nest = acc . Nest ( 10 , 20 ) i , j = nest . get_indices () @nest . iteration_logic : def _ (): A [ i , j ] = acc . cast ( 10 , acc . ScalarType . int8 ) ...","title":"Cast"},{"location":"Reference/functions/cast/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/functions/cast/#acceracastvalue-type","text":"The cast operation converts a value from one acc.ScalarType to another. Accera performs implicit casting between most types. Therefore, this operation should only be used to override the implicit casting behavior documented in Section 2 . Limitation: casting constants may result in truncation.","title":"accera.cast(value, type)"},{"location":"Reference/functions/cast/#arguments","text":"argument description type/default value The value to cast type The destination type acc.ScalarType","title":"Arguments"},{"location":"Reference/functions/cast/#returns","text":"The result after casting","title":"Returns"},{"location":"Reference/functions/cast/#examples","text":"Casting from float32 to int16: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) B = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . int16 , shape = ( 10 , 20 )) nest = acc . Nest ( 10 , 20 ) i , j = nest . get_indices () @nest . iteration_logic : def _ (): B [ i , j ] = acc . cast ( A [ i , j ], acc . ScalarType . int16 ) # explicit cast to int16 ... In comparison, casting from int16 to float32 is implicit, which means the cast operation can be omitted: A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . int16 , shape = ( 10 , 20 )) B = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( 10 , 20 )) nest = acc . Nest ( 10 , 20 ) i , j = nest . get_indices () @nest . iteration_logic : def _ (): B [ i , j ] = A [ i , j ] # implicit cast to float32 ... Casting a constant to int8: A = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . int8 , shape = ( 10 , 20 )) nest = acc . Nest ( 10 , 20 ) i , j = nest . get_indices () @nest . iteration_logic : def _ (): A [ i , j ] = acc . cast ( 10 , acc . ScalarType . int8 ) ...","title":"Examples"},{"location":"Reference/functions/create_parameter_grid/","text":"Accera v1.2.7 Reference accera.create_parameter_grid(parameter_choices, filter_func, sample, seed) Create a parameter grid from a dictionary that maps each parameter to its possible values. Arguments argument description type/default parameter_choices A dictionary that maps each parameter to its possible values dictionary filter_func A callable to filter parameter_choices which returns a bool to indicate whether a given parameter combination should be included in the grid Callable sample A number to limit the size of the parameter grid. The grid is randomly sampled. integer seed The seed value for random sampling. integer Returns List of dictionary Examples Create a parameter grid from a dictionary that maps each parameter to its possible values: parameters = acc . create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}) package . add ( nest , args = ( A , B , C ), base_name = \"matmul\" , parameters ) Define a lambda or function to filter out combinations from the parameter grid. The arguments to the filter are the values of a parameter combination. The filter function should return True if the combination should be included, and False otherwise: parameters = acc . create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, filter_func = lambda p0 , p1 , p2 , p3 : p2 < p1 and 4 * ( p0 * p3 + p1 * p2 + p1 * p3 + p2 * p3 ) / 1024 < 256 ) Parameter grids can result in a large number of possible combinations. We can limit the number of combinations by random sampling: parameters = acc . create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, sample = 5 )","title":"Create parameter grid"},{"location":"Reference/functions/create_parameter_grid/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/functions/create_parameter_grid/#acceracreate_parameter_gridparameter_choices-filter_func-sample-seed","text":"Create a parameter grid from a dictionary that maps each parameter to its possible values.","title":"accera.create_parameter_grid(parameter_choices, filter_func, sample, seed)"},{"location":"Reference/functions/create_parameter_grid/#arguments","text":"argument description type/default parameter_choices A dictionary that maps each parameter to its possible values dictionary filter_func A callable to filter parameter_choices which returns a bool to indicate whether a given parameter combination should be included in the grid Callable sample A number to limit the size of the parameter grid. The grid is randomly sampled. integer seed The seed value for random sampling. integer","title":"Arguments"},{"location":"Reference/functions/create_parameter_grid/#returns","text":"List of dictionary","title":"Returns"},{"location":"Reference/functions/create_parameter_grid/#examples","text":"Create a parameter grid from a dictionary that maps each parameter to its possible values: parameters = acc . create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}) package . add ( nest , args = ( A , B , C ), base_name = \"matmul\" , parameters ) Define a lambda or function to filter out combinations from the parameter grid. The arguments to the filter are the values of a parameter combination. The filter function should return True if the combination should be included, and False otherwise: parameters = acc . create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, filter_func = lambda p0 , p1 , p2 , p3 : p2 < p1 and 4 * ( p0 * p3 + p1 * p2 + p1 * p3 + p2 * p3 ) / 1024 < 256 ) Parameter grids can result in a large number of possible combinations. We can limit the number of combinations by random sampling: parameters = acc . create_parameter_grid ( parameter_choices = { P0 :[ 8 , 16 ], P1 :[ 16 , 32 ], P2 :[ 16 ], P3 :[ 1.0 , 2.0 ]}, sample = 5 )","title":"Examples"},{"location":"Reference/functions/create_parameters/","text":"Accera v1.2.7 Reference accera.create_parameters() Creates placeholder parameters. Returns Tuple of Parameter Examples Create 3 parameters m , n , k . Use them to parameterize the nest shape: m , n , k = acc . create_parameters () nest = acc . Nest ( shape = ( m , n , k ))","title":"Create parameters"},{"location":"Reference/functions/create_parameters/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/functions/create_parameters/#acceracreate_parameters","text":"Creates placeholder parameters.","title":"accera.create_parameters()"},{"location":"Reference/functions/create_parameters/#returns","text":"Tuple of Parameter","title":"Returns"},{"location":"Reference/functions/create_parameters/#examples","text":"Create 3 parameters m , n , k . Use them to parameterize the nest shape: m , n , k = acc . create_parameters () nest = acc . Nest ( shape = ( m , n , k ))","title":"Examples"},{"location":"Reference/functions/fuse/","text":"Accera v1.2.7 Reference accera.fuse(schedules[, *args, partial]) The fuse operation combines multiple iteration spaces into a single \"fused\" iteration space. The fused iteration space represents the union of the work in the original spaces. In cases where it doesn't make sense to fuse all of the iteration space dimensions, we can choose to fuse a prefix of the dimensions and leave the rest unfused. Arguments argument description type/default schedules If performing partial fusing, this is a tuple of the schedules to fuse. If performing full fusing, this contains the first schedule to fuse, while args will contain the subsequent schedules. *args Optional variable arguments containing subsequent schedules to fuse variable Schedule arguments partial The number of dimensions to fuse. If not specified, all dimensions will be fused non-negative integer Returns The fused Schedule Examples Full fusing of same-shaped iteration spaces: # Fuse all dimensions of schedule0 and schedule1 schedule = acc . fuse ( schedule0 , schedule1 ) f , i , j = schedule . get_indices () # Reorder the indices so that the fused dimension is the innermost schedule . reorder ( i , j , f ) Partial iteration space fusing: # Fuse the first two dimensions of schedule0 and schedule1 schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k = schedule . get_indices () # Reorder the indices to interleave the schedules schedule . reorder ( i , j , f , k )","title":"Fuse"},{"location":"Reference/functions/fuse/#accera-v127-reference","text":"","title":"Accera v1.2.7 Reference"},{"location":"Reference/functions/fuse/#accerafuseschedules-args-partial","text":"The fuse operation combines multiple iteration spaces into a single \"fused\" iteration space. The fused iteration space represents the union of the work in the original spaces. In cases where it doesn't make sense to fuse all of the iteration space dimensions, we can choose to fuse a prefix of the dimensions and leave the rest unfused.","title":"accera.fuse(schedules[, *args, partial])"},{"location":"Reference/functions/fuse/#arguments","text":"argument description type/default schedules If performing partial fusing, this is a tuple of the schedules to fuse. If performing full fusing, this contains the first schedule to fuse, while args will contain the subsequent schedules. *args Optional variable arguments containing subsequent schedules to fuse variable Schedule arguments partial The number of dimensions to fuse. If not specified, all dimensions will be fused non-negative integer","title":"Arguments"},{"location":"Reference/functions/fuse/#returns","text":"The fused Schedule","title":"Returns"},{"location":"Reference/functions/fuse/#examples","text":"Full fusing of same-shaped iteration spaces: # Fuse all dimensions of schedule0 and schedule1 schedule = acc . fuse ( schedule0 , schedule1 ) f , i , j = schedule . get_indices () # Reorder the indices so that the fused dimension is the innermost schedule . reorder ( i , j , f ) Partial iteration space fusing: # Fuse the first two dimensions of schedule0 and schedule1 schedule = acc . fuse (( schedule0 , schedule1 ), partial = 2 ) f , i , j , k = schedule . get_indices () # Reorder the indices to interleave the schedules schedule . reorder ( i , j , f , k )","title":"Examples"},{"location":"Tutorials/","text":"Accera Tutorials Tutorial Description Hello Matrix Multiplication Start here if you are completely new to Accera and would like to learn more about the workflow Optimized Matrix Multiplication Once you understand the basics, we'll look at how to optimize matrix multiplication for a specific hardware target Hello Matrix Multiplication on GPU We'll look at how to apply the basic concepts for GPU targets Cross Compilation for Raspberry Pi 3 After you know how to generate code for the host target, we'll look at how to generate code for other targets","title":"Index"},{"location":"Tutorials/#accera-tutorials","text":"Tutorial Description Hello Matrix Multiplication Start here if you are completely new to Accera and would like to learn more about the workflow Optimized Matrix Multiplication Once you understand the basics, we'll look at how to optimize matrix multiplication for a specific hardware target Hello Matrix Multiplication on GPU We'll look at how to apply the basic concepts for GPU targets Cross Compilation for Raspberry Pi 3 After you know how to generate code for the host target, we'll look at how to generate code for other targets","title":"Accera Tutorials"},{"location":"Tutorials/Hello_MatMul/","text":"Hello MatMul By the end of this tutorial, you will learn how to: Implement a simple Matrix Multiplication (MatMul) function using Accera's Domain Specific Language (DSL) Produce a HAT package containing the MatMul function Call the function from C or C++ code Prerequisites This tutorial assumes you already have Accera installed. If not, you can find the instructions in here You should also be familiar with writing Python and C++ A naive MatMul algorithm Let's consider the example of multiplying matrices A and B, and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for loops. Expressed in Python, this could like: # A.shape = (M, K), B.shape = (K, N), C.shape = (M, N) for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j] Accera Python DSL We will now walk through a naive Matrix Multiplication (MatMul) using Accera. Create an empty file called hello_matmul_generator.py . First we'll import Accera's module. import accera as acc Define some matrix sizes. A will be M by K, B will be K by N, and C will be M by N. # Define our matrix sizes M = 128 N = 256 K = 256 Write a Python function that receives arrays A , B and C . These are our input and input/output matrices. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) Here, we will use the Nest class to define our 3-layered nested for loop. The range indices are M , N , and K , with the outermost loop ( M ) listed first. We can get the loop nest indices in order to perform the computation. # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next we define the logic of each iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul, and let's define the schedule which controls how the logic is executed. To do this, we first create the schedule from the nest: sched = nest . create_schedule () At this point, sched represents the default schedule for our algorithm. We can also perform some basic transformations on this schedule. For example, the following lines of code will split the k index in blocks of 4 (so k , k+4 , k+8 , and so on). # Split the k loop into blocks of 4, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # # Split k into two loops # for k in range(0, K, 4): # for kk in range(4): # C[i, j] += A[i, k + kk] * B[k + kk, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. kk = sched . split ( k , 4 ) The split index is now k and kk . The next step is to create a plan from the schedule. For instance, we can use this plan to unroll the innermost loop. plan = sched . create_plan () # Unroll kk, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # for k in range(0, K, 4): # # Unrolled kk # C[i, j] += A[i, k + 0] * B[k + 0, j] # C[i, j] += A[i, k + 1] * B[k + 1, j] # C[i, j] += A[i, k + 2] * B[k + 2, j] # C[i, j] += A[i, k + 3] * B[k + 3, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. plan . unroll ( kk ) Use the plan to add a callable function named hello_matmul_pi3_py to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"hello_matmul_py\" ) Finally, we build the HAT package: # Build the HAT package package . build ( name = \"hello_matmul\" ) By now, you should have all the code necessary to generate your first Accera MatMul function. You can also find the complete Python script here . Generate HAT package Next, we run the generator script to produce a HAT package. Windows/MacOS python hello_matmul_generator.py Ubuntu python3 hello_matmul_generator.py After this runs, you should see a header file hello_matmul.hat and some object files (such as hello_matmul.obj or hello_matmul.o ). The .hat file format is described here . In Accera, we call these files the \"HAT package\". Runner code We will now walk through how to call our MatMul implementation from the HAT package. Create a file called hello_matmul_runner.cpp with the code below. You can also find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares our MatMul function #include \"hello_matmul.hat\" #define M 128 #define N 256 #define K 256 int main ( int argc , const char ** argv ) { // Prepare our matrices float A [ M * K ]; float B [ K * N ]; float C [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); hello_matmul_py ( A , B , C ); printf ( \"Result (first few elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); return 0 ; } The code above creates the A , B , and C matrices, and calls the function hello_matmul_py to perform MatMul. Now that we have written the code, we will compile and link it with the HAT package to create an executable. Save the file to your working directory, in the same location as hello_matmul_generator.py and the generated *.hat and object files. Build and run Windows We will need the 64-bit Visual C++ tools to link against the generated 64-bit .obj. From an \"x64 Native Tools Command Prompt\" : cl.exe hello_matmul_runner.cpp *.lib hello_matmul_runner.exe MacOS clang hello_matmul_runner.cpp *.a -o hello_matmul_runner ./hello_matmul_runner Ubuntu gcc hello_matmul_runner.cpp *.a -o hello_matmul_runner ./hello_matmul_runner The output should look like: Calling MatMul M=128, K=256, N=256 Result (first few elements): 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 You can now experiment with the generated MatMul function with your own inputs. Optimized MatMul algorithm The above example illustrates a naive algorithm. To see what a more optimized version could like like, see the Optimized MatMul tutorial.","title":"Hello MatMul"},{"location":"Tutorials/Hello_MatMul/#hello-matmul","text":"By the end of this tutorial, you will learn how to: Implement a simple Matrix Multiplication (MatMul) function using Accera's Domain Specific Language (DSL) Produce a HAT package containing the MatMul function Call the function from C or C++ code","title":"Hello MatMul"},{"location":"Tutorials/Hello_MatMul/#prerequisites","text":"This tutorial assumes you already have Accera installed. If not, you can find the instructions in here You should also be familiar with writing Python and C++","title":"Prerequisites"},{"location":"Tutorials/Hello_MatMul/#a-naive-matmul-algorithm","text":"Let's consider the example of multiplying matrices A and B, and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for loops. Expressed in Python, this could like: # A.shape = (M, K), B.shape = (K, N), C.shape = (M, N) for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j]","title":"A naive MatMul algorithm"},{"location":"Tutorials/Hello_MatMul/#accera-python-dsl","text":"We will now walk through a naive Matrix Multiplication (MatMul) using Accera. Create an empty file called hello_matmul_generator.py . First we'll import Accera's module. import accera as acc Define some matrix sizes. A will be M by K, B will be K by N, and C will be M by N. # Define our matrix sizes M = 128 N = 256 K = 256 Write a Python function that receives arrays A , B and C . These are our input and input/output matrices. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) Here, we will use the Nest class to define our 3-layered nested for loop. The range indices are M , N , and K , with the outermost loop ( M ) listed first. We can get the loop nest indices in order to perform the computation. # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next we define the logic of each iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul, and let's define the schedule which controls how the logic is executed. To do this, we first create the schedule from the nest: sched = nest . create_schedule () At this point, sched represents the default schedule for our algorithm. We can also perform some basic transformations on this schedule. For example, the following lines of code will split the k index in blocks of 4 (so k , k+4 , k+8 , and so on). # Split the k loop into blocks of 4, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # # Split k into two loops # for k in range(0, K, 4): # for kk in range(4): # C[i, j] += A[i, k + kk] * B[k + kk, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. kk = sched . split ( k , 4 ) The split index is now k and kk . The next step is to create a plan from the schedule. For instance, we can use this plan to unroll the innermost loop. plan = sched . create_plan () # Unroll kk, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # for k in range(0, K, 4): # # Unrolled kk # C[i, j] += A[i, k + 0] * B[k + 0, j] # C[i, j] += A[i, k + 1] * B[k + 1, j] # C[i, j] += A[i, k + 2] * B[k + 2, j] # C[i, j] += A[i, k + 3] * B[k + 3, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. plan . unroll ( kk ) Use the plan to add a callable function named hello_matmul_pi3_py to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"hello_matmul_py\" ) Finally, we build the HAT package: # Build the HAT package package . build ( name = \"hello_matmul\" ) By now, you should have all the code necessary to generate your first Accera MatMul function. You can also find the complete Python script here .","title":"Accera Python DSL"},{"location":"Tutorials/Hello_MatMul/#generate-hat-package","text":"Next, we run the generator script to produce a HAT package.","title":"Generate HAT package"},{"location":"Tutorials/Hello_MatMul/#windowsmacos","text":"python hello_matmul_generator.py","title":"Windows/MacOS"},{"location":"Tutorials/Hello_MatMul/#ubuntu","text":"python3 hello_matmul_generator.py After this runs, you should see a header file hello_matmul.hat and some object files (such as hello_matmul.obj or hello_matmul.o ). The .hat file format is described here . In Accera, we call these files the \"HAT package\".","title":"Ubuntu"},{"location":"Tutorials/Hello_MatMul/#runner-code","text":"We will now walk through how to call our MatMul implementation from the HAT package. Create a file called hello_matmul_runner.cpp with the code below. You can also find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares our MatMul function #include \"hello_matmul.hat\" #define M 128 #define N 256 #define K 256 int main ( int argc , const char ** argv ) { // Prepare our matrices float A [ M * K ]; float B [ K * N ]; float C [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); hello_matmul_py ( A , B , C ); printf ( \"Result (first few elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); return 0 ; } The code above creates the A , B , and C matrices, and calls the function hello_matmul_py to perform MatMul. Now that we have written the code, we will compile and link it with the HAT package to create an executable. Save the file to your working directory, in the same location as hello_matmul_generator.py and the generated *.hat and object files.","title":"Runner code"},{"location":"Tutorials/Hello_MatMul/#build-and-run","text":"","title":"Build and run"},{"location":"Tutorials/Hello_MatMul/#windows","text":"We will need the 64-bit Visual C++ tools to link against the generated 64-bit .obj. From an \"x64 Native Tools Command Prompt\" : cl.exe hello_matmul_runner.cpp *.lib hello_matmul_runner.exe","title":"Windows"},{"location":"Tutorials/Hello_MatMul/#macos","text":"clang hello_matmul_runner.cpp *.a -o hello_matmul_runner ./hello_matmul_runner","title":"MacOS"},{"location":"Tutorials/Hello_MatMul/#ubuntu_1","text":"gcc hello_matmul_runner.cpp *.a -o hello_matmul_runner ./hello_matmul_runner The output should look like: Calling MatMul M=128, K=256, N=256 Result (first few elements): 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 You can now experiment with the generated MatMul function with your own inputs.","title":"Ubuntu"},{"location":"Tutorials/Hello_MatMul/#optimized-matmul-algorithm","text":"The above example illustrates a naive algorithm. To see what a more optimized version could like like, see the Optimized MatMul tutorial.","title":"Optimized MatMul algorithm"},{"location":"Tutorials/Hello_MatMul_GPU/","text":"Hello MatMul GPU In this tutorial, you will learn how to implement a simple Matrix Multiplication (MatMul) function for execution on a GPU. We will use the Accera's Domain Specific Language (DSL) to produce a HAT package containing the MatMul function that can be called from the host to launch the MatMul function on the GPU. Prerequisites You should have Accera installed. If not, you can find the instructions in here . Be familiar with writing Python and C++ code. Be familiar with basic GPU programming and concepts. You have completed the Hello_MatMul tutorial. You have installed the Vulkan SDK and runtime . Review: the naive MatMul algorithm As in the Hello_MatMul tutorial, we'll consider the example of multiplying matrices A and B and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for-loops. Expressed in Python, this can look like: for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j] Accera Python DSL We will now walk through a basic Matrix Multiplication (MatMul) using Accera. Additionally, we will direct Accera to execute this MatMul function on the default GPU. Create an empty file called hello_matmul_gpu_generator.py . Import dependent modules: import accera as acc Define some matrix sizes, where A's shape is M by K, B's is K by N, and C's, M by N. # Define our matrix sizes M = 1024 N = 512 K = 256 Declare arrays A , B , and C . These are our input and input/output matrices and hold 32-bit floating-point elements. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) Use the Nest class to define our 3-layered nested for-loop and get the indices: # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next, we define the logic for every iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul. Notice how, up to this point, it is identical to what we did for the CPU example . Let's now define the schedule to control the execution logic. To do this, we first create the schedule from the nest: schedule = nest . create_schedule () We will transform the iteration space and change the plan according to some predefined constants to execute this efficiently on our chosen hardware target. The values of these constants can come either from hardware target characteristics and the shapes of the arrays or can be found through auto-tuning. These will be explained in detail in a subsequent tutorial. For now, define: block_x = 16 block_y = 16 Transform the iteration space to specify the thread block behavior. See (GPU blocks)[TODO:markdown...] section to learning more about optimizing block sizes on GPU: ii = schedule . split ( i , block_x ) jj = schedule . split ( j , block_y ) Set the order to traverse the iteration space. Note that the precise order of execution on GPU targets will be unknown due to the parallel nature of the hardware. Nevertheless, setting the order here is important since the coarse grain parallelization (e.g., grid) should precede the more fine-grained (e.g., warps/wavefronts): schedule . reorder ( i , j , ii , jj , k ) Create a plan from the schedule. The plan allows us to control specific execution behavior on the hardware target. Such grid launch dimensions and thread blocks sizes are essential for high performance: target = acc . Target ( category = acc . Target . Category . GPU , runtime = acc . Target . Runtime . VULKAN ) plan = schedule . create_plan ( target ) Bind dimensions of the schedule to execution units on the GPU. Use the outer dimensions i , j to be the block indices x , y in the grid, and the ii and jj dimensions to be the thread indices x , y in the block: plan . bind ({ i : target . GridUnit . BLOCK_X , j : target . GridUnit . BLOCK_Y , ii : target . GridUnit . THREAD_X , jj : target . GridUnit . THREAD_Y }) Use the plan to add a callable function named hello_matmul_gpu to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"hello_matmul_gpu\" ) Finally, we build the HAT package: # Build a statically-linked HAT package to be consumed by the C++ runner package . build ( name = \"hello_matmul_gpu\" , format = acc . Package . Format . HAT_STATIC ) By now, you have all the code necessary to generate an Accera MatMul function that runs on the GPU. You can find the complete Python script here . Generate HAT package Next, we run the generator script to produce a HAT package. Windows/MacOS python hello_matmul_gpu_generator.py Ubuntu python3 hello_matmul_gpu_generator.py After this script runs, you should see a header file hello_matmul_gpu.hat and some object files (such as hello_matmul_gpu.obj or hello_matmul_gpu.o ). The build process also generates a supporting module, AcceraGPUUtilities.hat and its object file for GPU initialization and uninitialization. In Accera, we call these files the \"HAT package\". Runner code Let's see how we can call our MatMul implementation from the HAT package. Create a file called hello_matmul_gpu_runner.cpp containing the code below. You can find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares GPU initialization/uninitialization functions #include \"AcceraGPUUtilities.hat\" // Include the HAT file that declares our MatMul function #include \"hello_matmul_gpu.hat\" #define M 1024 #define N 512 #define K 256 int main ( int argc , const char ** argv ) { // Prepare our matrices (using the heap for large matrices) float * A = new float [ M * K ]; float * B = new float [ K * N ]; float * C = new float [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); // Initialize the GPU AcceraGPUInitialize (); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); hello_matmul_gpu ( A , B , C ); printf ( \"Result (first 10 elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); // Uninitialize the GPU AcceraGPUDeInitialize (); delete [] A ; delete [] B ; delete [] C ; return 0 ; } The above code creates the A , B , and C matrices and calls the function hello_matmul_gpu to perform MatMul. Now that we have the code, compile and link it with the HAT package to create an executable. Save the file to your working directory, in the exact location as hello_matmul_gpu_generator.py and the generated *.hat and object files. Build and run Accera includes a shared library that wraps the Vulkan APIs ( acc-vulkan-runtime-wrappers.so , acc-vulkan-runtime-wrappers.dll , or acc-vulkan-runtime-wrappers.dylib ). We need to provide the path to this shared library when building and running the executable. Find the installed path to the \"accera\" package: Windows/MacOS pip show accera Ubuntu pip3 show accera From the output above, find the Location entry, for example: Location: /usr/local/lib/python3.8/dist-packages We will use this path below. Windows We will need the 64-bit Visual C++ tools to link against the generated 64-bit .obj. From an \"x64 Native Tools Command Prompt\" : Set the ACCERA_PATH environment variable to the full install path of the \"accera\" package (derived from pip show accera to locate acc-vulkan-runtime-wrappers.dll ): set ACCERA_PATH = <Location_path> \\a ccera Set the PATH environment variable to allow the runner to locate acc-vulkan-runtime-wrappers.dll : set PATH = %PATH% ; %ACCERA_PATH% Now build and run: cl.exe hello_matmul_gpu_runner.cpp *.lib %ACCERA_PATH%/*.lib hello_matmul_gpu_runner.exe MacOS Set the ACCERA_PATH environment variable to the full install path of the \"accera\" package (derived from pip show accera to locate acc-vulkan-runtime-wrappers.dylib ): export ACCERA_PATH = <Location_path>/accera Now build and run: clang++ hello_matmul_gpu_runner.cpp *.a $ACCERA_PATH /*.dylib -o hello_matmul_gpu_runner DYLD_LIBRARY_PATH = $ACCERA_PATH ./hello_matmul_gpu_runner Ubuntu Set the ACCERA_PATH environment variable to the full install path of the \"accera\" package (derived from pip3 show accera to locate acc-vulkan-runtime-wrappers.so ): export ACCERA_PATH = <Location_path>/accera Now build and run: g++ hello_matmul_gpu_runner.cpp *.a $ACCERA_PATH /*.so -o hello_matmul_gpu_runner LD_LIBRARY_PATH = $ACCERA_PATH ./hello_matmul_gpu_runner The output should look like this: Calling MatMul M=1024, K=256, N=512 Result (first 10 elements): 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 You can now experiment with the generated MatMul function with your own inputs.","title":"Hello MatMul GPU"},{"location":"Tutorials/Hello_MatMul_GPU/#hello-matmul-gpu","text":"In this tutorial, you will learn how to implement a simple Matrix Multiplication (MatMul) function for execution on a GPU. We will use the Accera's Domain Specific Language (DSL) to produce a HAT package containing the MatMul function that can be called from the host to launch the MatMul function on the GPU.","title":"Hello MatMul GPU"},{"location":"Tutorials/Hello_MatMul_GPU/#prerequisites","text":"You should have Accera installed. If not, you can find the instructions in here . Be familiar with writing Python and C++ code. Be familiar with basic GPU programming and concepts. You have completed the Hello_MatMul tutorial. You have installed the Vulkan SDK and runtime .","title":"Prerequisites"},{"location":"Tutorials/Hello_MatMul_GPU/#review-the-naive-matmul-algorithm","text":"As in the Hello_MatMul tutorial, we'll consider the example of multiplying matrices A and B and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for-loops. Expressed in Python, this can look like: for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j]","title":"Review: the naive MatMul algorithm"},{"location":"Tutorials/Hello_MatMul_GPU/#accera-python-dsl","text":"We will now walk through a basic Matrix Multiplication (MatMul) using Accera. Additionally, we will direct Accera to execute this MatMul function on the default GPU. Create an empty file called hello_matmul_gpu_generator.py . Import dependent modules: import accera as acc Define some matrix sizes, where A's shape is M by K, B's is K by N, and C's, M by N. # Define our matrix sizes M = 1024 N = 512 K = 256 Declare arrays A , B , and C . These are our input and input/output matrices and hold 32-bit floating-point elements. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) Use the Nest class to define our 3-layered nested for-loop and get the indices: # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next, we define the logic for every iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul. Notice how, up to this point, it is identical to what we did for the CPU example . Let's now define the schedule to control the execution logic. To do this, we first create the schedule from the nest: schedule = nest . create_schedule () We will transform the iteration space and change the plan according to some predefined constants to execute this efficiently on our chosen hardware target. The values of these constants can come either from hardware target characteristics and the shapes of the arrays or can be found through auto-tuning. These will be explained in detail in a subsequent tutorial. For now, define: block_x = 16 block_y = 16 Transform the iteration space to specify the thread block behavior. See (GPU blocks)[TODO:markdown...] section to learning more about optimizing block sizes on GPU: ii = schedule . split ( i , block_x ) jj = schedule . split ( j , block_y ) Set the order to traverse the iteration space. Note that the precise order of execution on GPU targets will be unknown due to the parallel nature of the hardware. Nevertheless, setting the order here is important since the coarse grain parallelization (e.g., grid) should precede the more fine-grained (e.g., warps/wavefronts): schedule . reorder ( i , j , ii , jj , k ) Create a plan from the schedule. The plan allows us to control specific execution behavior on the hardware target. Such grid launch dimensions and thread blocks sizes are essential for high performance: target = acc . Target ( category = acc . Target . Category . GPU , runtime = acc . Target . Runtime . VULKAN ) plan = schedule . create_plan ( target ) Bind dimensions of the schedule to execution units on the GPU. Use the outer dimensions i , j to be the block indices x , y in the grid, and the ii and jj dimensions to be the thread indices x , y in the block: plan . bind ({ i : target . GridUnit . BLOCK_X , j : target . GridUnit . BLOCK_Y , ii : target . GridUnit . THREAD_X , jj : target . GridUnit . THREAD_Y }) Use the plan to add a callable function named hello_matmul_gpu to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"hello_matmul_gpu\" ) Finally, we build the HAT package: # Build a statically-linked HAT package to be consumed by the C++ runner package . build ( name = \"hello_matmul_gpu\" , format = acc . Package . Format . HAT_STATIC ) By now, you have all the code necessary to generate an Accera MatMul function that runs on the GPU. You can find the complete Python script here .","title":"Accera Python DSL"},{"location":"Tutorials/Hello_MatMul_GPU/#generate-hat-package","text":"Next, we run the generator script to produce a HAT package.","title":"Generate HAT package"},{"location":"Tutorials/Hello_MatMul_GPU/#windowsmacos","text":"python hello_matmul_gpu_generator.py","title":"Windows/MacOS"},{"location":"Tutorials/Hello_MatMul_GPU/#ubuntu","text":"python3 hello_matmul_gpu_generator.py After this script runs, you should see a header file hello_matmul_gpu.hat and some object files (such as hello_matmul_gpu.obj or hello_matmul_gpu.o ). The build process also generates a supporting module, AcceraGPUUtilities.hat and its object file for GPU initialization and uninitialization. In Accera, we call these files the \"HAT package\".","title":"Ubuntu"},{"location":"Tutorials/Hello_MatMul_GPU/#runner-code","text":"Let's see how we can call our MatMul implementation from the HAT package. Create a file called hello_matmul_gpu_runner.cpp containing the code below. You can find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares GPU initialization/uninitialization functions #include \"AcceraGPUUtilities.hat\" // Include the HAT file that declares our MatMul function #include \"hello_matmul_gpu.hat\" #define M 1024 #define N 512 #define K 256 int main ( int argc , const char ** argv ) { // Prepare our matrices (using the heap for large matrices) float * A = new float [ M * K ]; float * B = new float [ K * N ]; float * C = new float [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); // Initialize the GPU AcceraGPUInitialize (); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); hello_matmul_gpu ( A , B , C ); printf ( \"Result (first 10 elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); // Uninitialize the GPU AcceraGPUDeInitialize (); delete [] A ; delete [] B ; delete [] C ; return 0 ; } The above code creates the A , B , and C matrices and calls the function hello_matmul_gpu to perform MatMul. Now that we have the code, compile and link it with the HAT package to create an executable. Save the file to your working directory, in the exact location as hello_matmul_gpu_generator.py and the generated *.hat and object files.","title":"Runner code"},{"location":"Tutorials/Hello_MatMul_GPU/#build-and-run","text":"Accera includes a shared library that wraps the Vulkan APIs ( acc-vulkan-runtime-wrappers.so , acc-vulkan-runtime-wrappers.dll , or acc-vulkan-runtime-wrappers.dylib ). We need to provide the path to this shared library when building and running the executable. Find the installed path to the \"accera\" package:","title":"Build and run"},{"location":"Tutorials/Hello_MatMul_GPU/#windowsmacos_1","text":"pip show accera","title":"Windows/MacOS"},{"location":"Tutorials/Hello_MatMul_GPU/#ubuntu_1","text":"pip3 show accera From the output above, find the Location entry, for example: Location: /usr/local/lib/python3.8/dist-packages We will use this path below.","title":"Ubuntu"},{"location":"Tutorials/Hello_MatMul_GPU/#windows","text":"We will need the 64-bit Visual C++ tools to link against the generated 64-bit .obj. From an \"x64 Native Tools Command Prompt\" : Set the ACCERA_PATH environment variable to the full install path of the \"accera\" package (derived from pip show accera to locate acc-vulkan-runtime-wrappers.dll ): set ACCERA_PATH = <Location_path> \\a ccera Set the PATH environment variable to allow the runner to locate acc-vulkan-runtime-wrappers.dll : set PATH = %PATH% ; %ACCERA_PATH% Now build and run: cl.exe hello_matmul_gpu_runner.cpp *.lib %ACCERA_PATH%/*.lib hello_matmul_gpu_runner.exe","title":"Windows"},{"location":"Tutorials/Hello_MatMul_GPU/#macos","text":"Set the ACCERA_PATH environment variable to the full install path of the \"accera\" package (derived from pip show accera to locate acc-vulkan-runtime-wrappers.dylib ): export ACCERA_PATH = <Location_path>/accera Now build and run: clang++ hello_matmul_gpu_runner.cpp *.a $ACCERA_PATH /*.dylib -o hello_matmul_gpu_runner DYLD_LIBRARY_PATH = $ACCERA_PATH ./hello_matmul_gpu_runner","title":"MacOS"},{"location":"Tutorials/Hello_MatMul_GPU/#ubuntu_2","text":"Set the ACCERA_PATH environment variable to the full install path of the \"accera\" package (derived from pip3 show accera to locate acc-vulkan-runtime-wrappers.so ): export ACCERA_PATH = <Location_path>/accera Now build and run: g++ hello_matmul_gpu_runner.cpp *.a $ACCERA_PATH /*.so -o hello_matmul_gpu_runner LD_LIBRARY_PATH = $ACCERA_PATH ./hello_matmul_gpu_runner The output should look like this: Calling MatMul M=1024, K=256, N=512 Result (first 10 elements): 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 You can now experiment with the generated MatMul function with your own inputs.","title":"Ubuntu"},{"location":"Tutorials/Optimized_MatMul/","text":"Optimized MatMul Optimizing MatMul is highly dependent on the target platform. The code in the example below is optimized specifically for an Intel Xeon E5-2673 v3 CPU. However, it should work equally well on CPUs with similar hardware characteristics, such as an AMD Epyc 7551. By the end of this tutorial, you will learn how to: * Implement a performant Matrix Multiplication (MatMul) function targetting AVX2 FMA3 CPUs like Intel Haswell or the AMD Epyc families. * Produce a HAT package containing the optimized MatMul function. * Call the function from C or C++ code. Prerequisites You should have Accera installed. If not, you can find the instructions in here . You are familiar with writing Python and C++. You know about SIMD instructions and registers. You have completed the Hello_MatMul tutorial. Review: the naive MatMul algorithm As in the Hello_MatMul tutorial, we'll consider the example of multiplying matrices A and B and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for-loops. Expressed in Python, this will look like: for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j] Accera Python DSL We will walk through how to specify an optimized Matrix Multiplication (MatMul) using Accera. This tutorial assumes the following: Specific matrix sizes. Inputs A and B are 784 x 128 and 128 x 512 matrices, respectively. The output C is a 784 x 512 matrix. These can represent a mid-level layer in a Resnet-50 model. The A matrix contains the activation values from the previous layer, and the B matrix contains the weights of the neural network layer. Row-major layout of the matrix elements. The target hardware is capable of AVX2 FMA3 instructions, such as the Intel Xeon E5-2673 v3 or the AMD Epyc 7551. Create an empty file called optimized_matmul_generator.py . Import dependent modules: import accera as acc Define some matrix sizes, where A's shape is M by K, B's is K by N, and C's, M by N. # Define our matrix sizes M = 784 N = 512 K = 128 Declare arrays A , B , and C . These are our input and input/output matrices and hold 32-bit floating-point elements. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) Use the Nest class to define a 3-layered nested for-loop and get the indices: # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next, we define the logic for every iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul. Let's now define the schedule which controls execution logic. To do this, we first create the schedule from the nest: schedule = nest . create_schedule () We will transform the iteration space and change the plan according to some predefined constants to execute this efficiently on our chosen hardware target. Values of these constants come either from hardware target characteristics and the shapes of the arrays or can be found through auto-tuning. These will be explained in detail in a subsequent tutorial. For now, define: tile_size_i = 6 tile_size_j = 256 tile_size_k = 128 inner_dim_unroll = 4 num_rows_in_kernel = 6 We create a CPU target that defines constants for the SIMD vector sizes and the number of vector execution units to use the hardware characteristics. target = acc . Target ( category = acc . Target . Category . CPU ) Transform the iteration space to specify the tiling behavior: ii = schedule . split ( i , tile_size_i ) jj = schedule . split ( j , tile_size_j ) kk = schedule . split ( k , tile_size_k ) Next, let's split the iteration space to match the kernel characteristics: kkk = schedule . split ( kk , inner_dim_unroll ) iii = schedule . split ( ii , num_rows_in_kernel ) jjj = schedule . split ( jj , ( target . vector_bytes // 4 ) * 2 ) # There are 2 vfma execution units, each holding (target.vector_bytes // 4) 32-bit float elements jjjj = schedule . split ( jjj , target . vector_bytes // 4 ) # Each SIMD register holds (target.vector_bytes // 4) 32-bit float elements Accera will handle the encountered boundary conditions for each of these splits and do appropriate optimizations such as loop un-switching to ensure that efficient code gets generated in those cases. Set the order to traverse the iteration space. We start with the outer indices that control the tiling, then move to the innermost indices that are used in the kernel: schedule . reorder ( j , k , i , jj , kk , ii , kkk , iii , jjj , jjjj ) Create a plan from the schedule and the current target. The plan allows us to control specific execution behavior on the hardware target, such as vectorization and caching, which are essential for high performance: plan = schedule . create_plan ( target ) Add caching. We use an input cache for array B that exceeds our threshold. The B cache will be packed according to the access pattern specified by the schedule. We use an input/output cache for array C . See caching for more information: # Cache the B array by prefetching and packing the memory footprint along slices of the jj dimension. plan . cache ( B , jj ) # Cache the C array along slices of jj dimension. Since the C array is the output, its footprint is # the size of the kernel. If the kernel is small enough, Accera will use registers for this # accumulation before writing these values back to C. plan . cache ( C , jj ) Kernelize the inner dimensions, which applies unroll and vectorize transformations allowing use of SIMD registers: plan . kernelize ( unroll_indices = [ jjj , iii , kkk ], vectorize_indices = jjjj ) Use the plan to add a function named optimized_matmul_py to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"optimized_matmul_py\" ) Finally, we build the HAT package: # Build a statically-linked HAT package to be consumed by the C++ runner package . build ( name = \"optimized_matmul\" , format = acc . Package . Format . HAT_STATIC ) By now, you should have all the code necessary to generate an optimized Accera MatMul function. You can find the complete Python script here . Generate HAT package Next, we run the generator script to produce a HAT package. Windows/MacOS python optimized_matmul_generator.py Ubuntu python3 optimized_matmul_generator.py The generator script produces a HAT file ( optimized_matmul.hat ). Examine this file, and you will see that it contains the exported function with the following meta-data: [functions.optimized_matmul_py_4a6286d9] name = 'optimized_matmul_py_4a6286d9' description = '' calling_convention = \"cdecl\" arguments = [ { name = '' , description = '' , logical_type = \"affine_array\" , declared_type = 'float*' , element_type = 'float' , usage = \"input_output\" , shape = [ 784 , 128 ], affine_map = [ 128 , 1 ], affine_offset = 0 }, { name = '' , description = '' , logical_type = \"affine_array\" , declared_type = 'float*' , element_type = 'float' , usage = \"input_output\" , shape = [ 128 , 512 ], affine_map = [ 512 , 1 ], affine_offset = 0 }, { name = '' , description = '' , logical_type = \"affine_array\" , declared_type = 'float*' , element_type = 'float' , usage = \"input_output\" , shape = [ 784 , 512 ], affine_map = [ 512 , 1 ], affine_offset = 0 } ] return = { name = '' , description = '' , logical_type = \"void\" , declared_type = 'void' , element_type = 'void' , usage = \"output\" } The C declaration from the header is: void optimized_matmul_py_4a6286d9 ( float * , float * , float * ); Accera automatically appends a unique identifier to the function implementation, such as optimized_matmul_py_4a6286d9 to support auto-tuning. This name is re-generated every time the HAT package is rebuilt. To make it easier for client code to use the function, Accera also provides a fixed-name alias, optimized_matmul_py , for the same function. To see how Accera generates code for the iteration space transformations and the plan, you can change the format=HAT to format=MLIR , which will output MLIR for each lowering phase. Stepping through the progression of lowerings, you can see how Accera moves from simple representation of the Accera DSL , to the final optimized assembly . Compare this to previous tutorial, whose naive DSL is given here , and final assembly can be viewed here . Runner code Let's see how to call our MatMul implementation from the HAT package. Create a file called optimized_matmul_runner.cpp with the code below. You can also find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares our MatMul function #include \"optimized_matmul.hat\" #define M 784 #define N 512 #define K 128 int main ( int argc , const char ** argv ) { // Prepare our matrices (using the heap for large matrices) float * A = new float [ M * K ]; float * B = new float [ K * N ]; float * C = new float [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); optimized_matmul_py ( A , B , C ); printf ( \"Result (first 10 elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); delete [] A ; delete [] B ; delete [] C ; return 0 ; } The above code creates the matrices A , B , and C and calls the function optimized_matmul_py to perform MatMul. Now that we have the code, let's compile and link it with the HAT package to create an executable. Save the file to your working directory, in the same location as optimized_matmul_generator.py and the generated *.hat and object files. Build and run Windows We will need the 64-bit Visual C++ tools to link against the generated 64-bit .obj. From an \"x64 Native Tools Command Prompt\" : cl.exe optimized_matmul_runner.cpp *.lib optimized_matmul_runner.exe MacOS clang++ optimized_matmul_runner.cpp *.a -o optimized_matmul_runner ./optimized_matmul_runner Ubuntu g++ optimized_matmul_runner.cpp *.a -o optimized_matmul_runner ./optimized_matmul_runner The output should look like: Calling MatMul M=784, K=128, N=512 Result (first 10 elements): 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 You can now experiment with the generated MatMul function with your own inputs.","title":"Optimized MatMul"},{"location":"Tutorials/Optimized_MatMul/#optimized-matmul","text":"Optimizing MatMul is highly dependent on the target platform. The code in the example below is optimized specifically for an Intel Xeon E5-2673 v3 CPU. However, it should work equally well on CPUs with similar hardware characteristics, such as an AMD Epyc 7551. By the end of this tutorial, you will learn how to: * Implement a performant Matrix Multiplication (MatMul) function targetting AVX2 FMA3 CPUs like Intel Haswell or the AMD Epyc families. * Produce a HAT package containing the optimized MatMul function. * Call the function from C or C++ code.","title":"Optimized MatMul"},{"location":"Tutorials/Optimized_MatMul/#prerequisites","text":"You should have Accera installed. If not, you can find the instructions in here . You are familiar with writing Python and C++. You know about SIMD instructions and registers. You have completed the Hello_MatMul tutorial.","title":"Prerequisites"},{"location":"Tutorials/Optimized_MatMul/#review-the-naive-matmul-algorithm","text":"As in the Hello_MatMul tutorial, we'll consider the example of multiplying matrices A and B and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for-loops. Expressed in Python, this will look like: for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j]","title":"Review: the naive MatMul algorithm"},{"location":"Tutorials/Optimized_MatMul/#accera-python-dsl","text":"We will walk through how to specify an optimized Matrix Multiplication (MatMul) using Accera. This tutorial assumes the following: Specific matrix sizes. Inputs A and B are 784 x 128 and 128 x 512 matrices, respectively. The output C is a 784 x 512 matrix. These can represent a mid-level layer in a Resnet-50 model. The A matrix contains the activation values from the previous layer, and the B matrix contains the weights of the neural network layer. Row-major layout of the matrix elements. The target hardware is capable of AVX2 FMA3 instructions, such as the Intel Xeon E5-2673 v3 or the AMD Epyc 7551. Create an empty file called optimized_matmul_generator.py . Import dependent modules: import accera as acc Define some matrix sizes, where A's shape is M by K, B's is K by N, and C's, M by N. # Define our matrix sizes M = 784 N = 512 K = 128 Declare arrays A , B , and C . These are our input and input/output matrices and hold 32-bit floating-point elements. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) Use the Nest class to define a 3-layered nested for-loop and get the indices: # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next, we define the logic for every iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul. Let's now define the schedule which controls execution logic. To do this, we first create the schedule from the nest: schedule = nest . create_schedule () We will transform the iteration space and change the plan according to some predefined constants to execute this efficiently on our chosen hardware target. Values of these constants come either from hardware target characteristics and the shapes of the arrays or can be found through auto-tuning. These will be explained in detail in a subsequent tutorial. For now, define: tile_size_i = 6 tile_size_j = 256 tile_size_k = 128 inner_dim_unroll = 4 num_rows_in_kernel = 6 We create a CPU target that defines constants for the SIMD vector sizes and the number of vector execution units to use the hardware characteristics. target = acc . Target ( category = acc . Target . Category . CPU ) Transform the iteration space to specify the tiling behavior: ii = schedule . split ( i , tile_size_i ) jj = schedule . split ( j , tile_size_j ) kk = schedule . split ( k , tile_size_k ) Next, let's split the iteration space to match the kernel characteristics: kkk = schedule . split ( kk , inner_dim_unroll ) iii = schedule . split ( ii , num_rows_in_kernel ) jjj = schedule . split ( jj , ( target . vector_bytes // 4 ) * 2 ) # There are 2 vfma execution units, each holding (target.vector_bytes // 4) 32-bit float elements jjjj = schedule . split ( jjj , target . vector_bytes // 4 ) # Each SIMD register holds (target.vector_bytes // 4) 32-bit float elements Accera will handle the encountered boundary conditions for each of these splits and do appropriate optimizations such as loop un-switching to ensure that efficient code gets generated in those cases. Set the order to traverse the iteration space. We start with the outer indices that control the tiling, then move to the innermost indices that are used in the kernel: schedule . reorder ( j , k , i , jj , kk , ii , kkk , iii , jjj , jjjj ) Create a plan from the schedule and the current target. The plan allows us to control specific execution behavior on the hardware target, such as vectorization and caching, which are essential for high performance: plan = schedule . create_plan ( target ) Add caching. We use an input cache for array B that exceeds our threshold. The B cache will be packed according to the access pattern specified by the schedule. We use an input/output cache for array C . See caching for more information: # Cache the B array by prefetching and packing the memory footprint along slices of the jj dimension. plan . cache ( B , jj ) # Cache the C array along slices of jj dimension. Since the C array is the output, its footprint is # the size of the kernel. If the kernel is small enough, Accera will use registers for this # accumulation before writing these values back to C. plan . cache ( C , jj ) Kernelize the inner dimensions, which applies unroll and vectorize transformations allowing use of SIMD registers: plan . kernelize ( unroll_indices = [ jjj , iii , kkk ], vectorize_indices = jjjj ) Use the plan to add a function named optimized_matmul_py to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"optimized_matmul_py\" ) Finally, we build the HAT package: # Build a statically-linked HAT package to be consumed by the C++ runner package . build ( name = \"optimized_matmul\" , format = acc . Package . Format . HAT_STATIC ) By now, you should have all the code necessary to generate an optimized Accera MatMul function. You can find the complete Python script here .","title":"Accera Python DSL"},{"location":"Tutorials/Optimized_MatMul/#generate-hat-package","text":"Next, we run the generator script to produce a HAT package.","title":"Generate HAT package"},{"location":"Tutorials/Optimized_MatMul/#windowsmacos","text":"python optimized_matmul_generator.py","title":"Windows/MacOS"},{"location":"Tutorials/Optimized_MatMul/#ubuntu","text":"python3 optimized_matmul_generator.py The generator script produces a HAT file ( optimized_matmul.hat ). Examine this file, and you will see that it contains the exported function with the following meta-data: [functions.optimized_matmul_py_4a6286d9] name = 'optimized_matmul_py_4a6286d9' description = '' calling_convention = \"cdecl\" arguments = [ { name = '' , description = '' , logical_type = \"affine_array\" , declared_type = 'float*' , element_type = 'float' , usage = \"input_output\" , shape = [ 784 , 128 ], affine_map = [ 128 , 1 ], affine_offset = 0 }, { name = '' , description = '' , logical_type = \"affine_array\" , declared_type = 'float*' , element_type = 'float' , usage = \"input_output\" , shape = [ 128 , 512 ], affine_map = [ 512 , 1 ], affine_offset = 0 }, { name = '' , description = '' , logical_type = \"affine_array\" , declared_type = 'float*' , element_type = 'float' , usage = \"input_output\" , shape = [ 784 , 512 ], affine_map = [ 512 , 1 ], affine_offset = 0 } ] return = { name = '' , description = '' , logical_type = \"void\" , declared_type = 'void' , element_type = 'void' , usage = \"output\" } The C declaration from the header is: void optimized_matmul_py_4a6286d9 ( float * , float * , float * ); Accera automatically appends a unique identifier to the function implementation, such as optimized_matmul_py_4a6286d9 to support auto-tuning. This name is re-generated every time the HAT package is rebuilt. To make it easier for client code to use the function, Accera also provides a fixed-name alias, optimized_matmul_py , for the same function. To see how Accera generates code for the iteration space transformations and the plan, you can change the format=HAT to format=MLIR , which will output MLIR for each lowering phase. Stepping through the progression of lowerings, you can see how Accera moves from simple representation of the Accera DSL , to the final optimized assembly . Compare this to previous tutorial, whose naive DSL is given here , and final assembly can be viewed here .","title":"Ubuntu"},{"location":"Tutorials/Optimized_MatMul/#runner-code","text":"Let's see how to call our MatMul implementation from the HAT package. Create a file called optimized_matmul_runner.cpp with the code below. You can also find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares our MatMul function #include \"optimized_matmul.hat\" #define M 784 #define N 512 #define K 128 int main ( int argc , const char ** argv ) { // Prepare our matrices (using the heap for large matrices) float * A = new float [ M * K ]; float * B = new float [ K * N ]; float * C = new float [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); optimized_matmul_py ( A , B , C ); printf ( \"Result (first 10 elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); delete [] A ; delete [] B ; delete [] C ; return 0 ; } The above code creates the matrices A , B , and C and calls the function optimized_matmul_py to perform MatMul. Now that we have the code, let's compile and link it with the HAT package to create an executable. Save the file to your working directory, in the same location as optimized_matmul_generator.py and the generated *.hat and object files.","title":"Runner code"},{"location":"Tutorials/Optimized_MatMul/#build-and-run","text":"","title":"Build and run"},{"location":"Tutorials/Optimized_MatMul/#windows","text":"We will need the 64-bit Visual C++ tools to link against the generated 64-bit .obj. From an \"x64 Native Tools Command Prompt\" : cl.exe optimized_matmul_runner.cpp *.lib optimized_matmul_runner.exe","title":"Windows"},{"location":"Tutorials/Optimized_MatMul/#macos","text":"clang++ optimized_matmul_runner.cpp *.a -o optimized_matmul_runner ./optimized_matmul_runner","title":"MacOS"},{"location":"Tutorials/Optimized_MatMul/#ubuntu_1","text":"g++ optimized_matmul_runner.cpp *.a -o optimized_matmul_runner ./optimized_matmul_runner The output should look like: Calling MatMul M=784, K=128, N=512 Result (first 10 elements): 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 768.419983 You can now experiment with the generated MatMul function with your own inputs.","title":"Ubuntu"},{"location":"Tutorials/Pi3_Cross_Compilation/","text":"Cross Compiling for the Raspberry Pi 3 By the end of this tutorial, you will learn how to: Cross compile a simple Matrix Multiplication (MatMul) function for execution on a Raspberry Pi 3. Produce a HAT package containing the MatMul function that can be called on the Pi 3 target. Call the function on a Raspberry Pi 3 from C/C++ code. Prerequisites You should have Accera installed. If not, you can find the instructions in here . Be familiar with writing Python and C++ code. Have access to a Raspberry Pi 3 device. A naive MatMul algorithm Consider the example of multiplying matrices A and B and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for-loops. In Python, this can be expressed as: # A.shape = (M, K), B.shape = (K, N), C.shape = (M, N) for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j] Accera Python DSL Let's walk through a na\u00efve Matrix Multiplication (MatMul) using Accera. Instead of using the default target, i.e., the host machine, we specify a target representing a Raspberry Pi 3 to cross-compile the host for a different target. Create an empty file called hello_matmul_pi3_generator.py . First, we import Accera's module: import accera as acc Define some matrix sizes, where A's shape is M by K, B's is K by N, and C's, M by N. # Define our matrix sizes M = 128 N = 256 K = 256 Write a Python function that receives A , B , and C arrays. These are our input and input/output matrices. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) We now use the Nest class to define our 3-layered nested for-loop. The range indices are M , N , and K , with the outermost loop ( M ) listed first. We can get the loop nest indices to perform the computation. # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next, we define the logic for every iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul. Let's now define the schedule which controls the execution of logic. For this, we first create the schedule from the nest: sched = nest . create_schedule () At this point, sched represents the default schedule for our algorithm. We can also perform some basic transformations on this schedule. For example, the following lines of code split the k index into blocks of 4 ( k , k+4 , k+8 , and so on). # Split the k loop into blocks of 4, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # # Split k into two loops # for k in range(0, K, 4): # for kk in range(4): # C[i, j] += A[i, k + kk] * B[k + kk, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. kk = sched . split ( k , 4 ) The split index is now k and kk . The next step is to create a plan from the schedule. For instance, we can use this plan to unroll the innermost loop. # Create a plan, specify the target to be a Raspberry Pi 3 pi3 = acc . Target ( acc . Target . Model . RASPBERRY_PI_3B ) plan = sched . create_plan ( pi3 ) # Unroll kk, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # for k in range(0, K, 4): # # Unrolled kk # C[i, j] += A[i, k + 0] * B[k + 0, j] # C[i, j] += A[i, k + 1] * B[k + 1, j] # C[i, j] += A[i, k + 2] * B[k + 2, j] # C[i, j] += A[i, k + 3] * B[k + 3, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. plan . unroll ( kk ) Use the plan to add a callable function named hello_matmul_pi3_py to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"hello_matmul_pi3_py\" ) Finally, we build the statically-linked HAT package for the Raspbian platform: # Build the HAT package package . build ( name = \"hello_matmul_pi3\" , format = acc . Package . Format . HAT_STATIC , platform = acc . Package . Platform . RASPBIAN ) After following the above steps, you should now have all the code necessary to generate your Accera MatMul function that can be called on a Raspberry Pi 3 target. You can find the complete Python script here . Generate HAT package Next, we run the generator script to produce a HAT package for the Raspberry Pi 3 target. Windows/MacOS python hello_matmul_pi3_generator.py Ubuntu python3 hello_matmul_pi3_generator.py After we run the script, there should be a header file hello_matmul_pi3.hat and an object file hello_matmul_pi3.o in the ELF format. The .hat file format is described here . Collectively, we call the .hat file and object file a \"HAT package\". Runner code Let's now see how we can call our MatMul implementation from the HAT package on the Raspberry Pi 3. Create a file called hello_matmul_pi3_runner.cpp with the code below. You can find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares our MatMul function #include \"hello_matmul_p3.HAT\" #define M 128 #define N 256 #define K 256 int main ( int argc , const char ** argv ) { // Prepare our matrices float A [ M * K ]; float B [ K * N ]; float C [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); hello_matmul_py ( A , B , C ); printf ( \"Result (first few elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); return 0 ; } The above code creates the A , B , and C matrices and calls the function hello_matmul_pi3_py to perform MatMul. Now that we have written the code, we compile and link it with the HAT package to create an executable file. Save this file to your working directory, in the exact location as hello_matmul_pi3_generator.py, and the generated *.hat and *.o files. Build and run On the Raspberry Pi 3 device For this step, you'll be working with your Raspberry Pi device. If your Pi device is accessible over the network, copy hello_matmul_pi3_runner.cpp , hello_matmul_pi3.hat , and hello_matmul_pi3.o using the Unix scp tool or the Windows WinSCP tool here ., otherwise use a USB thumb drive to transfer files manually. You do not need to copy the other generated files and folders. You also need gcc . Although it is often installed by default on Raspberry Pi 3 systems, type this for confirmation: sudo apt-get install -y gcc This has been verified with \"Raspbian GNU/Linux 9 (stretch)\" and gcc<4:6.3.0-4> and should work with subsequent versions. Now, you can run the following commands to build and run. gcc hello_matmul_pi3_runner.cpp hello_matmul_pi3.o -o hello_matmul_pi3_runner ./hello_matmul_pi3_runner The output should look like: Calling MatMul M=128, K=256, N=256 Result (first few elements): 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 You can now experiment with the generated MatMul function with your own inputs. To try different inputs, you can modify hello_matmul_pi3_runner.cpp on the Raspberry Pi 3 and recompile it with the existing HAT package.","title":"Pi3 Cross Compilation"},{"location":"Tutorials/Pi3_Cross_Compilation/#cross-compiling-for-the-raspberry-pi-3","text":"By the end of this tutorial, you will learn how to: Cross compile a simple Matrix Multiplication (MatMul) function for execution on a Raspberry Pi 3. Produce a HAT package containing the MatMul function that can be called on the Pi 3 target. Call the function on a Raspberry Pi 3 from C/C++ code.","title":"Cross Compiling for the Raspberry Pi 3"},{"location":"Tutorials/Pi3_Cross_Compilation/#prerequisites","text":"You should have Accera installed. If not, you can find the instructions in here . Be familiar with writing Python and C++ code. Have access to a Raspberry Pi 3 device.","title":"Prerequisites"},{"location":"Tutorials/Pi3_Cross_Compilation/#a-naive-matmul-algorithm","text":"Consider the example of multiplying matrices A and B and adding the result into matrix C. In NumPy syntax, this can be expressed as: C += A @ B A naive algorithm for matrix multiplication typically contains 3 nested for-loops. In Python, this can be expressed as: # A.shape = (M, K), B.shape = (K, N), C.shape = (M, N) for i in range(M): for j in range(N): for k in range(K): C[i, j] += A[i, k] * B[k, j]","title":"A naive MatMul algorithm"},{"location":"Tutorials/Pi3_Cross_Compilation/#accera-python-dsl","text":"Let's walk through a na\u00efve Matrix Multiplication (MatMul) using Accera. Instead of using the default target, i.e., the host machine, we specify a target representing a Raspberry Pi 3 to cross-compile the host for a different target. Create an empty file called hello_matmul_pi3_generator.py . First, we import Accera's module: import accera as acc Define some matrix sizes, where A's shape is M by K, B's is K by N, and C's, M by N. # Define our matrix sizes M = 128 N = 256 K = 256 Write a Python function that receives A , B , and C arrays. These are our input and input/output matrices. A = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( M , K )) B = acc . Array ( role = acc . Array . Role . INPUT , element_type = acc . ScalarType . float32 , shape = ( K , N )) C = acc . Array ( role = acc . Array . Role . INPUT_OUTPUT , element_type = acc . ScalarType . float32 , shape = ( M , N )) We now use the Nest class to define our 3-layered nested for-loop. The range indices are M , N , and K , with the outermost loop ( M ) listed first. We can get the loop nest indices to perform the computation. # Define the loop nest nest = acc . Nest ( shape = ( M , N , K )) # Get the loop nest indices i , j , k = nest . get_indices () Next, we define the logic for every iteration of the loop nest: # Define the loop nest logic @nest . iteration_logic def _ (): C [ i , j ] += A [ i , k ] * B [ k , j ] We have finished defining the logic of MatMul. Let's now define the schedule which controls the execution of logic. For this, we first create the schedule from the nest: sched = nest . create_schedule () At this point, sched represents the default schedule for our algorithm. We can also perform some basic transformations on this schedule. For example, the following lines of code split the k index into blocks of 4 ( k , k+4 , k+8 , and so on). # Split the k loop into blocks of 4, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # # Split k into two loops # for k in range(0, K, 4): # for kk in range(4): # C[i, j] += A[i, k + kk] * B[k + kk, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. kk = sched . split ( k , 4 ) The split index is now k and kk . The next step is to create a plan from the schedule. For instance, we can use this plan to unroll the innermost loop. # Create a plan, specify the target to be a Raspberry Pi 3 pi3 = acc . Target ( acc . Target . Model . RASPBERRY_PI_3B ) plan = sched . create_plan ( pi3 ) # Unroll kk, effectively doing this # (assuming K is divisible by 4): # # for i in range(M): # for j in range(N): # for k in range(0, K, 4): # # Unrolled kk # C[i, j] += A[i, k + 0] * B[k + 0, j] # C[i, j] += A[i, k + 1] * B[k + 1, j] # C[i, j] += A[i, k + 2] * B[k + 2, j] # C[i, j] += A[i, k + 3] * B[k + 3, j] # # If k is not divisible by 4, Accera will take care of the boundary # case for you. plan . unroll ( kk ) Use the plan to add a callable function named hello_matmul_pi3_py to a HAT package. # Create a package and add a function to the package based on the plan package = acc . Package () package . add ( plan , args = ( A , B , C ), base_name = \"hello_matmul_pi3_py\" ) Finally, we build the statically-linked HAT package for the Raspbian platform: # Build the HAT package package . build ( name = \"hello_matmul_pi3\" , format = acc . Package . Format . HAT_STATIC , platform = acc . Package . Platform . RASPBIAN ) After following the above steps, you should now have all the code necessary to generate your Accera MatMul function that can be called on a Raspberry Pi 3 target. You can find the complete Python script here .","title":"Accera Python DSL"},{"location":"Tutorials/Pi3_Cross_Compilation/#generate-hat-package","text":"Next, we run the generator script to produce a HAT package for the Raspberry Pi 3 target.","title":"Generate HAT package"},{"location":"Tutorials/Pi3_Cross_Compilation/#windowsmacos","text":"python hello_matmul_pi3_generator.py","title":"Windows/MacOS"},{"location":"Tutorials/Pi3_Cross_Compilation/#ubuntu","text":"python3 hello_matmul_pi3_generator.py After we run the script, there should be a header file hello_matmul_pi3.hat and an object file hello_matmul_pi3.o in the ELF format. The .hat file format is described here . Collectively, we call the .hat file and object file a \"HAT package\".","title":"Ubuntu"},{"location":"Tutorials/Pi3_Cross_Compilation/#runner-code","text":"Let's now see how we can call our MatMul implementation from the HAT package on the Raspberry Pi 3. Create a file called hello_matmul_pi3_runner.cpp with the code below. You can find it here . #include <stdio.h> #include <algorithm> // Include the HAT file that declares our MatMul function #include \"hello_matmul_p3.HAT\" #define M 128 #define N 256 #define K 256 int main ( int argc , const char ** argv ) { // Prepare our matrices float A [ M * K ]; float B [ K * N ]; float C [ M * N ]; // Fill with data std :: fill_n ( A , M * K , 2.0f ); std :: fill_n ( B , K * N , 3.0f ); std :: fill_n ( C , M * N , 0.42f ); printf ( \"Calling MatMul M=%d, K=%d, N=%d \\n \" , M , K , N ); hello_matmul_py ( A , B , C ); printf ( \"Result (first few elements): \" ); for ( int i = 0 ; i < 10 ; ++ i ) { printf ( \"%f \" , C [ i ]); } printf ( \" \\n \" ); return 0 ; } The above code creates the A , B , and C matrices and calls the function hello_matmul_pi3_py to perform MatMul. Now that we have written the code, we compile and link it with the HAT package to create an executable file. Save this file to your working directory, in the exact location as hello_matmul_pi3_generator.py, and the generated *.hat and *.o files.","title":"Runner code"},{"location":"Tutorials/Pi3_Cross_Compilation/#build-and-run","text":"","title":"Build and run"},{"location":"Tutorials/Pi3_Cross_Compilation/#on-the-raspberry-pi-3-device","text":"For this step, you'll be working with your Raspberry Pi device. If your Pi device is accessible over the network, copy hello_matmul_pi3_runner.cpp , hello_matmul_pi3.hat , and hello_matmul_pi3.o using the Unix scp tool or the Windows WinSCP tool here ., otherwise use a USB thumb drive to transfer files manually. You do not need to copy the other generated files and folders. You also need gcc . Although it is often installed by default on Raspberry Pi 3 systems, type this for confirmation: sudo apt-get install -y gcc This has been verified with \"Raspbian GNU/Linux 9 (stretch)\" and gcc<4:6.3.0-4> and should work with subsequent versions. Now, you can run the following commands to build and run. gcc hello_matmul_pi3_runner.cpp hello_matmul_pi3.o -o hello_matmul_pi3_runner ./hello_matmul_pi3_runner The output should look like: Calling MatMul M=128, K=256, N=256 Result (first few elements): 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 1536.419922 You can now experiment with the generated MatMul function with your own inputs. To try different inputs, you can modify hello_matmul_pi3_runner.cpp on the Raspberry Pi 3 and recompile it with the existing HAT package.","title":"On the Raspberry Pi 3 device"}]}